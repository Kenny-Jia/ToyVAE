{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2406db2a-9fbf-450e-9968-a31ec6d51c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 00:58:57.235339: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 00:58:57.455513: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-10-15 00:58:57.455556: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-10-15 00:59:14.867066: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-15 00:59:14.867204: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-15 00:59:14.867224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import traceback\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.math as tfmath\n",
    "import tensorflow.keras as keras\n",
    "# from scipy.optimize import curve_fit\n",
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn.metrics as sk\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ecd26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import PReLU, Input, LSTM, Flatten, Concatenate, Dense, Conv2D, TimeDistributed, MaxPooling2D, LeakyReLU, ReLU, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import Precision\n",
    "# from qkeras import QActivation, QDense, QConv2D, QBatchNormalization, QConv2DBatchnorm\n",
    "# from qkeras import quantized_relu, quantized_bits\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc21ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from preprocessed_SNL_data.h5\n"
     ]
    }
   ],
   "source": [
    "#preprocessed_SNL_data.h5 is located under s3df /sdf/home/l/lizhx/\n",
    "home_path = \"/fs/ddn/sdf/group/atlas/d/lizhx/\"\n",
    "file_path = home_path + \"preprocessed_SNL_data.h5\"\n",
    "with h5py.File(file_path, 'r') as hf:\n",
    "    X_train = hf['X_train'][:]\n",
    "    X_test  = hf['X_test'][:]\n",
    "    Ato4l_data  = hf['Ato4l_data'][:]\n",
    "    hToTauTau_data  = hf['hToTauTau_data'][:]\n",
    "    hChToTauNu_data  = hf['hChToTauNu_data'][:]\n",
    "    leptoquark_data = hf['leptoquark_data'][:]\n",
    "    print(\"Data loaded from preprocessed_SNL_data.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58eedb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 1:\n",
      "  Mean: -0.0000\n",
      "  Min: -1.9571\n",
      "  Max: 53.1526\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 2:\n",
      "  Mean: 0.0000\n",
      "  Min: 0.0000\n",
      "  Max: 0.0000\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 3:\n",
      "  Mean: 0.0000\n",
      "  Min: -1.7323\n",
      "  Max: 1.7311\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 4:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.9537\n",
      "  Max: 47.1318\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 5:\n",
      "  Mean: -0.0000\n",
      "  Min: -2.4819\n",
      "  Max: 2.4821\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 6:\n",
      "  Mean: -0.0000\n",
      "  Min: -2.3496\n",
      "  Max: 2.3489\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 7:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.0355\n",
      "  Max: 200.8080\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 8:\n",
      "  Mean: -0.0000\n",
      "  Min: -43.0203\n",
      "  Max: 43.0213\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 9:\n",
      "  Mean: 0.0000\n",
      "  Min: -34.6662\n",
      "  Max: 34.6653\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 10:\n",
      "  Mean: 0.0000\n",
      "  Min: -0.0108\n",
      "  Max: 302.0646\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 11:\n",
      "  Mean: -0.0000\n",
      "  Min: -181.6179\n",
      "  Max: 181.7817\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 12:\n",
      "  Mean: -0.0000\n",
      "  Min: -130.9459\n",
      "  Max: 130.8367\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 13:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.0028\n",
      "  Max: 660.7622\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 14:\n",
      "  Mean: 0.0000\n",
      "  Min: -520.3063\n",
      "  Max: 686.6438\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 15:\n",
      "  Mean: -0.0000\n",
      "  Min: -487.7219\n",
      "  Max: 484.9506\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 16:\n",
      "  Mean: 0.0000\n",
      "  Min: -0.8222\n",
      "  Max: 33.0882\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 17:\n",
      "  Mean: 0.0000\n",
      "  Min: -2.5472\n",
      "  Max: 2.5471\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 18:\n",
      "  Mean: 0.0000\n",
      "  Min: -2.5510\n",
      "  Max: 2.5516\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 19:\n",
      "  Mean: 0.0000\n",
      "  Min: -0.0297\n",
      "  Max: 291.0383\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 20:\n",
      "  Mean: 0.0000\n",
      "  Min: -47.0408\n",
      "  Max: 47.0603\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 21:\n",
      "  Mean: 0.0000\n",
      "  Min: -41.7168\n",
      "  Max: 41.7156\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 22:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.0083\n",
      "  Max: 421.5737\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 23:\n",
      "  Mean: -0.0000\n",
      "  Min: -205.2899\n",
      "  Max: 202.9845\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 24:\n",
      "  Mean: -0.0000\n",
      "  Min: -174.2299\n",
      "  Max: 173.6709\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 25:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.0020\n",
      "  Max: 940.8060\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 26:\n",
      "  Mean: 0.0000\n",
      "  Min: -810.1814\n",
      "  Max: 794.4273\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 27:\n",
      "  Mean: -0.0000\n",
      "  Min: -722.3286\n",
      "  Max: 612.0592\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 28:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.5123\n",
      "  Max: 58.0216\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 29:\n",
      "  Mean: 0.0000\n",
      "  Min: -3.8580\n",
      "  Max: 3.8601\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 30:\n",
      "  Mean: 0.0000\n",
      "  Min: -2.7959\n",
      "  Max: 2.7976\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 31:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.2677\n",
      "  Max: 109.7365\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 32:\n",
      "  Mean: 0.0000\n",
      "  Min: -6.3577\n",
      "  Max: 6.3593\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 33:\n",
      "  Mean: 0.0000\n",
      "  Min: -5.0049\n",
      "  Max: 5.0044\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 34:\n",
      "  Mean: 0.0000\n",
      "  Min: -0.1481\n",
      "  Max: 123.6013\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 35:\n",
      "  Mean: -0.0000\n",
      "  Min: -11.6921\n",
      "  Max: 11.6929\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 36:\n",
      "  Mean: -0.0000\n",
      "  Min: -9.2581\n",
      "  Max: 9.2558\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 37:\n",
      "  Mean: 0.0000\n",
      "  Min: -0.0871\n",
      "  Max: 101.4869\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 38:\n",
      "  Mean: -0.0000\n",
      "  Min: -21.1709\n",
      "  Max: 21.1645\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 39:\n",
      "  Mean: -0.0000\n",
      "  Min: -16.2261\n",
      "  Max: 16.2256\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 40:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.0575\n",
      "  Max: 120.7499\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 41:\n",
      "  Mean: -0.0000\n",
      "  Min: -34.5995\n",
      "  Max: 34.6021\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 42:\n",
      "  Mean: -0.0000\n",
      "  Min: -25.6311\n",
      "  Max: 25.6354\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 43:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.0399\n",
      "  Max: 108.0682\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 44:\n",
      "  Mean: -0.0000\n",
      "  Min: -52.7219\n",
      "  Max: 52.7200\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 45:\n",
      "  Mean: 0.0000\n",
      "  Min: -38.4837\n",
      "  Max: 38.4987\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 46:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.0274\n",
      "  Max: 142.9166\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 47:\n",
      "  Mean: 0.0000\n",
      "  Min: -80.5176\n",
      "  Max: 79.8578\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 48:\n",
      "  Mean: 0.0000\n",
      "  Min: -57.4688\n",
      "  Max: 57.4615\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 49:\n",
      "  Mean: 0.0000\n",
      "  Min: -0.0182\n",
      "  Max: 223.2545\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 50:\n",
      "  Mean: 0.0000\n",
      "  Min: -117.8208\n",
      "  Max: 117.5744\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 51:\n",
      "  Mean: -0.0000\n",
      "  Min: -87.9387\n",
      "  Max: 88.1077\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 52:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.0117\n",
      "  Max: 339.2351\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 53:\n",
      "  Mean: -0.0000\n",
      "  Min: -187.4638\n",
      "  Max: 191.8051\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 54:\n",
      "  Mean: 0.0000\n",
      "  Min: -139.8838\n",
      "  Max: 139.1267\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 55:\n",
      "  Mean: -0.0000\n",
      "  Min: -0.0071\n",
      "  Max: 297.2272\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 56:\n",
      "  Mean: 0.0000\n",
      "  Min: -324.9908\n",
      "  Max: 280.1775\n",
      "  Contains NaN: False\n",
      "\n",
      "Column 57:\n",
      "  Mean: -0.0000\n",
      "  Min: -220.9851\n",
      "  Max: 220.6210\n",
      "  Contains NaN: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_columns(arr):\n",
    "    # Check if the input array has 57 columns\n",
    "    if arr.shape[1] != 57:\n",
    "        raise ValueError(\"Input array must have 57 columns\")\n",
    "\n",
    "    for col in range(57):\n",
    "        column = arr[:, col]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_val = np.mean(column)\n",
    "        min_val = np.min(column)\n",
    "        max_val = np.max(column)\n",
    "        has_nan = np.isnan(column).any()\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Column {col + 1}:\")\n",
    "        print(f\"  Mean: {mean_val:.4f}\")\n",
    "        print(f\"  Min: {min_val:.4f}\")\n",
    "        print(f\"  Max: {max_val:.4f}\")\n",
    "        print(f\"  Contains NaN: {has_nan}\")\n",
    "        print()  # Empty line for readability\n",
    "analyze_columns(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd108b6-f2b4-4b39-9cee-ba8faa7bc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def Qmake_encoder_set_weights(input_dim,h_dim_1,h_dim_2,latent_dim):\n",
    "    l2_factor = 1e-3\n",
    "    inputs = keras.Input(shape=(input_dim))\n",
    "#     x = BatchNormalization(name=\"BN0\")(inputs)\n",
    "    x = Dense(h_dim_1,\n",
    "             kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "             bias_initializer=keras.initializers.Zeros(),\n",
    "             kernel_regularizer=l1_l2(l1=0, l2=l2_factor),\n",
    "             name = \"dense1\")(inputs)\n",
    "#     x = BatchNormalization(name=\"BN1\")(x)\n",
    "    x = ReLU(name=\"relu1\")(x)\n",
    "    x = Dense(h_dim_2,\n",
    "             kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "             bias_initializer=keras.initializers.Zeros(),\n",
    "             kernel_regularizer=l1_l2(l1=0, l2=l2_factor),\n",
    "             name = \"dense2\")(x)    \n",
    "#     x = BatchNormalization(name=\"BN2\")(x)\n",
    "    x = ReLU(name=\"relu2\")(x)\n",
    "    z_mean=Dense(latent_dim, name='z_mean',\n",
    "                  kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "                  bias_initializer=keras.initializers.Zeros(),\n",
    "                  kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(x)\n",
    "    z_logvar=Dense(latent_dim, name='z_log_var',\n",
    "                          kernel_initializer=keras.initializers.Zeros(),\n",
    "                          bias_initializer=keras.initializers.Zeros(),\n",
    "                          kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(x)\n",
    "    z=Sampling()([z_mean,z_logvar])\n",
    "    encoder = keras.Model(inputs,[z_mean,z_logvar,z],name='encoder')\n",
    "    return encoder\n",
    "\n",
    "def Qmake_decoder_set_weights(input_dim,h_dim_1,h_dim_2,latent_dim):\n",
    "    l2_factor = 1e-3\n",
    "    inputs=keras.Input(shape=(latent_dim))\n",
    "    x=layers.Dense(h_dim_2,\n",
    "                   activation='relu',\n",
    "                   kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "                   bias_initializer=keras.initializers.Zeros(),\n",
    "                   kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(inputs)\n",
    "    x=layers.Dense(h_dim_1,\n",
    "                   activation='relu',\n",
    "                   kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "                   bias_initializer=keras.initializers.Zeros(),\n",
    "                   kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(x)\n",
    "    z=layers.Dense(input_dim,\n",
    "                   kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "                   bias_initializer=keras.initializers.Zeros(),\n",
    "                   kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(x)\n",
    "    decoder=keras.Model(inputs,z,name='decoder')\n",
    "    return decoder\n",
    "\n",
    "def Qmake_discriminator(input_dim, h_dim_1, h_dim_2):\n",
    "    l2_factor = 1e-3\n",
    "    inputs = keras.Input(shape=(input_dim))\n",
    "    x = Dense(h_dim_1,\n",
    "              activation='relu',\n",
    "              kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "              bias_initializer=keras.initializers.Zeros(),\n",
    "              kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(inputs)\n",
    "    x = Dense(h_dim_2,\n",
    "              activation='relu',\n",
    "              kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "              bias_initializer=keras.initializers.Zeros(),\n",
    "              kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(x)\n",
    "    x = Dense(1,\n",
    "              activation='sigmoid',  # Output probability\n",
    "              kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "              bias_initializer=keras.initializers.Zeros(),\n",
    "              kernel_regularizer=l1_l2(l1=0, l2=l2_factor))(x)\n",
    "    discriminator = keras.Model(inputs, x, name='discriminator')\n",
    "    return discriminator\n",
    "\n",
    "\n",
    "def custom_mse_loss_with_multi_index_scaling(masked_data, masked_reconstruction):\n",
    "#     jet_scale = 256/64\n",
    "#     tau_scale = 128/64\n",
    "#     muon_scale = 32/64\n",
    "#     met_scale = 512/64\n",
    "#     em_scale = 128/64\n",
    "#   no scaling right now\n",
    "    jet_scale = 1\n",
    "    tau_scale = 1\n",
    "    muon_scale = 1\n",
    "    met_scale = 1\n",
    "    em_scale = 1\n",
    "    # Define the indices and their corresponding scale factors\n",
    "    scale_dict = {\n",
    "        0: met_scale,\n",
    "        3: em_scale, 6: em_scale, 9: em_scale, 12: em_scale,\n",
    "        15: tau_scale, 18: tau_scale, 21: tau_scale, 24: tau_scale,\n",
    "        27: jet_scale, 30: jet_scale, 33: jet_scale, 36: jet_scale, 39: jet_scale, 42: jet_scale,\n",
    "        45: muon_scale, 48: muon_scale, 51: muon_scale, 54: muon_scale\n",
    "    }\n",
    "\n",
    "    # Create the scaling tensor\n",
    "    scale_tensor = tf.ones_like(masked_data)\n",
    "    for index, factor in scale_dict.items():\n",
    "        index_mask = tf.one_hot(index, depth=tf.shape(masked_data)[-1])\n",
    "        scale_tensor += index_mask * (factor - 1)\n",
    "\n",
    "    # Apply scaling\n",
    "    scaled_data = masked_data * scale_tensor\n",
    "    scaled_reconstruction = masked_reconstruction * scale_tensor\n",
    "\n",
    "    # Hardcoded lists for eta and phi indices\n",
    "    eta_indices = [4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46, 49, 52, 55]\n",
    "    phi_indices = [2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47, 50, 53, 56]\n",
    "\n",
    "    batch_size = tf.shape(scaled_reconstruction)[0]\n",
    "    \n",
    "    # Set only the first eta (index 1) to zero\n",
    "    indices = tf.stack([tf.range(batch_size), tf.ones(batch_size, dtype=tf.int32)], axis=1)\n",
    "    updates = tf.zeros(batch_size)\n",
    "    scaled_reconstruction = tf.tensor_scatter_nd_update(scaled_reconstruction, indices, updates)\n",
    "    \n",
    "    # Apply constraints to eta\n",
    "    for i in eta_indices:\n",
    "        indices = tf.stack([tf.range(batch_size), tf.fill([batch_size], i)], axis=1)\n",
    "        updates = 3 * tf.tanh(scaled_reconstruction[:, i] / 3)\n",
    "        scaled_reconstruction = tf.tensor_scatter_nd_update(scaled_reconstruction, indices, updates)\n",
    "    \n",
    "    # Apply constraints to phi\n",
    "    for i in phi_indices:\n",
    "        indices = tf.stack([tf.range(batch_size), tf.fill([batch_size], i)], axis=1)\n",
    "        updates = 3.14159265258979 * tf.tanh(scaled_reconstruction[:, i] / 3.14159265258979)\n",
    "        scaled_reconstruction = tf.tensor_scatter_nd_update(scaled_reconstruction, indices, updates)\n",
    "        \n",
    "    # Calculate MSE using keras.losses.mse\n",
    "    mse = keras.losses.mse(scaled_data, scaled_reconstruction)\n",
    "\n",
    "    # Take the sum across all dimensions\n",
    "    return tf.reduce_sum(mse)\n",
    "\n",
    "class VAE_GAN_Model(keras.Model):\n",
    "    def __init__(self, encoder, decoder, discriminator, steps_per_epoch=3125, \n",
    "                cycle_length=10, min_beta=0.1, max_beta=0.85, gamma = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.discriminator = discriminator\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.beta_tracker = keras.metrics.Mean(name=\"beta\")\n",
    "        # self.grad_tracker = keras.metrics.Mean(name=\"grad\")\n",
    "        self.discriminator_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "        self.gamma = tf.Variable(gamma, dtype=tf.float32)\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.cycle_length = tf.cast(cycle_length, tf.float32)\n",
    "        self.min_beta = tf.cast(min_beta, tf.float32)\n",
    "        self.max_beta = tf.cast(max_beta, tf.float32)\n",
    "        self.beta = tf.Variable(min_beta, dtype=tf.float32)\n",
    "\n",
    "    def compile(self, optimizer, **kwargs):\n",
    "        super(VAE_GAN_Model, self).compile(**kwargs)\n",
    "        # Set the optimizer for the entire model (encoder + decoder + discriminator)\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        # Collect trainable variables from encoder, decoder, and discriminator\n",
    "        trainable_variables = (\n",
    "            self.encoder.trainable_weights + \n",
    "            self.decoder.trainable_weights + \n",
    "            self.discriminator.trainable_weights\n",
    "        )\n",
    "        # Build the optimizer with the full variable list\n",
    "        self.optimizer.build(trainable_variables)\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.discriminator_loss_tracker,\n",
    "            self.beta_tracker,\n",
    "            # self.grad_tracker\n",
    "        ]\n",
    "\n",
    "    def cyclical_annealing_beta(self, epoch):\n",
    "        cycle = tf.floor(1.0 + epoch / self.cycle_length)\n",
    "        x = tf.abs(epoch / self.cycle_length - cycle + 1)\n",
    "        return self.min_beta + (self.max_beta - self.min_beta) * tf.minimum(x, 1.0)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Get the current epoch number\n",
    "        epoch = tf.cast(self.optimizer.iterations / self.steps_per_epoch, tf.float32)\n",
    "        \n",
    "        # Update beta\n",
    "        self.beta.assign(self.cyclical_annealing_beta(epoch))\n",
    "\n",
    "        # ---------------------------\n",
    "        # Train the Discriminator\n",
    "        # ---------------------------\n",
    "        with tf.GradientTape() as tape_disc:\n",
    "            # Generate reconstructed data\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            \n",
    "            # Get discriminator predictions\n",
    "            real_output = self.discriminator(data)\n",
    "            fake_output = self.discriminator(reconstruction)\n",
    "            \n",
    "            # Labels for real and fake data\n",
    "            real_labels = tf.ones_like(real_output)\n",
    "            fake_labels = tf.zeros_like(fake_output)\n",
    "            \n",
    "            # Discriminator loss\n",
    "            d_loss_real = keras.losses.binary_crossentropy(real_labels, real_output)\n",
    "            d_loss_fake = keras.losses.binary_crossentropy(fake_labels, fake_output)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss = tf.reduce_mean(d_loss)\n",
    "        \n",
    "        grads_disc = tape_disc.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads_disc, self.discriminator.trainable_weights))\n",
    "        \n",
    "        # ---------------------------\n",
    "        # Train the VAE (Generator)\n",
    "        # ---------------------------\n",
    "        with tf.GradientTape() as tape_vae:\n",
    "            # Forward pass\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            \n",
    "            # Reconstruction loss\n",
    "            mask = K.cast(K.not_equal(data, 0), K.floatx())\n",
    "            reconstruction_loss = custom_mse_loss_with_multi_index_scaling(mask * data, mask * reconstruction)\n",
    "            reconstruction_loss *= (1 - self.beta)\n",
    "            \n",
    "            # KL divergence loss\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= self.beta\n",
    "            \n",
    "            # Generator (VAE) wants to fool the discriminator\n",
    "            fake_output = self.discriminator(reconstruction)\n",
    "            valid_labels = tf.ones_like(fake_output)  # Try to make discriminator think reconstructions are real\n",
    "            g_loss_adv = keras.losses.binary_crossentropy(valid_labels, fake_output)\n",
    "            g_loss_adv = tf.reduce_mean(g_loss_adv)\n",
    "            g_loss_adv *= self.gamma  # Weight by gamma\n",
    "            \n",
    "            # Total VAE loss\n",
    "            total_loss = reconstruction_loss + kl_loss + g_loss_adv\n",
    "        \n",
    "        grads_vae = tape_vae.gradient(total_loss, self.encoder.trainable_weights + self.decoder.trainable_weights)\n",
    "        # grads_vae, global_norm = tf.clip_by_global_norm(grads_vae, 1000.0)  # gradient global_norm ~2000 \n",
    "        self.optimizer.apply_gradients(zip(grads_vae, self.encoder.trainable_weights + self.decoder.trainable_weights))\n",
    "\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.discriminator_loss_tracker.update_state(d_loss)\n",
    "        # self.grad_tracker.update_state(global_norm)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reco_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"disc_loss\": self.discriminator_loss_tracker.result(),\n",
    "            # \"grad\": self.grad_tracker.result(),\n",
    "            \"beta\": self.beta,\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Forward pass\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        \n",
    "        # Reconstruction loss\n",
    "        mask = K.cast(K.not_equal(data, 0), K.floatx())\n",
    "        reconstruction_loss = custom_mse_loss_with_multi_index_scaling(mask * data, mask * reconstruction)\n",
    "        reconstruction_loss *= (1 - self.beta)\n",
    "        \n",
    "        # KL divergence loss\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        kl_loss *= self.beta\n",
    "        \n",
    "        # Discriminator loss (only for monitoring)\n",
    "        # pass both data and reconstruction through D to get generator adversarial loss\n",
    "        real_output = self.discriminator(data)\n",
    "        fake_output = self.discriminator(reconstruction)\n",
    "        real_labels = tf.ones_like(real_output)\n",
    "        fake_labels = tf.zeros_like(fake_output)\n",
    "        d_loss_real = keras.losses.binary_crossentropy(real_labels, real_output)\n",
    "        d_loss_fake = keras.losses.binary_crossentropy(fake_labels, fake_output)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss = tf.reduce_mean(d_loss)\n",
    "        \n",
    "        # Generator adversarial loss\n",
    "        valid_labels = tf.ones_like(fake_output)\n",
    "        g_loss_adv = keras.losses.binary_crossentropy(valid_labels, fake_output)\n",
    "        g_loss_adv = tf.reduce_mean(g_loss_adv)\n",
    "        g_loss_adv *= self.gamma\n",
    "        \n",
    "        # Total VAE loss\n",
    "        total_loss = reconstruction_loss + kl_loss + g_loss_adv\n",
    "        \n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reco_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "            \"disc_loss\": d_loss,\n",
    "            \"beta\": self.beta_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def call(self, data):\n",
    "        z_mean,z_log_var,x = self.encoder(data)\n",
    "        reconstruction = self.decoder(x)\n",
    "        return {\n",
    "            \"z_mean\": z_mean,\n",
    "            \"z_log_var\": z_log_var,\n",
    "            \"reconstruction\": reconstruction\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ffb0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse(y_true, y_pred, sample_weight):\n",
    "    return tf.reduce_mean(tf.multiply(sample_weight, tf.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc8cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50 # 100\n",
    "BATCH_SIZE = 1024\n",
    "STOP_PATIENCE = 15\n",
    "LR_PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306b66b6-96f3-4e7d-ac72-d24cd1002dea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 01:00:39.505457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-10-15 01:00:39.508470: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-10-15 01:00:39.510080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sdfiana005): /proc/driver/nvidia/version does not exist\n",
      "2024-10-15 01:00:39.520882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 57)]         0           []                               \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 32)           1856        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " relu1 (ReLU)                   (None, 32)           0           ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 16)           528         ['relu1[0][0]']                  \n",
      "                                                                                                  \n",
      " relu2 (ReLU)                   (None, 16)           0           ['dense2[0][0]']                 \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 3)            51          ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 3)            51          ['relu2[0][0]']                  \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 3)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,486\n",
      "Trainable params: 2,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                64        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 57)                1881      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,489\n",
      "Trainable params: 2,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 57)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                1856      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,401\n",
      "Trainable params: 2,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_dim = X_train.shape[1]\n",
    "h_dim_1 = 32\n",
    "h_dim_2 = 16\n",
    "latent_dim = 3\n",
    "gamma = 1.0 \n",
    "\n",
    "T2A_enc = Qmake_encoder_set_weights(X_train.shape[1], h_dim_1, h_dim_2, latent_dim)\n",
    "T2A_dec = Qmake_decoder_set_weights(X_train.shape[1], h_dim_1, h_dim_2, latent_dim)\n",
    "T2A_discriminator = Qmake_discriminator(input_dim, h_dim_1, h_dim_2)\n",
    "\n",
    "steps_per_epoch = X_train.shape[0] // BATCH_SIZE\n",
    "T2A = VAE_GAN_Model(T2A_enc, T2A_dec, T2A_discriminator, steps_per_epoch=steps_per_epoch, cycle_length=10, min_beta=0.1, max_beta=0.8)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "T2A.compile(optimizer=opt,weighted_metrics=[weighted_mse]) #,weighted_metrics=[weighted_mse]\n",
    "\n",
    "T2A_enc.summary()\n",
    "T2A_dec.summary()\n",
    "T2A_discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbfc6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit model & save weights\n",
    "\n",
    "early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=LR_PATIENCE, verbose=1)\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "history = T2A.fit(x=X_train, validation_split=0.2, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks, shuffle=True)\n",
    "T2A.save_weights(filepath=home_path+'software_dev/trained_models/toyVAE/', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(history.history['val_loss'])  # Best epoch index based on validation loss\n",
    "\n",
    "# Access the best metrics\n",
    "best_val_loss = history.history['val_loss'][best_epoch]\n",
    "best_loss = history.history['loss'][best_epoch]\n",
    "print(f\"Best epoch: {best_epoch}\") \n",
    "print(f\"Best training loss: {best_loss}\")\n",
    "print(f\"Best validation loss: {best_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c0fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_values = np.array([0.01, 0.1, 1.0, 10.0, 100.0, 1000.0])  # List of gamma values to try\n",
    "iters = 8\n",
    "loss_arr = np.zeros((6, iters))\n",
    "reco_loss_arr = np.zeros((6, iters))\n",
    "models_array = np.empty((6, iters), dtype=object)\n",
    "history_array = np.empty((6, iters), dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8630637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with gamma = 0.01\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 52s 19ms/step - loss: 814.0239 - reco_loss: 813.1270 - kl_loss: 1.5060 - disc_loss: 0.2474 - beta: 0.2120 - val_loss: 630.6161 - val_reco_loss: 628.7170 - val_kl_loss: 1.8211 - val_disc_loss: 0.0056 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 550.9824 - reco_loss: 548.1577 - kl_loss: 2.8838 - disc_loss: 0.0048 - beta: 0.3240 - val_loss: 501.1181 - val_reco_loss: 498.6863 - val_kl_loss: 2.3387 - val_disc_loss: 9.6530e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 412.8779 - reco_loss: 409.6810 - kl_loss: 3.2723 - disc_loss: 0.0019 - beta: 0.4360 - val_loss: 415.0770 - val_reco_loss: 412.1175 - val_kl_loss: 2.8551 - val_disc_loss: 3.8068e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 333.3246 - reco_loss: 329.7289 - kl_loss: 3.5811 - disc_loss: 9.6055e-04 - beta: 0.5480 - val_loss: 337.3490 - val_reco_loss: 333.9623 - val_kl_loss: 3.2691 - val_disc_loss: 1.0339e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 268.6082 - reco_loss: 264.7794 - kl_loss: 3.7435 - disc_loss: 7.6991e-04 - beta: 0.6600 - val_loss: 260.3427 - val_reco_loss: 256.6822 - val_kl_loss: 3.5457 - val_disc_loss: 1.9364e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 196.7913 - reco_loss: 192.9072 - kl_loss: 3.7520 - disc_loss: 2.6123e-04 - beta: 0.7720 - val_loss: 174.0435 - val_reco_loss: 170.1173 - val_kl_loss: 3.7943 - val_disc_loss: 1.6465e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 299.2661 - reco_loss: 296.5863 - kl_loss: 1.6271 - disc_loss: 7.4691e-04 - beta: 0.1840 - val_loss: 608.1517 - val_reco_loss: 606.7923 - val_kl_loss: 1.2210 - val_disc_loss: 2.8546e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 464.3992 - reco_loss: 462.8830 - kl_loss: 1.5513 - disc_loss: 6.6226e-04 - beta: 0.2960 - val_loss: 532.5963 - val_reco_loss: 530.6890 - val_kl_loss: 1.7548 - val_disc_loss: 1.1258e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 398.5158 - reco_loss: 396.3869 - kl_loss: 2.1797 - disc_loss: 2.5681e-04 - beta: 0.4080 - val_loss: 430.7148 - val_reco_loss: 428.1489 - val_kl_loss: 2.4234 - val_disc_loss: 2.5125e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 342.6238 - reco_loss: 339.9011 - kl_loss: 2.6969 - disc_loss: 2.5714e-04 - beta: 0.5200 - val_loss: 359.3802 - val_reco_loss: 356.4905 - val_kl_loss: 2.7529 - val_disc_loss: 5.7353e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 263.4749 - reco_loss: 260.3371 - kl_loss: 3.1078 - disc_loss: 2.7996e-04 - beta: 0.6320 - val_loss: 277.2029 - val_reco_loss: 273.8907 - val_kl_loss: 3.1624 - val_disc_loss: 2.7381e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 201.4044 - reco_loss: 197.9133 - kl_loss: 3.3881 - disc_loss: 2.3306e-04 - beta: 0.7440 - val_loss: 190.8609 - val_reco_loss: 187.2518 - val_kl_loss: 3.4719 - val_disc_loss: 4.2062e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 388.2567 - reco_loss: 384.2349 - kl_loss: 2.7747 - disc_loss: 3.7609e-04 - beta: 0.1560 - val_loss: 619.1362 - val_reco_loss: 617.9924 - val_kl_loss: 0.9662 - val_disc_loss: 3.2420e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 473.7280 - reco_loss: 472.3980 - kl_loss: 1.2778 - disc_loss: 4.3952e-04 - beta: 0.2680 - val_loss: 533.3801 - val_reco_loss: 531.6351 - val_kl_loss: 1.5678 - val_disc_loss: 1.9766e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 437.4966 - reco_loss: 435.5468 - kl_loss: 1.8623 - disc_loss: 1.0594e-04 - beta: 0.3800 - val_loss: 449.9768 - val_reco_loss: 447.6743 - val_kl_loss: 2.1227 - val_disc_loss: 9.5028e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 349.0086 - reco_loss: 346.5162 - kl_loss: 2.3973 - disc_loss: 2.7283e-04 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 348.9964 - reco_loss: 346.5039 - kl_loss: 2.3973 - disc_loss: 2.7289e-04 - beta: 0.4920 - val_loss: 372.9384 - val_reco_loss: 370.0699 - val_kl_loss: 2.6961 - val_disc_loss: 1.5206e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 273.1794 - reco_loss: 270.2245 - kl_loss: 2.8584 - disc_loss: 7.8493e-05 - beta: 0.6040 - val_loss: 289.7462 - val_reco_loss: 286.4297 - val_kl_loss: 3.1400 - val_disc_loss: 4.6583e-06 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 213.9701 - reco_loss: 210.6434 - kl_loss: 3.2316 - disc_loss: 1.3587e-04 - beta: 0.7160 - val_loss: 210.2066 - val_reco_loss: 206.6199 - val_kl_loss: 3.4260 - val_disc_loss: 1.7798e-05 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 163.1698 - reco_loss: 159.6740 - kl_loss: 2.7558 - disc_loss: 3.0161e-04 - beta: 0.1280 - val_loss: 644.1782 - val_reco_loss: 643.2027 - val_kl_loss: 0.7722 - val_disc_loss: 1.0671e-05 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 480.5187 - reco_loss: 479.3620 - kl_loss: 1.1042 - disc_loss: 6.3122e-04 - beta: 0.2400 - val_loss: 563.0809 - val_reco_loss: 561.4586 - val_kl_loss: 1.4331 - val_disc_loss: 1.1385e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 429.9555 - reco_loss: 428.1824 - kl_loss: 1.6931 - disc_loss: 4.1300e-05 - beta: 0.3520 - val_loss: 475.4231 - val_reco_loss: 473.2032 - val_kl_loss: 2.0351 - val_disc_loss: 1.3201e-05 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.01\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 51s 18ms/step - loss: 919.4905 - reco_loss: 918.5063 - kl_loss: 1.7227 - disc_loss: 0.2016 - beta: 0.2120 - val_loss: 768.5978 - val_reco_loss: 764.9053 - val_kl_loss: 3.6214 - val_disc_loss: 0.0077 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 577.0583 - reco_loss: 574.1650 - kl_loss: 2.8417 - disc_loss: 0.0086 - beta: 0.3240 - val_loss: 583.3263 - val_reco_loss: 580.0386 - val_kl_loss: 3.2029 - val_disc_loss: 0.0048 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 455.1370 - reco_loss: 452.0364 - kl_loss: 3.0164 - disc_loss: 0.0049 - beta: 0.4360 - val_loss: 452.6380 - val_reco_loss: 448.7559 - val_kl_loss: 3.7947 - val_disc_loss: 0.0117 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 359.9028 - reco_loss: 356.4207 - kl_loss: 3.4562 - disc_loss: 0.0044 - beta: 0.5480 - val_loss: 333.6266 - val_reco_loss: 328.9753 - val_kl_loss: 4.5552 - val_disc_loss: 0.0020 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 261.1869 - reco_loss: 257.4022 - kl_loss: 3.8732 - disc_loss: 0.0034 - beta: 0.6600 - val_loss: 242.8269 - val_reco_loss: 238.1209 - val_kl_loss: 4.6008 - val_disc_loss: 0.0010 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 196.0119 - reco_loss: 191.9415 - kl_loss: 3.9425 - disc_loss: 0.0028 - beta: 0.7720 - val_loss: 167.2576 - val_reco_loss: 162.3409 - val_kl_loss: 4.8074 - val_disc_loss: 4.7549e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 308.7066 - reco_loss: 305.8544 - kl_loss: 1.6991 - disc_loss: 0.0032 - beta: 0.1840 - val_loss: 577.5434 - val_reco_loss: 575.9060 - val_kl_loss: 1.5106 - val_disc_loss: 9.5144e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 501.7518 - reco_loss: 500.1026 - kl_loss: 1.6702 - disc_loss: 0.0014 - beta: 0.2960 - val_loss: 485.5146 - val_reco_loss: 482.8755 - val_kl_loss: 2.5099 - val_disc_loss: 1.6709e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 427.4758 - reco_loss: 424.9376 - kl_loss: 2.4137 - disc_loss: 8.2268e-04 - beta: 0.4080 - val_loss: 409.3371 - val_reco_loss: 405.9219 - val_kl_loss: 3.2677 - val_disc_loss: 1.4063e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 353.9102 - reco_loss: 350.7731 - kl_loss: 3.0433 - disc_loss: 0.0016 - beta: 0.5200 - val_loss: 329.9860 - val_reco_loss: 325.8745 - val_kl_loss: 3.9627 - val_disc_loss: 2.6167e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 266.4868 - reco_loss: 263.0691 - kl_loss: 3.4760 - disc_loss: 0.0018 - beta: 0.6320 - val_loss: 253.6160 - val_reco_loss: 248.9516 - val_kl_loss: 4.5298 - val_disc_loss: 1.0524e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 224.0429 - reco_loss: 220.1912 - kl_loss: 3.6718 - disc_loss: 0.0023 - beta: 0.7440 - val_loss: 178.8381 - val_reco_loss: 174.0845 - val_kl_loss: 4.5968 - val_disc_loss: 1.4910e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 2405176520320.0312 - reco_loss: 2299123968917.0166 - kl_loss: 37027491840.0000 - disc_loss: 0.0039 - beta: 0.1560 - val_loss: 591.3806 - val_reco_loss: 589.9407 - val_kl_loss: 1.2626 - val_disc_loss: 9.6268e-06 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 491.2816 - reco_loss: 489.9207 - kl_loss: 1.3838 - disc_loss: 4.7394e-04 - beta: 0.2680 - val_loss: 494.5868 - val_reco_loss: 492.2879 - val_kl_loss: 2.1248 - val_disc_loss: 2.1329e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 10679621516155.2422 - reco_loss: 10642459358850.3691 - kl_loss: 1101752565760.0000 - disc_loss: 4.9480 - beta: 0.3800 - val_loss: 429.2960 - val_reco_loss: 426.1319 - val_kl_loss: 2.9701 - val_disc_loss: 6.9423e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 590850135903071633408.0000 - reco_loss: 589466327959667736576.0000 - kl_loss: 2083508151620993024.0000 - disc_loss: 0.0018 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 591088766109379723264.0000 - reco_loss: 589704399272910585856.0000 - kl_loss: 2082674721807138816.0000 - disc_loss: 0.0018 - beta: 0.4920 - val_loss: 360.6704 - val_reco_loss: 356.8214 - val_kl_loss: 3.7375 - val_disc_loss: 0.0467 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 3464670754.1315 - reco_loss: 3443307687.8809 - kl_loss: 13003024.0000 - disc_loss: 0.0061 - beta: 0.6040 - val_loss: 277.6809 - val_reco_loss: 273.1874 - val_kl_loss: 4.3381 - val_disc_loss: 8.9616e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 205695.1524 - reco_loss: 203385.2895 - kl_loss: 5440.4062 - disc_loss: 0.0035 - beta: 0.7160 - val_loss: 207.4752 - val_reco_loss: 202.4706 - val_kl_loss: 4.8570 - val_disc_loss: 0.0185 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 169.0597 - reco_loss: 165.1481 - kl_loss: 3.1149 - disc_loss: 0.0085 - beta: 0.1280 - val_loss: 618.9027 - val_reco_loss: 617.6934 - val_kl_loss: 1.0148 - val_disc_loss: 5.3748e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 502.3663 - reco_loss: 501.1217 - kl_loss: 1.2329 - disc_loss: 0.0014 - beta: 0.2400 - val_loss: 548.6103 - val_reco_loss: 546.4740 - val_kl_loss: 1.9608 - val_disc_loss: 3.9273e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 437.7459 - reco_loss: 435.7277 - kl_loss: 1.9281 - disc_loss: 3.2154e-04 - beta: 0.3520 - val_loss: 452.0665 - val_reco_loss: 449.0988 - val_kl_loss: 2.7929 - val_disc_loss: 1.1301e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.01\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 55s 20ms/step - loss: 778.1642 - reco_loss: 776.9034 - kl_loss: 2.0905 - disc_loss: 0.2041 - beta: 0.2120 - val_loss: 760.4953 - val_reco_loss: 756.4075 - val_kl_loss: 4.0071 - val_disc_loss: 0.0044 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 501.9728 - reco_loss: 498.6782 - kl_loss: 3.3995 - disc_loss: 0.0057 - beta: 0.3240 - val_loss: 603.4662 - val_reco_loss: 598.5989 - val_kl_loss: 4.7703 - val_disc_loss: 0.0027 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 437.4815 - reco_loss: 433.8865 - kl_loss: 3.6028 - disc_loss: 0.0041 - beta: 0.4360 - val_loss: 459.9107 - val_reco_loss: 453.8110 - val_kl_loss: 5.9698 - val_disc_loss: 0.0016 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 383.2789 - reco_loss: 379.2844 - kl_loss: 3.8162 - disc_loss: 0.0024 - beta: 0.5480 - val_loss: 380.2985 - val_reco_loss: 374.6513 - val_kl_loss: 5.5280 - val_disc_loss: 9.0422e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 289.5105 - reco_loss: 285.4118 - kl_loss: 3.9059 - disc_loss: 0.0013 - beta: 0.6600 - val_loss: 297.7107 - val_reco_loss: 292.5403 - val_kl_loss: 5.0160 - val_disc_loss: 2.7517e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 203.8625 - reco_loss: 199.7238 - kl_loss: 3.9864 - disc_loss: 0.0020 - beta: 0.7720 - val_loss: 189.1796 - val_reco_loss: 184.0160 - val_kl_loss: 4.9921 - val_disc_loss: 3.1029e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 313.4100 - reco_loss: 310.5729 - kl_loss: 1.7267 - disc_loss: 0.0029 - beta: 0.1840 - val_loss: 613.6258 - val_reco_loss: 611.6666 - val_kl_loss: 1.7486 - val_disc_loss: 2.4825e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 450.9435 - reco_loss: 449.2882 - kl_loss: 1.7457 - disc_loss: 0.0010 - beta: 0.2960 - val_loss: 511.2042 - val_reco_loss: 508.0105 - val_kl_loss: 2.9984 - val_disc_loss: 1.0538e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 402.1845 - reco_loss: 399.7096 - kl_loss: 2.4731 - disc_loss: 8.7447e-04 - beta: 0.4080 - val_loss: 426.7740 - val_reco_loss: 422.6734 - val_kl_loss: 3.8976 - val_disc_loss: 0.0019 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 359.9959 - reco_loss: 356.9064 - kl_loss: 3.0637 - disc_loss: 0.0011 - beta: 0.5200 - val_loss: 346.6815 - val_reco_loss: 341.8605 - val_kl_loss: 4.5750 - val_disc_loss: 2.2924e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 286.5154 - reco_loss: 282.9445 - kl_loss: 3.4348 - disc_loss: 0.0029 - beta: 0.6320 - val_loss: 262.8072 - val_reco_loss: 257.7435 - val_kl_loss: 4.8638 - val_disc_loss: 9.1007e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 278.6679 - reco_loss: 239.9253 - kl_loss: 67.0512 - disc_loss: 0.0076 - beta: 0.7440 - val_loss: 191.2585 - val_reco_loss: 186.1413 - val_kl_loss: 4.9047 - val_disc_loss: 9.8252e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 31121733.7244 - reco_loss: 31041612.8411 - kl_loss: 93810.1875 - disc_loss: 0.0099 - beta: 0.1560 - val_loss: 600.9348 - val_reco_loss: 599.3266 - val_kl_loss: 1.3299 - val_disc_loss: 0.0014 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 474.3307 - reco_loss: 472.9003 - kl_loss: 1.3996 - disc_loss: 0.0017 - beta: 0.2680 - val_loss: 507.5432 - val_reco_loss: 504.8914 - val_kl_loss: 2.3873 - val_disc_loss: 0.0010 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 414.8527 - reco_loss: 412.7505 - kl_loss: 2.0430 - disc_loss: 0.0021 - beta: 0.3800 - val_loss: 425.4586 - val_reco_loss: 421.8008 - val_kl_loss: 3.3893 - val_disc_loss: 2.3624e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 352.6548 - reco_loss: 349.8935 - kl_loss: 2.6928 - disc_loss: 0.0017 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 352.6366 - reco_loss: 349.8752 - kl_loss: 2.6926 - disc_loss: 0.0017 - beta: 0.4920 - val_loss: 362.0811 - val_reco_loss: 357.7158 - val_kl_loss: 4.0635 - val_disc_loss: 4.8232e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 292.5406 - reco_loss: 289.2813 - kl_loss: 3.1825 - disc_loss: 0.0022 - beta: 0.6040 - val_loss: 276.2337 - val_reco_loss: 270.9990 - val_kl_loss: 4.9418 - val_disc_loss: 0.0052 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 220.9681 - reco_loss: 217.2416 - kl_loss: 3.6255 - disc_loss: 0.0046 - beta: 0.7160 - val_loss: 202.3441 - val_reco_loss: 196.7078 - val_kl_loss: 5.3243 - val_disc_loss: 0.0011 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 164.6655 - reco_loss: 160.7449 - kl_loss: 3.0516 - disc_loss: 0.0160 - beta: 0.1280 - val_loss: 596.1429 - val_reco_loss: 594.6644 - val_kl_loss: 1.1529 - val_disc_loss: 5.4910e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 492.7278 - reco_loss: 491.4351 - kl_loss: 1.2227 - disc_loss: 0.0011 - beta: 0.2400 - val_loss: 517.0540 - val_reco_loss: 514.5370 - val_kl_loss: 2.1904 - val_disc_loss: 2.1735e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 428.9034 - reco_loss: 426.9037 - kl_loss: 1.8928 - disc_loss: 4.2618e-04 - beta: 0.3520 - val_loss: 445.0746 - val_reco_loss: 441.6096 - val_kl_loss: 3.1308 - val_disc_loss: 0.0011 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.01\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 54s 19ms/step - loss: 959.0135 - reco_loss: 958.5122 - kl_loss: 0.8801 - disc_loss: 0.1572 - beta: 0.2120 - val_loss: 694.4014 - val_reco_loss: 692.8648 - val_kl_loss: 1.4622 - val_disc_loss: 0.0144 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 557.3944 - reco_loss: 555.5766 - kl_loss: 1.9242 - disc_loss: 0.0140 - beta: 0.3240 - val_loss: 533.5963 - val_reco_loss: 531.0567 - val_kl_loss: 2.4420 - val_disc_loss: 0.0042 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 461.2930 - reco_loss: 458.6856 - kl_loss: 2.6334 - disc_loss: 0.0063 - beta: 0.4360 - val_loss: 437.2326 - val_reco_loss: 433.8400 - val_kl_loss: 3.2883 - val_disc_loss: 0.0019 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 347.0026 - reco_loss: 343.8885 - kl_loss: 3.1425 - disc_loss: 0.0048 - beta: 0.5480 - val_loss: 347.8969 - val_reco_loss: 343.7278 - val_kl_loss: 4.0495 - val_disc_loss: 0.0128 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 273.5285 - reco_loss: 269.8510 - kl_loss: 3.5578 - disc_loss: 0.0093 - beta: 0.6600 - val_loss: 251.8459 - val_reco_loss: 247.1448 - val_kl_loss: 4.5815 - val_disc_loss: 0.0175 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 200.6712 - reco_loss: 196.6258 - kl_loss: 9.3439 - disc_loss: 0.0056 - beta: 0.7720 - val_loss: 174.4955 - val_reco_loss: 169.5580 - val_kl_loss: 4.7632 - val_disc_loss: 0.0067 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 291.1078 - reco_loss: 288.3650 - kl_loss: 1.6569 - disc_loss: 0.0066 - beta: 0.1840 - val_loss: 595.8094 - val_reco_loss: 594.1776 - val_kl_loss: 1.4675 - val_disc_loss: 5.9748e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 463.3738 - reco_loss: 461.8315 - kl_loss: 1.5625 - disc_loss: 0.0010 - beta: 0.2960 - val_loss: 505.4529 - val_reco_loss: 502.9673 - val_kl_loss: 2.2784 - val_disc_loss: 0.0013 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 412.2622 - reco_loss: 410.0541 - kl_loss: 2.1845 - disc_loss: 7.7815e-04 - beta: 0.4080 - val_loss: 439.6549 - val_reco_loss: 436.4101 - val_kl_loss: 3.0407 - val_disc_loss: 7.6090e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 342.8715 - reco_loss: 340.1168 - kl_loss: 2.7066 - disc_loss: 0.0024 - beta: 0.5200 - val_loss: 343.7846 - val_reco_loss: 340.0023 - val_kl_loss: 3.6173 - val_disc_loss: 0.0052 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 43267.9435 - reco_loss: 43043.7471 - kl_loss: 724.9430 - disc_loss: 0.0020 - beta: 0.6320 - val_loss: 263.3827 - val_reco_loss: 259.2608 - val_kl_loss: 3.9170 - val_disc_loss: 0.0018 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 214.5017 - reco_loss: 210.8372 - kl_loss: 3.5267 - disc_loss: 0.0028 - beta: 0.7440 - val_loss: 186.4048 - val_reco_loss: 181.7144 - val_kl_loss: 4.5081 - val_disc_loss: 0.0042 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 213.5372 - reco_loss: 210.0935 - kl_loss: 2.2070 - disc_loss: 0.0068 - beta: 0.1560 - val_loss: 594.0540 - val_reco_loss: 592.7186 - val_kl_loss: 1.1205 - val_disc_loss: 0.0025 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 481.6552 - reco_loss: 480.2896 - kl_loss: 1.3096 - disc_loss: 9.1950e-04 - beta: 0.2680 - val_loss: 507.2010 - val_reco_loss: 505.1281 - val_kl_loss: 1.8564 - val_disc_loss: 9.5674e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 415.3649 - reco_loss: 413.2022 - kl_loss: 2.5719 - disc_loss: 0.0012 - beta: 0.3800 - val_loss: 441.9819 - val_reco_loss: 439.2444 - val_kl_loss: 2.5137 - val_disc_loss: 8.3379e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 352.3574 - reco_loss: 349.7980 - kl_loss: 2.4987 - disc_loss: 9.4566e-04 - beta: 0.4918\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 352.3342 - reco_loss: 349.7746 - kl_loss: 2.4991 - disc_loss: 9.4570e-04 - beta: 0.4920 - val_loss: 369.1593 - val_reco_loss: 365.7967 - val_kl_loss: 3.1335 - val_disc_loss: 7.1862e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 16030949.5944 - reco_loss: 13748590.2669 - kl_loss: 1440236.0000 - disc_loss: 7.1017e-04 - beta: 0.6040 - val_loss: 285.5005 - val_reco_loss: 281.5623 - val_kl_loss: 3.7327 - val_disc_loss: 3.6700e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 219.7565 - reco_loss: 216.1683 - kl_loss: 3.4338 - disc_loss: 0.0018 - beta: 0.7160 - val_loss: 203.8268 - val_reco_loss: 199.4089 - val_kl_loss: 4.2008 - val_disc_loss: 0.0031 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 168.9732 - reco_loss: 165.2803 - kl_loss: 2.9204 - disc_loss: 0.0056 - beta: 0.1280 - val_loss: 610.7052 - val_reco_loss: 609.5197 - val_kl_loss: 0.9257 - val_disc_loss: 4.1969e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 501.4591 - reco_loss: 500.2216 - kl_loss: 1.1602 - disc_loss: 6.3211e-04 - beta: 0.2400 - val_loss: 536.4211 - val_reco_loss: 534.4327 - val_kl_loss: 1.7133 - val_disc_loss: 5.2399e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 416.3506 - reco_loss: 414.4615 - kl_loss: 1.8055 - disc_loss: 3.0645e-04 - beta: 0.3520 - val_loss: 459.4052 - val_reco_loss: 456.6468 - val_kl_loss: 2.4794 - val_disc_loss: 1.6107e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.01\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 50s 18ms/step - loss: 835.2275 - reco_loss: 834.7871 - kl_loss: 0.7628 - disc_loss: 0.2180 - beta: 0.2120 - val_loss: 667.5522 - val_reco_loss: 665.8461 - val_kl_loss: 1.6273 - val_disc_loss: 0.0052 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 550.3397 - reco_loss: 548.6617 - kl_loss: 1.7896 - disc_loss: 0.0063 - beta: 0.3240 - val_loss: 507.5045 - val_reco_loss: 504.9193 - val_kl_loss: 2.4824 - val_disc_loss: 9.2674e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 418.8178 - reco_loss: 416.4326 - kl_loss: 2.4731 - disc_loss: 0.0016 - beta: 0.4360 - val_loss: 419.6788 - val_reco_loss: 416.3768 - val_kl_loss: 3.1855 - val_disc_loss: 4.7504e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 347.9221 - reco_loss: 344.9324 - kl_loss: 3.0644 - disc_loss: 9.4474e-04 - beta: 0.5480 - val_loss: 337.1878 - val_reco_loss: 333.4426 - val_kl_loss: 3.6038 - val_disc_loss: 8.9072e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 268.2184 - reco_loss: 264.6732 - kl_loss: 3.4785 - disc_loss: 5.3581e-04 - beta: 0.6600 - val_loss: 264.2140 - val_reco_loss: 260.0003 - val_kl_loss: 4.0609 - val_disc_loss: 2.3185e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 193.4028 - reco_loss: 189.5382 - kl_loss: 3.6845 - disc_loss: 5.6566e-04 - beta: 0.7720 - val_loss: 178.6814 - val_reco_loss: 174.3454 - val_kl_loss: 4.1897 - val_disc_loss: 3.0237e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 287.7773 - reco_loss: 284.9801 - kl_loss: 1.6462 - disc_loss: 2.8749e-04 - beta: 0.1840 - val_loss: 606.2177 - val_reco_loss: 604.8193 - val_kl_loss: 1.2551 - val_disc_loss: 1.2988e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 501.4488 - reco_loss: 499.9717 - kl_loss: 1.5068 - disc_loss: 3.5242e-04 - beta: 0.2960 - val_loss: 519.3527 - val_reco_loss: 517.2903 - val_kl_loss: 1.9008 - val_disc_loss: 1.6095e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 394.8914 - reco_loss: 392.7532 - kl_loss: 2.1078 - disc_loss: 1.8518e-04 - beta: 0.4080 - val_loss: 451.0984 - val_reco_loss: 448.4405 - val_kl_loss: 2.4955 - val_disc_loss: 6.2938e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 333.1128 - reco_loss: 330.4744 - kl_loss: 2.6234 - disc_loss: 2.3140e-04 - beta: 0.5200 - val_loss: 366.7843 - val_reco_loss: 363.7172 - val_kl_loss: 2.8705 - val_disc_loss: 4.3398e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 271.0107 - reco_loss: 267.8767 - kl_loss: 3.0715 - disc_loss: 2.1503e-04 - beta: 0.6320 - val_loss: 286.4215 - val_reco_loss: 283.0089 - val_kl_loss: 3.2425 - val_disc_loss: 1.8924e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 207.9069 - reco_loss: 204.4810 - kl_loss: 3.3363 - disc_loss: 2.7968e-04 - beta: 0.7440 - val_loss: 195.6552 - val_reco_loss: 191.9372 - val_kl_loss: 3.5308 - val_disc_loss: 6.7021e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 204.7629 - reco_loss: 201.5048 - kl_loss: 2.1152 - disc_loss: 7.9902e-04 - beta: 0.1560 - val_loss: 640.5717 - val_reco_loss: 639.4028 - val_kl_loss: 0.9628 - val_disc_loss: 3.5648e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 470.8743 - reco_loss: 469.5635 - kl_loss: 1.2476 - disc_loss: 2.3251e-04 - beta: 0.2680 - val_loss: 546.6932 - val_reco_loss: 544.9354 - val_kl_loss: 1.5317 - val_disc_loss: 1.1379e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 436.4047 - reco_loss: 434.4211 - kl_loss: 1.8361 - disc_loss: 2.9946e-04 - beta: 0.3800 - val_loss: 474.6891 - val_reco_loss: 472.3405 - val_kl_loss: 2.1194 - val_disc_loss: 1.4338e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 344.7021 - reco_loss: 342.3107 - kl_loss: 2.3634 - disc_loss: 1.0929e-04 - beta: 0.4918\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 344.6824 - reco_loss: 342.2906 - kl_loss: 2.3633 - disc_loss: 1.0937e-04 - beta: 0.4920 - val_loss: 382.2542 - val_reco_loss: 379.5210 - val_kl_loss: 2.5192 - val_disc_loss: 2.2627e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 280.0841 - reco_loss: 277.2182 - kl_loss: 2.8182 - disc_loss: 1.2501e-04 - beta: 0.6040 - val_loss: 295.0371 - val_reco_loss: 291.7436 - val_kl_loss: 3.0743 - val_disc_loss: 5.9049e-06 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 210.5271 - reco_loss: 207.2708 - kl_loss: 3.1950 - disc_loss: 6.9003e-05 - beta: 0.7160 - val_loss: 210.9811 - val_reco_loss: 207.4006 - val_kl_loss: 3.3686 - val_disc_loss: 5.2898e-05 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 163.8487 - reco_loss: 159.3487 - kl_loss: 3.2196 - disc_loss: 2.6011e-04 - beta: 0.1280 - val_loss: 626.6962 - val_reco_loss: 625.6983 - val_kl_loss: 0.7426 - val_disc_loss: 3.2378e-06 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 477.4520 - reco_loss: 476.2999 - kl_loss: 1.0757 - disc_loss: 8.1608e-05 - beta: 0.2400 - val_loss: 543.6033 - val_reco_loss: 541.9648 - val_kl_loss: 1.4105 - val_disc_loss: 6.2147e-06 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 418.8773 - reco_loss: 417.0790 - kl_loss: 1.6804 - disc_loss: 4.3751e-05 - beta: 0.3520 - val_loss: 457.5910 - val_reco_loss: 455.3553 - val_kl_loss: 1.9858 - val_disc_loss: 3.3896e-06 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.01\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 55s 20ms/step - loss: 975.1191 - reco_loss: 974.3638 - kl_loss: 1.3815 - disc_loss: 0.2049 - beta: 0.2120 - val_loss: 670.5131 - val_reco_loss: 668.3603 - val_kl_loss: 2.0831 - val_disc_loss: 0.0115 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 511.8550 - reco_loss: 509.3196 - kl_loss: 2.6195 - disc_loss: 0.0094 - beta: 0.3240 - val_loss: 544.8263 - val_reco_loss: 541.7069 - val_kl_loss: 3.0311 - val_disc_loss: 0.0019 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 417.7826 - reco_loss: 414.7248 - kl_loss: 3.0498 - disc_loss: 0.0032 - beta: 0.4360 - val_loss: 441.4012 - val_reco_loss: 437.9845 - val_kl_loss: 3.3173 - val_disc_loss: 8.6443e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 351.1888 - reco_loss: 347.8416 - kl_loss: 3.4357 - disc_loss: 0.0017 - beta: 0.5480 - val_loss: 344.2333 - val_reco_loss: 340.4072 - val_kl_loss: 3.6968 - val_disc_loss: 0.0039 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1430.0507 - reco_loss: 1375.1812 - kl_loss: 2750.0796 - disc_loss: 0.0025 - beta: 0.6600 - val_loss: 262.4759 - val_reco_loss: 258.6628 - val_kl_loss: 3.6987 - val_disc_loss: 0.0015 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 200.0933 - reco_loss: 196.0270 - kl_loss: 3.8944 - disc_loss: 0.0021 - beta: 0.7720 - val_loss: 173.5144 - val_reco_loss: 169.5063 - val_kl_loss: 3.8742 - val_disc_loss: 9.1288e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 293.9241 - reco_loss: 291.2784 - kl_loss: 1.6516 - disc_loss: 0.0032 - beta: 0.1840 - val_loss: 614.4370 - val_reco_loss: 612.9875 - val_kl_loss: 1.2966 - val_disc_loss: 2.3108e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 482.7285 - reco_loss: 481.1351 - kl_loss: 1.6231 - disc_loss: 0.0010 - beta: 0.2960 - val_loss: 527.9586 - val_reco_loss: 525.8080 - val_kl_loss: 2.0019 - val_disc_loss: 9.2468e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 409.8912 - reco_loss: 407.5372 - kl_loss: 2.3023 - disc_loss: 8.7300e-04 - beta: 0.4080 - val_loss: 436.0411 - val_reco_loss: 433.2880 - val_kl_loss: 2.6196 - val_disc_loss: 6.1761e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 347.3344 - reco_loss: 344.4739 - kl_loss: 2.8433 - disc_loss: 7.2849e-04 - beta: 0.5200 - val_loss: 360.3723 - val_reco_loss: 357.1180 - val_kl_loss: 3.0841 - val_disc_loss: 8.3496e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 290.3664 - reco_loss: 286.9938 - kl_loss: 3.2713 - disc_loss: 0.0011 - beta: 0.6320 - val_loss: 277.5724 - val_reco_loss: 273.8787 - val_kl_loss: 3.5498 - val_disc_loss: 3.6299e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 201.4368 - reco_loss: 197.8050 - kl_loss: 3.5530 - disc_loss: 0.0014 - beta: 0.7440 - val_loss: 191.4999 - val_reco_loss: 187.6866 - val_kl_loss: 3.6532 - val_disc_loss: 1.9665e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 205.5413 - reco_loss: 202.1177 - kl_loss: 2.2369 - disc_loss: 0.0016 - beta: 0.1560 - val_loss: 599.6437 - val_reco_loss: 598.4492 - val_kl_loss: 1.0152 - val_disc_loss: 2.0058e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 468.6484 - reco_loss: 467.2814 - kl_loss: 1.3659 - disc_loss: 2.6618e-04 - beta: 0.2680 - val_loss: 547.8774 - val_reco_loss: 545.9854 - val_kl_loss: 1.6849 - val_disc_loss: 3.7040e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 442.3753 - reco_loss: 440.2998 - kl_loss: 2.0529 - disc_loss: 6.7657e-04 - beta: 0.3800 - val_loss: 440.7728 - val_reco_loss: 438.3959 - val_kl_loss: 2.2071 - val_disc_loss: 1.4198e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 356.3737 - reco_loss: 353.7234 - kl_loss: 2.5938 - disc_loss: 2.8091e-04 - beta: 0.4920\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 356.3651 - reco_loss: 353.7147 - kl_loss: 2.5938 - disc_loss: 2.8093e-04 - beta: 0.4920 - val_loss: 359.7022 - val_reco_loss: 356.7860 - val_kl_loss: 2.7073 - val_disc_loss: 4.2755e-06 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 296.0164 - reco_loss: 292.7899 - kl_loss: 3.1158 - disc_loss: 2.0700e-04 - beta: 0.6040 - val_loss: 292.8562 - val_reco_loss: 289.4836 - val_kl_loss: 3.1935 - val_disc_loss: 1.1783e-05 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 239.0213 - reco_loss: 234.4534 - kl_loss: 5.6496 - disc_loss: 3.7748e-04 - beta: 0.7160 - val_loss: 206.2709 - val_reco_loss: 202.5685 - val_kl_loss: 3.5225 - val_disc_loss: 1.6551e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 161.0618 - reco_loss: 157.3004 - kl_loss: 2.9569 - disc_loss: 0.0021 - beta: 0.1280 - val_loss: 657.1197 - val_reco_loss: 656.1359 - val_kl_loss: 0.7795 - val_disc_loss: 1.8338e-05 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 496.2330 - reco_loss: 495.0261 - kl_loss: 1.1798 - disc_loss: 2.9201e-04 - beta: 0.2400 - val_loss: 573.6835 - val_reco_loss: 571.9425 - val_kl_loss: 1.5386 - val_disc_loss: 1.1469e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 435.2959 - reco_loss: 433.3969 - kl_loss: 1.8511 - disc_loss: 2.9730e-04 - beta: 0.3520 - val_loss: 480.7957 - val_reco_loss: 478.5168 - val_kl_loss: 2.0793 - val_disc_loss: 3.8546e-06 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.01\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 51s 19ms/step - loss: 895.6302 - reco_loss: 895.1068 - kl_loss: 0.9905 - disc_loss: 0.2725 - beta: 0.2120 - val_loss: 731.5402 - val_reco_loss: 729.2660 - val_kl_loss: 2.2018 - val_disc_loss: 0.0054 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 521.2561 - reco_loss: 519.1257 - kl_loss: 2.2630 - disc_loss: 0.0063 - beta: 0.3240 - val_loss: 609.2654 - val_reco_loss: 606.0274 - val_kl_loss: 3.1295 - val_disc_loss: 2.9285e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 442.5045 - reco_loss: 439.6808 - kl_loss: 2.8677 - disc_loss: 0.0013 - beta: 0.4360 - val_loss: 473.3440 - val_reco_loss: 469.2628 - val_kl_loss: 3.9705 - val_disc_loss: 3.2933e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 339.0717 - reco_loss: 335.7033 - kl_loss: 3.4442 - disc_loss: 0.0016 - beta: 0.5480 - val_loss: 360.3962 - val_reco_loss: 356.1750 - val_kl_loss: 4.0967 - val_disc_loss: 1.0456e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 31350754642.7934 - reco_loss: 25971545295.6889 - kl_loss: 3567632128.0000 - disc_loss: 0.0010 - beta: 0.6600 - val_loss: 270.1209 - val_reco_loss: 265.8651 - val_kl_loss: 4.1193 - val_disc_loss: 1.7069e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 187.6638 - reco_loss: 183.8792 - kl_loss: 3.7295 - disc_loss: 8.3690e-04 - beta: 0.7720 - val_loss: 172.1248 - val_reco_loss: 167.8611 - val_kl_loss: 4.1235 - val_disc_loss: 1.5626e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 275507.0098 - reco_loss: 195057.6681 - kl_loss: 34973.4141 - disc_loss: 7.3936e-04 - beta: 0.1840 - val_loss: 595.5707 - val_reco_loss: 594.1332 - val_kl_loss: 1.2836 - val_disc_loss: 9.3036e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 527.1276 - reco_loss: 525.3432 - kl_loss: 1.8260 - disc_loss: 4.8779e-04 - beta: 0.2960 - val_loss: 507.7355 - val_reco_loss: 505.4791 - val_kl_loss: 2.0990 - val_disc_loss: 8.3990e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 420.7608 - reco_loss: 418.5295 - kl_loss: 2.1714 - disc_loss: 0.0015 - beta: 0.4080 - val_loss: 434.0053 - val_reco_loss: 431.2225 - val_kl_loss: 2.6273 - val_disc_loss: 0.0017 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 339.8719 - reco_loss: 337.1750 - kl_loss: 2.6983 - disc_loss: 0.0024 - beta: 0.5200 - val_loss: 356.3320 - val_reco_loss: 353.1022 - val_kl_loss: 3.0804 - val_disc_loss: 8.1889e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 295.7068 - reco_loss: 292.4901 - kl_loss: 3.1359 - disc_loss: 0.0045 - beta: 0.6320 - val_loss: 271.5598 - val_reco_loss: 267.8847 - val_kl_loss: 3.5244 - val_disc_loss: 6.8858e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 204.2500 - reco_loss: 200.7339 - kl_loss: 3.4218 - disc_loss: 0.0021 - beta: 0.7440 - val_loss: 191.0862 - val_reco_loss: 187.2934 - val_kl_loss: 3.6338 - val_disc_loss: 2.7040e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 201.6182 - reco_loss: 198.3520 - kl_loss: 2.1298 - disc_loss: 0.0027 - beta: 0.1560 - val_loss: 608.0436 - val_reco_loss: 606.8280 - val_kl_loss: 1.0579 - val_disc_loss: 7.3215e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 511.0051 - reco_loss: 509.6698 - kl_loss: 1.3106 - disc_loss: 4.3970e-04 - beta: 0.2680 - val_loss: 517.4753 - val_reco_loss: 515.5924 - val_kl_loss: 1.7283 - val_disc_loss: 2.8005e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 410.9450 - reco_loss: 409.0327 - kl_loss: 1.9201 - disc_loss: 5.3615e-04 - beta: 0.3800 - val_loss: 443.6120 - val_reco_loss: 441.0869 - val_kl_loss: 2.3376 - val_disc_loss: 9.5774e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 354.2200 - reco_loss: 351.6919 - kl_loss: 2.4574 - disc_loss: 0.0018 - beta: 0.4920\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 354.2131 - reco_loss: 351.6850 - kl_loss: 2.4574 - disc_loss: 0.0018 - beta: 0.4920 - val_loss: 365.4275 - val_reco_loss: 362.2494 - val_kl_loss: 2.9869 - val_disc_loss: 7.8879e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 277.5146 - reco_loss: 274.5308 - kl_loss: 2.9409 - disc_loss: 5.5129e-04 - beta: 0.6040 - val_loss: 281.3986 - val_reco_loss: 277.8533 - val_kl_loss: 3.3614 - val_disc_loss: 2.3557e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 219.2716 - reco_loss: 215.8778 - kl_loss: 3.3281 - disc_loss: 0.0015 - beta: 0.7160 - val_loss: 202.5346 - val_reco_loss: 198.5897 - val_kl_loss: 3.7413 - val_disc_loss: 0.0013 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 164.7270 - reco_loss: 161.1497 - kl_loss: 2.8242 - disc_loss: 0.0091 - beta: 0.1280 - val_loss: 613.0354 - val_reco_loss: 612.0310 - val_kl_loss: 0.8193 - val_disc_loss: 1.4670e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 471.6137 - reco_loss: 470.4932 - kl_loss: 1.1299 - disc_loss: 7.4593e-04 - beta: 0.2400 - val_loss: 531.1771 - val_reco_loss: 529.4445 - val_kl_loss: 1.5526 - val_disc_loss: 1.5332e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 434.5295 - reco_loss: 432.7312 - kl_loss: 1.7589 - disc_loss: 3.1962e-04 - beta: 0.3520 - val_loss: 458.4245 - val_reco_loss: 456.0396 - val_kl_loss: 2.1987 - val_disc_loss: 4.4982e-05 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.01\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 52s 19ms/step - loss: 908.3581 - reco_loss: 907.7947 - kl_loss: 1.0017 - disc_loss: 0.1572 - beta: 0.2120 - val_loss: 714.3985 - val_reco_loss: 712.5718 - val_kl_loss: 1.7490 - val_disc_loss: 0.0070 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 552.3733 - reco_loss: 550.1480 - kl_loss: 2.3633 - disc_loss: 0.0088 - beta: 0.3240 - val_loss: 549.7419 - val_reco_loss: 546.6271 - val_kl_loss: 3.0272 - val_disc_loss: 0.0073 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 407.2859 - reco_loss: 404.1976 - kl_loss: 3.1546 - disc_loss: 0.0034 - beta: 0.4360 - val_loss: 417.7216 - val_reco_loss: 413.2071 - val_kl_loss: 4.3959 - val_disc_loss: 0.0018 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 356.4157 - reco_loss: 352.7396 - kl_loss: 3.6669 - disc_loss: 0.0033 - beta: 0.5480 - val_loss: 334.1381 - val_reco_loss: 329.2761 - val_kl_loss: 4.7112 - val_disc_loss: 0.0013 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 258.2469 - reco_loss: 254.2513 - kl_loss: 3.9835 - disc_loss: 0.0039 - beta: 0.6600 - val_loss: 252.5212 - val_reco_loss: 247.1693 - val_kl_loss: 5.1894 - val_disc_loss: 0.0046 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 185.4696 - reco_loss: 181.3305 - kl_loss: 4.0721 - disc_loss: 0.0054 - beta: 0.7720 - val_loss: 172.6214 - val_reco_loss: 167.1945 - val_kl_loss: 5.2623 - val_disc_loss: 0.0121 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 295.9198 - reco_loss: 293.0337 - kl_loss: 1.7633 - disc_loss: 0.0061 - beta: 0.1840 - val_loss: 619.5834 - val_reco_loss: 617.7566 - val_kl_loss: 1.6347 - val_disc_loss: 0.0021 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 478.3802 - reco_loss: 476.6878 - kl_loss: 1.7157 - disc_loss: 0.0019 - beta: 0.2960 - val_loss: 559.6246 - val_reco_loss: 556.7056 - val_kl_loss: 2.7307 - val_disc_loss: 5.3273e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 406.2994 - reco_loss: 403.8513 - kl_loss: 2.4339 - disc_loss: 0.0013 - beta: 0.4080 - val_loss: 454.7227 - val_reco_loss: 450.9381 - val_kl_loss: 3.6224 - val_disc_loss: 9.3177e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 1027.6019 - reco_loss: 1021.5718 - kl_loss: 11.7046 - disc_loss: 0.0026 - beta: 0.5200 - val_loss: 359.6148 - val_reco_loss: 355.1747 - val_kl_loss: 4.2607 - val_disc_loss: 8.7015e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 275.6437 - reco_loss: 272.0844 - kl_loss: 3.5163 - disc_loss: 0.0023 - beta: 0.6320 - val_loss: 268.4584 - val_reco_loss: 263.5924 - val_kl_loss: 4.6519 - val_disc_loss: 7.0659e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 204.1085 - reco_loss: 200.1140 - kl_loss: 3.8217 - disc_loss: 0.0044 - beta: 0.7440 - val_loss: 185.6607 - val_reco_loss: 180.5160 - val_kl_loss: 4.9611 - val_disc_loss: 0.0025 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 199.2630 - reco_loss: 195.6777 - kl_loss: 2.3875 - disc_loss: 0.0097 - beta: 0.1560 - val_loss: 603.9661 - val_reco_loss: 602.4634 - val_kl_loss: 1.2687 - val_disc_loss: 8.7277e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 464.5413 - reco_loss: 463.0919 - kl_loss: 1.4464 - disc_loss: 6.4087e-04 - beta: 0.2680 - val_loss: 487.0719 - val_reco_loss: 484.7103 - val_kl_loss: 2.1513 - val_disc_loss: 2.8137e-05 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 400.5125 - reco_loss: 398.3582 - kl_loss: 2.1277 - disc_loss: 6.0838e-04 - beta: 0.3800 - val_loss: 428.6199 - val_reco_loss: 425.4705 - val_kl_loss: 2.9223 - val_disc_loss: 0.0222 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 324.3551 - reco_loss: 321.6061 - kl_loss: 2.7387 - disc_loss: 9.5344e-04 - beta: 0.4920\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 324.3585 - reco_loss: 321.6095 - kl_loss: 2.7387 - disc_loss: 9.5336e-04 - beta: 0.4920 - val_loss: 344.4518 - val_reco_loss: 340.6445 - val_kl_loss: 3.6074 - val_disc_loss: 1.3335e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 281.7505 - reco_loss: 278.3976 - kl_loss: 3.2992 - disc_loss: 5.4500e-04 - beta: 0.6040 - val_loss: 276.5908 - val_reco_loss: 272.0909 - val_kl_loss: 4.2864 - val_disc_loss: 1.0252e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 24950379192772332.0000 - reco_loss: 24819634985656292.0000 - kl_loss: 649919685722112.0000 - disc_loss: 0.0018 - beta: 0.7160 - val_loss: 194.9756 - val_reco_loss: 190.0921 - val_kl_loss: 4.6963 - val_disc_loss: 0.0022 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 80235063510371.1094 - reco_loss: 79246196933685.7031 - kl_loss: 234017030144.0000 - disc_loss: 0.0074 - beta: 0.1280 - val_loss: 592.5763 - val_reco_loss: 591.3303 - val_kl_loss: 1.0231 - val_disc_loss: 3.8402e-05 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 480.6663 - reco_loss: 479.3721 - kl_loss: 1.2520 - disc_loss: 3.6823e-04 - beta: 0.2400 - val_loss: 523.7945 - val_reco_loss: 521.6513 - val_kl_loss: 1.9312 - val_disc_loss: 5.0901e-05 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 418.1424 - reco_loss: 416.1479 - kl_loss: 1.9503 - disc_loss: 1.9442e-04 - beta: 0.3520 - val_loss: 453.8044 - val_reco_loss: 450.7865 - val_kl_loss: 2.7993 - val_disc_loss: 4.4650e-05 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.1\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 52s 19ms/step - loss: 897.5271 - reco_loss: 896.7285 - kl_loss: 0.6905 - disc_loss: 0.1617 - beta: 0.2120 - val_loss: 620.2332 - val_reco_loss: 617.9100 - val_kl_loss: 1.4988 - val_disc_loss: 0.0044 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 491.2021 - reco_loss: 488.9090 - kl_loss: 1.6554 - disc_loss: 0.0095 - beta: 0.3240 - val_loss: 503.9000 - val_reco_loss: 500.3209 - val_kl_loss: 2.5294 - val_disc_loss: 0.0048 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 416.4627 - reco_loss: 413.1689 - kl_loss: 2.3156 - disc_loss: 0.0117 - beta: 0.4360 - val_loss: 415.6477 - val_reco_loss: 410.9722 - val_kl_loss: 3.4636 - val_disc_loss: 0.0066 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 346.7389 - reco_loss: 342.7551 - kl_loss: 2.8734 - disc_loss: 0.0242 - beta: 0.5480 - val_loss: 359.8054 - val_reco_loss: 354.7747 - val_kl_loss: 3.7337 - val_disc_loss: 0.0346 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 291.9848 - reco_loss: 287.4302 - kl_loss: 3.3432 - disc_loss: 0.0337 - beta: 0.6600 - val_loss: 264.3767 - val_reco_loss: 259.1613 - val_kl_loss: 4.0420 - val_disc_loss: 0.1601 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 180.5893 - reco_loss: 175.9392 - kl_loss: 3.6096 - disc_loss: 0.0634 - beta: 0.7720 - val_loss: 183.9414 - val_reco_loss: 178.6864 - val_kl_loss: 4.1092 - val_disc_loss: 0.0374 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 292.2599 - reco_loss: 288.6743 - kl_loss: 1.5949 - disc_loss: 0.0700 - beta: 0.1840 - val_loss: 616.9163 - val_reco_loss: 614.2721 - val_kl_loss: 1.3004 - val_disc_loss: 0.0014 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 1226471.1841 - reco_loss: 1226121.0712 - kl_loss: 14815.4492 - disc_loss: 0.0030 - beta: 0.2960 - val_loss: 521.8677 - val_reco_loss: 518.2733 - val_kl_loss: 2.1012 - val_disc_loss: 4.1229e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 413.4751 - reco_loss: 410.1250 - kl_loss: 2.1712 - disc_loss: 0.0026 - beta: 0.4080 - val_loss: 429.3151 - val_reco_loss: 425.1013 - val_kl_loss: 2.7374 - val_disc_loss: 7.0338e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 335.2737 - reco_loss: 331.1597 - kl_loss: 2.8152 - disc_loss: 0.0072 - beta: 0.5200 - val_loss: 349.4175 - val_reco_loss: 344.4455 - val_kl_loss: 3.5571 - val_disc_loss: 0.0083 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 283.7151 - reco_loss: 278.9406 - kl_loss: 3.1980 - disc_loss: 0.0298 - beta: 0.6320 - val_loss: 267.9965 - val_reco_loss: 263.0114 - val_kl_loss: 3.6094 - val_disc_loss: 0.0147 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 34942008.7737 - reco_loss: 27287801.3584 - kl_loss: 64261252.0000 - disc_loss: 0.0476 - beta: 0.7440 - val_loss: 191.3386 - val_reco_loss: 186.3224 - val_kl_loss: 3.9221 - val_disc_loss: 0.0893 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 204.8995 - reco_loss: 200.7643 - kl_loss: 2.1898 - disc_loss: 0.0553 - beta: 0.1560 - val_loss: 609.5403 - val_reco_loss: 606.9144 - val_kl_loss: 1.0446 - val_disc_loss: 7.0694e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 437.1720 - reco_loss: 434.6996 - kl_loss: 1.3018 - disc_loss: 0.0024 - beta: 0.2680 - val_loss: 519.2130 - val_reco_loss: 516.0625 - val_kl_loss: 1.6734 - val_disc_loss: 0.0017 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 410.2024 - reco_loss: 407.0178 - kl_loss: 1.9119 - disc_loss: 0.0028 - beta: 0.3800 - val_loss: 479.3417 - val_reco_loss: 475.5447 - val_kl_loss: 2.2269 - val_disc_loss: 0.0013 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 359.8641 - reco_loss: 356.2143 - kl_loss: 2.4500 - disc_loss: 0.0064 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 359.8418 - reco_loss: 356.1918 - kl_loss: 2.4503 - disc_loss: 0.0064 - beta: 0.4920 - val_loss: 380.0988 - val_reco_loss: 375.9094 - val_kl_loss: 2.7491 - val_disc_loss: 0.0175 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 103900171873.8285 - reco_loss: 102781114490.1744 - kl_loss: 204554864.0000 - disc_loss: 0.0127 - beta: 0.6040 - val_loss: 281.8802 - val_reco_loss: 277.0633 - val_kl_loss: 3.3402 - val_disc_loss: 0.0234 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 6367917635.0303 - reco_loss: 6237905641.2652 - kl_loss: 3323632640.0000 - disc_loss: 0.0328 - beta: 0.7160 - val_loss: 207.4574 - val_reco_loss: 202.4585 - val_kl_loss: 3.6375 - val_disc_loss: 0.0392 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 173.0504 - reco_loss: 168.5213 - kl_loss: 2.8654 - disc_loss: 0.0446 - beta: 0.1280 - val_loss: 616.9584 - val_reco_loss: 614.6365 - val_kl_loss: 0.8271 - val_disc_loss: 0.0015 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 485.9112 - reco_loss: 483.6533 - kl_loss: 1.1259 - disc_loss: 0.0036 - beta: 0.2400 - val_loss: 546.8666 - val_reco_loss: 543.6945 - val_kl_loss: 1.4913 - val_disc_loss: 4.7283e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 408.0213 - reco_loss: 404.9788 - kl_loss: 1.7462 - disc_loss: 0.0018 - beta: 0.3520 - val_loss: 463.2117 - val_reco_loss: 459.4738 - val_kl_loss: 2.0834 - val_disc_loss: 4.5247e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.1\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 50s 18ms/step - loss: 892.4955 - reco_loss: 891.7829 - kl_loss: 0.6785 - disc_loss: 0.2128 - beta: 0.2120 - val_loss: 647.7628 - val_reco_loss: 645.2920 - val_kl_loss: 1.6871 - val_disc_loss: 0.0163 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 514.2908 - reco_loss: 511.8494 - kl_loss: 1.9326 - disc_loss: 0.0160 - beta: 0.3240 - val_loss: 526.5859 - val_reco_loss: 522.3914 - val_kl_loss: 3.2509 - val_disc_loss: 0.0081 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 455.7932 - reco_loss: 452.2821 - kl_loss: 2.6981 - disc_loss: 0.0266 - beta: 0.4360 - val_loss: 431.4581 - val_reco_loss: 426.3048 - val_kl_loss: 4.1311 - val_disc_loss: 0.0348 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 350.0722 - reco_loss: 345.9880 - kl_loss: 3.3059 - disc_loss: 0.0442 - beta: 0.5480 - val_loss: 335.3460 - val_reco_loss: 330.0156 - val_kl_loss: 4.5054 - val_disc_loss: 0.0267 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 333468282400.1411 - reco_loss: 323027932241.6080 - kl_loss: 29588045824.0000 - disc_loss: 0.0451 - beta: 0.6600 - val_loss: 250.0667 - val_reco_loss: 244.4599 - val_kl_loss: 4.8346 - val_disc_loss: 0.0261 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 203.9802 - reco_loss: 199.1894 - kl_loss: 3.9026 - disc_loss: 0.0614 - beta: 0.7720 - val_loss: 172.0067 - val_reco_loss: 166.7353 - val_kl_loss: 4.4934 - val_disc_loss: 0.1794 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 295.0864 - reco_loss: 291.7075 - kl_loss: 1.6631 - disc_loss: 0.0713 - beta: 0.1840 - val_loss: 580.0798 - val_reco_loss: 577.5016 - val_kl_loss: 1.5506 - val_disc_loss: 0.0018 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 486.1972 - reco_loss: 483.6623 - kl_loss: 1.6751 - disc_loss: 0.0054 - beta: 0.2960 - val_loss: 512.2112 - val_reco_loss: 508.6502 - val_kl_loss: 2.4271 - val_disc_loss: 0.0019 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 445.0625 - reco_loss: 441.3104 - kl_loss: 2.5149 - disc_loss: 0.0056 - beta: 0.4080 - val_loss: 420.1829 - val_reco_loss: 415.7336 - val_kl_loss: 3.2464 - val_disc_loss: 0.0172 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 347.1966 - reco_loss: 343.0716 - kl_loss: 2.9788 - disc_loss: 0.0096 - beta: 0.5200 - val_loss: 334.3901 - val_reco_loss: 329.1626 - val_kl_loss: 3.9246 - val_disc_loss: 0.0059 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 275.4059 - reco_loss: 270.7933 - kl_loss: 3.5687 - disc_loss: 0.0192 - beta: 0.6320 - val_loss: 271.4167 - val_reco_loss: 265.8587 - val_kl_loss: 4.4192 - val_disc_loss: 0.0097 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 207.5833 - reco_loss: 202.4235 - kl_loss: 3.8712 - disc_loss: 0.0332 - beta: 0.7440 - val_loss: 182.9332 - val_reco_loss: 177.1884 - val_kl_loss: 4.5003 - val_disc_loss: 0.0389 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1560 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2680 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3800 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.1\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 56s 20ms/step - loss: 912.7053 - reco_loss: 911.7436 - kl_loss: 0.9851 - disc_loss: 0.2219 - beta: 0.2120 - val_loss: 724.5298 - val_reco_loss: 721.7282 - val_kl_loss: 1.9960 - val_disc_loss: 0.0100 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 530.1892 - reco_loss: 527.4341 - kl_loss: 2.2904 - disc_loss: 0.0196 - beta: 0.3240 - val_loss: 498.7685 - val_reco_loss: 493.7841 - val_kl_loss: 4.0026 - val_disc_loss: 0.0214 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 432.0220 - reco_loss: 428.1347 - kl_loss: 2.9714 - disc_loss: 0.0233 - beta: 0.4360 - val_loss: 402.9656 - val_reco_loss: 397.2305 - val_kl_loss: 4.5362 - val_disc_loss: 0.0188 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 350.6986 - reco_loss: 346.2343 - kl_loss: 3.3496 - disc_loss: 0.0237 - beta: 0.5480 - val_loss: 321.7784 - val_reco_loss: 315.9811 - val_kl_loss: 4.6245 - val_disc_loss: 0.0232 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 273.0966 - reco_loss: 268.3201 - kl_loss: 3.6633 - disc_loss: 0.0302 - beta: 0.6600 - val_loss: 246.3204 - val_reco_loss: 240.6221 - val_kl_loss: 4.5749 - val_disc_loss: 0.1137 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 192.9494 - reco_loss: 188.0017 - kl_loss: 3.8004 - disc_loss: 0.0510 - beta: 0.7720 - val_loss: 164.9234 - val_reco_loss: 159.0135 - val_kl_loss: 4.8678 - val_disc_loss: 0.0289 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 321.3487 - reco_loss: 317.5167 - kl_loss: 1.6698 - disc_loss: 0.0310 - beta: 0.1840 - val_loss: 560.2850 - val_reco_loss: 557.3937 - val_kl_loss: 1.4626 - val_disc_loss: 6.5174e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 136905.4564 - reco_loss: 135172.7288 - kl_loss: 9319.0918 - disc_loss: 0.0023 - beta: 0.2960 - val_loss: 494.9648 - val_reco_loss: 491.0015 - val_kl_loss: 2.4203 - val_disc_loss: 0.0015 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 423.8536 - reco_loss: 420.2632 - kl_loss: 2.2926 - disc_loss: 0.0040 - beta: 0.4080 - val_loss: 404.2506 - val_reco_loss: 399.1090 - val_kl_loss: 3.2026 - val_disc_loss: 0.0038 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 46166757391825690624.0000 - reco_loss: 45169743002945085440.0000 - kl_loss: 11547353689391890432.0000 - disc_loss: 0.0100 - beta: 0.5200 - val_loss: 333.2675 - val_reco_loss: 327.4789 - val_kl_loss: 3.9165 - val_disc_loss: 0.0082 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6320 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7440 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1560 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2680 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3800 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.1\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 52s 19ms/step - loss: 817.5812 - reco_loss: 816.5880 - kl_loss: 1.0645 - disc_loss: 0.1960 - beta: 0.2120 - val_loss: 648.4772 - val_reco_loss: 644.9033 - val_kl_loss: 2.7887 - val_disc_loss: 0.0119 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 533.0831 - reco_loss: 530.0032 - kl_loss: 2.4200 - disc_loss: 0.0081 - beta: 0.3240 - val_loss: 498.9345 - val_reco_loss: 492.9066 - val_kl_loss: 5.1019 - val_disc_loss: 0.0082 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 420.3038 - reco_loss: 416.3456 - kl_loss: 3.0891 - disc_loss: 0.0155 - beta: 0.4360 - val_loss: 399.1316 - val_reco_loss: 392.3318 - val_kl_loss: 5.6784 - val_disc_loss: 0.0271 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 324.5219 - reco_loss: 320.0305 - kl_loss: 3.5799 - disc_loss: 0.0416 - beta: 0.5480 - val_loss: 324.3114 - val_reco_loss: 316.4416 - val_kl_loss: 6.7004 - val_disc_loss: 0.0346 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 2995898464886.7622 - reco_loss: 1217562198693.3479 - kl_loss: 1661691232256.0000 - disc_loss: 0.0735 - beta: 0.6600 - val_loss: 250.6284 - val_reco_loss: 243.7248 - val_kl_loss: 5.9714 - val_disc_loss: 0.1613 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 196.9565 - reco_loss: 192.0963 - kl_loss: 3.9823 - disc_loss: 0.1292 - beta: 0.7720 - val_loss: 174.2606 - val_reco_loss: 168.2787 - val_kl_loss: 5.2252 - val_disc_loss: 0.1546 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 302.5322 - reco_loss: 298.9839 - kl_loss: 1.7419 - disc_loss: 0.1094 - beta: 0.1840 - val_loss: 586.0015 - val_reco_loss: 583.3037 - val_kl_loss: 1.7356 - val_disc_loss: 0.0189 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 525.3910 - reco_loss: 522.7787 - kl_loss: 1.6677 - disc_loss: 0.0224 - beta: 0.2960 - val_loss: 495.6702 - val_reco_loss: 491.9458 - val_kl_loss: 2.7165 - val_disc_loss: 0.1111 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 9081.4598 - reco_loss: 9069.3439 - kl_loss: 5.6229 - disc_loss: 0.2185 - beta: 0.4080 - val_loss: 434.4075 - val_reco_loss: 429.9390 - val_kl_loss: 3.4175 - val_disc_loss: 0.0796 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 344.6245 - reco_loss: 340.9216 - kl_loss: 2.9408 - disc_loss: 0.1246 - beta: 0.5200 - val_loss: 341.2946 - val_reco_loss: 336.2485 - val_kl_loss: 4.0801 - val_disc_loss: 0.0807 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 277.0081 - reco_loss: 272.8640 - kl_loss: 3.4078 - disc_loss: 0.1506 - beta: 0.6320 - val_loss: 260.7926 - val_reco_loss: 255.6023 - val_kl_loss: 4.3382 - val_disc_loss: 0.0667 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7440 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1560 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2680 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3800 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.1\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 52s 19ms/step - loss: 867.1279 - reco_loss: 866.1963 - kl_loss: 0.9389 - disc_loss: 0.2126 - beta: 0.2120 - val_loss: 648.9138 - val_reco_loss: 645.8395 - val_kl_loss: 2.2329 - val_disc_loss: 0.0031 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 514.4395 - reco_loss: 511.6618 - kl_loss: 2.1077 - disc_loss: 0.0050 - beta: 0.3240 - val_loss: 504.2206 - val_reco_loss: 499.1152 - val_kl_loss: 4.0115 - val_disc_loss: 0.0014 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 456.7353 - reco_loss: 452.9633 - kl_loss: 2.8572 - disc_loss: 0.0085 - beta: 0.4360 - val_loss: 391.0224 - val_reco_loss: 385.0256 - val_kl_loss: 5.0028 - val_disc_loss: 0.0209 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 349.0676 - reco_loss: 344.8796 - kl_loss: 3.3514 - disc_loss: 0.0214 - beta: 0.5480 - val_loss: 318.1146 - val_reco_loss: 311.9516 - val_kl_loss: 5.2388 - val_disc_loss: 0.0160 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 262.4366 - reco_loss: 257.9609 - kl_loss: 3.6034 - disc_loss: 0.0360 - beta: 0.6600 - val_loss: 231.7473 - val_reco_loss: 225.4701 - val_kl_loss: 5.3261 - val_disc_loss: 0.0685 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 203.1921 - reco_loss: 198.5690 - kl_loss: 3.7054 - disc_loss: 0.0996 - beta: 0.7720 - val_loss: 157.3302 - val_reco_loss: 151.4726 - val_kl_loss: 5.1273 - val_disc_loss: 0.1271 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 304.9550 - reco_loss: 301.5441 - kl_loss: 1.6253 - disc_loss: 0.0694 - beta: 0.1840 - val_loss: 546.9280 - val_reco_loss: 544.1399 - val_kl_loss: 1.7098 - val_disc_loss: 0.0027 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 470.2287 - reco_loss: 467.6946 - kl_loss: 1.5780 - disc_loss: 0.0050 - beta: 0.2960 - val_loss: 479.3267 - val_reco_loss: 475.5543 - val_kl_loss: 2.5717 - val_disc_loss: 0.0043 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 434.1852 - reco_loss: 430.8401 - kl_loss: 2.2030 - disc_loss: 0.0166 - beta: 0.4080 - val_loss: 398.8658 - val_reco_loss: 393.9876 - val_kl_loss: 3.6735 - val_disc_loss: 0.0053 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 343.7987 - reco_loss: 339.8338 - kl_loss: 2.7943 - disc_loss: 0.0437 - beta: 0.5200 - val_loss: 320.5007 - val_reco_loss: 315.1408 - val_kl_loss: 4.1599 - val_disc_loss: 0.0404 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 268.4376 - reco_loss: 264.2038 - kl_loss: 3.2034 - disc_loss: 0.0935 - beta: 0.6320 - val_loss: 243.1150 - val_reco_loss: 237.5025 - val_kl_loss: 4.6477 - val_disc_loss: 0.2102 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 29901.8412 - reco_loss: 19853.8853 - kl_loss: 21977.3672 - disc_loss: 0.1494 - beta: 0.7440 - val_loss: 169.5836 - val_reco_loss: 163.7676 - val_kl_loss: 4.9525 - val_disc_loss: 0.1324 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 208.1800 - reco_loss: 204.1125 - kl_loss: 2.1922 - disc_loss: 0.1745 - beta: 0.1560 - val_loss: 550.7059 - val_reco_loss: 548.4017 - val_kl_loss: 1.2690 - val_disc_loss: 0.0120 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 483.7342 - reco_loss: 481.3539 - kl_loss: 1.3527 - disc_loss: 0.0212 - beta: 0.2680 - val_loss: 469.6153 - val_reco_loss: 465.9475 - val_kl_loss: 2.2745 - val_disc_loss: 0.0172 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 1713.2396 - reco_loss: 1705.9816 - kl_loss: 19.8169 - disc_loss: 0.0520 - beta: 0.3800 - val_loss: 406.8824 - val_reco_loss: 402.4610 - val_kl_loss: 3.1462 - val_disc_loss: 0.0459 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 590.9221 - reco_loss: 584.9402 - kl_loss: 6.4881 - disc_loss: 0.0930 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 591.1306 - reco_loss: 585.1466 - kl_loss: 6.4854 - disc_loss: 0.0930 - beta: 0.4920 - val_loss: 332.5887 - val_reco_loss: 327.4313 - val_kl_loss: 3.9232 - val_disc_loss: 0.0714 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 57s 23ms/step - loss: 289.9943 - reco_loss: 285.8685 - kl_loss: 3.0746 - disc_loss: 0.0956 - beta: 0.6040 - val_loss: 258.4438 - val_reco_loss: 252.5913 - val_kl_loss: 4.5786 - val_disc_loss: 0.0939 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 57s 23ms/step - loss: 16731930907661458.0000 - reco_loss: 16074649533954546.0000 - kl_loss: 455465041395712.0000 - disc_loss: 0.1757 - beta: 0.7160 - val_loss: 188.7322 - val_reco_loss: 182.4669 - val_kl_loss: 5.1147 - val_disc_loss: 0.2853 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 10932204.1911 - reco_loss: 10820124.2705 - kl_loss: 124233.7188 - disc_loss: 0.2365 - beta: 0.1280 - val_loss: 567.6377 - val_reco_loss: 565.4124 - val_kl_loss: 1.0537 - val_disc_loss: 0.0452 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 504.6294 - reco_loss: 502.5654 - kl_loss: 1.1833 - disc_loss: 0.0432 - beta: 0.2400 - val_loss: 482.0666 - val_reco_loss: 478.7339 - val_kl_loss: 2.1361 - val_disc_loss: 0.0294 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 431.9788 - reco_loss: 429.1563 - kl_loss: 1.8585 - disc_loss: 0.0514 - beta: 0.3520 - val_loss: 415.8980 - val_reco_loss: 411.5823 - val_kl_loss: 3.0690 - val_disc_loss: 0.0534 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.1\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 53s 19ms/step - loss: 971.8685 - reco_loss: 971.0075 - kl_loss: 0.8799 - disc_loss: 0.2526 - beta: 0.2120 - val_loss: 730.5345 - val_reco_loss: 728.4572 - val_kl_loss: 1.3725 - val_disc_loss: 0.0365 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 568.5372 - reco_loss: 565.8769 - kl_loss: 2.0938 - disc_loss: 0.0137 - beta: 0.3240 - val_loss: 596.0976 - val_reco_loss: 593.0709 - val_kl_loss: 2.2036 - val_disc_loss: 0.0222 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 430.8823 - reco_loss: 427.3483 - kl_loss: 2.7858 - disc_loss: 0.0102 - beta: 0.4360 - val_loss: 434.8942 - val_reco_loss: 430.2209 - val_kl_loss: 3.4832 - val_disc_loss: 0.0167 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 339.8337 - reco_loss: 335.6654 - kl_loss: 3.3009 - disc_loss: 0.0151 - beta: 0.5480 - val_loss: 342.4892 - val_reco_loss: 337.2975 - val_kl_loss: 4.1656 - val_disc_loss: 0.0139 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 270.3123 - reco_loss: 265.6670 - kl_loss: 3.7215 - disc_loss: 0.0288 - beta: 0.6600 - val_loss: 260.4857 - val_reco_loss: 254.9824 - val_kl_loss: 4.4301 - val_disc_loss: 0.0458 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 202.3934 - reco_loss: 197.4713 - kl_loss: 3.8984 - disc_loss: 0.0536 - beta: 0.7720 - val_loss: 171.3430 - val_reco_loss: 166.0039 - val_kl_loss: 4.3919 - val_disc_loss: 0.0380 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 289.3940 - reco_loss: 285.9013 - kl_loss: 1.7100 - disc_loss: 0.0519 - beta: 0.1840 - val_loss: 604.6097 - val_reco_loss: 602.0982 - val_kl_loss: 1.2682 - val_disc_loss: 0.0014 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 497.9986 - reco_loss: 495.3540 - kl_loss: 1.6203 - disc_loss: 0.0041 - beta: 0.2960 - val_loss: 528.7186 - val_reco_loss: 525.3243 - val_kl_loss: 2.0299 - val_disc_loss: 0.0062 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 397.4762 - reco_loss: 394.1492 - kl_loss: 2.3253 - disc_loss: 0.0103 - beta: 0.4080 - val_loss: 442.4677 - val_reco_loss: 438.2438 - val_kl_loss: 2.7059 - val_disc_loss: 0.0049 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 336.0011 - reco_loss: 332.0350 - kl_loss: 2.8850 - disc_loss: 0.0228 - beta: 0.5200 - val_loss: 360.0397 - val_reco_loss: 355.4825 - val_kl_loss: 3.1519 - val_disc_loss: 0.0123 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 262.7999 - reco_loss: 258.4751 - kl_loss: 3.3328 - disc_loss: 0.0251 - beta: 0.6320 - val_loss: 272.8094 - val_reco_loss: 268.0760 - val_kl_loss: 3.6134 - val_disc_loss: 0.0208 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 197.4610 - reco_loss: 192.8719 - kl_loss: 3.6716 - disc_loss: 0.0319 - beta: 0.7440 - val_loss: 192.4404 - val_reco_loss: 187.3928 - val_kl_loss: 3.9203 - val_disc_loss: 0.0176 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 201.5339 - reco_loss: 197.2120 - kl_loss: 2.2923 - disc_loss: 0.0443 - beta: 0.1560 - val_loss: 621.0005 - val_reco_loss: 618.7443 - val_kl_loss: 1.0225 - val_disc_loss: 7.6499e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 492.7096 - reco_loss: 490.3485 - kl_loss: 1.3629 - disc_loss: 0.0021 - beta: 0.2680 - val_loss: 532.9255 - val_reco_loss: 529.7925 - val_kl_loss: 1.7276 - val_disc_loss: 4.0406e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 427.5411 - reco_loss: 424.4333 - kl_loss: 1.9840 - disc_loss: 0.0024 - beta: 0.3800 - val_loss: 450.2020 - val_reco_loss: 446.3948 - val_kl_loss: 2.3054 - val_disc_loss: 0.0021 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 337.8521 - reco_loss: 334.0956 - kl_loss: 2.5696 - disc_loss: 0.0051 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 337.8481 - reco_loss: 334.0914 - kl_loss: 2.5695 - disc_loss: 0.0051 - beta: 0.4920 - val_loss: 367.7932 - val_reco_loss: 363.5988 - val_kl_loss: 2.8391 - val_disc_loss: 0.0042 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 290.5940 - reco_loss: 286.2769 - kl_loss: 3.0830 - disc_loss: 0.0091 - beta: 0.6040 - val_loss: 291.2502 - val_reco_loss: 286.3794 - val_kl_loss: 3.3938 - val_disc_loss: 0.0048 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 215.0912 - reco_loss: 210.3235 - kl_loss: 3.5209 - disc_loss: 0.0116 - beta: 0.7160 - val_loss: 211.6970 - val_reco_loss: 206.6033 - val_kl_loss: 3.7163 - val_disc_loss: 0.0228 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 166.3565 - reco_loss: 161.4795 - kl_loss: 2.9893 - disc_loss: 0.0336 - beta: 0.1280 - val_loss: 610.8036 - val_reco_loss: 608.6901 - val_kl_loss: 0.8226 - val_disc_loss: 0.0060 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 485.6437 - reco_loss: 483.3637 - kl_loss: 1.1850 - disc_loss: 0.0039 - beta: 0.2400 - val_loss: 545.0543 - val_reco_loss: 542.2131 - val_kl_loss: 1.5566 - val_disc_loss: 0.0029 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 426.8396 - reco_loss: 423.8596 - kl_loss: 1.8375 - disc_loss: 0.0039 - beta: 0.3520 - val_loss: 465.4229 - val_reco_loss: 461.8275 - val_kl_loss: 2.1782 - val_disc_loss: 0.0030 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.1\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 55s 20ms/step - loss: 850.1170 - reco_loss: 848.9288 - kl_loss: 1.3261 - disc_loss: 0.1749 - beta: 0.2120 - val_loss: 704.8661 - val_reco_loss: 701.9733 - val_kl_loss: 2.1736 - val_disc_loss: 0.0117 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 529.1325 - reco_loss: 525.9800 - kl_loss: 2.6136 - disc_loss: 0.0211 - beta: 0.3240 - val_loss: 563.1852 - val_reco_loss: 559.2925 - val_kl_loss: 3.0553 - val_disc_loss: 0.0118 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 411.5926 - reco_loss: 407.5735 - kl_loss: 3.3451 - disc_loss: 0.0243 - beta: 0.4360 - val_loss: 439.9619 - val_reco_loss: 434.9737 - val_kl_loss: 4.0437 - val_disc_loss: 0.0133 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 342.2498 - reco_loss: 337.6436 - kl_loss: 3.8313 - disc_loss: 0.0331 - beta: 0.5480 - val_loss: 361.1540 - val_reco_loss: 355.4068 - val_kl_loss: 4.7473 - val_disc_loss: 0.0986 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 259.1156 - reco_loss: 254.3632 - kl_loss: 3.9126 - disc_loss: 0.0611 - beta: 0.6600 - val_loss: 267.3261 - val_reco_loss: 261.6948 - val_kl_loss: 4.8137 - val_disc_loss: 0.1305 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 197.1305 - reco_loss: 192.4986 - kl_loss: 3.9077 - disc_loss: 0.1001 - beta: 0.7720 - val_loss: 182.5066 - val_reco_loss: 176.6644 - val_kl_loss: 5.0913 - val_disc_loss: 0.1966 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 291.5672 - reco_loss: 288.2122 - kl_loss: 1.6601 - disc_loss: 0.0874 - beta: 0.1840 - val_loss: 628.0082 - val_reco_loss: 625.4338 - val_kl_loss: 1.5163 - val_disc_loss: 0.0067 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 475.4984 - reco_loss: 472.9665 - kl_loss: 1.6586 - disc_loss: 0.0103 - beta: 0.2960 - val_loss: 520.6314 - val_reco_loss: 516.9738 - val_kl_loss: 2.3173 - val_disc_loss: 0.0047 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 430.5814 - reco_loss: 427.2751 - kl_loss: 2.3344 - disc_loss: 0.0109 - beta: 0.4080 - val_loss: 423.8399 - val_reco_loss: 419.4196 - val_kl_loss: 3.1179 - val_disc_loss: 0.0039 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 369.0254 - reco_loss: 364.5493 - kl_loss: 3.1760 - disc_loss: 0.0164 - beta: 0.5200 - val_loss: 349.0721 - val_reco_loss: 344.4117 - val_kl_loss: 3.5029 - val_disc_loss: 0.0304 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 277.5616 - reco_loss: 273.1417 - kl_loss: 3.3199 - disc_loss: 0.0147 - beta: 0.6320 - val_loss: 271.5563 - val_reco_loss: 266.1746 - val_kl_loss: 4.0851 - val_disc_loss: 0.0322 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 3178691.4038 - reco_loss: 3135332.3269 - kl_loss: 111018.0391 - disc_loss: 0.0205 - beta: 0.7440 - val_loss: 191.4483 - val_reco_loss: 186.2558 - val_kl_loss: 4.2285 - val_disc_loss: 0.0645 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 216.2936 - reco_loss: 211.9348 - kl_loss: 2.2515 - disc_loss: 0.0499 - beta: 0.1560 - val_loss: 605.0506 - val_reco_loss: 602.6985 - val_kl_loss: 1.1553 - val_disc_loss: 7.0519e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 495.6600 - reco_loss: 493.2150 - kl_loss: 1.3669 - disc_loss: 0.0025 - beta: 0.2680 - val_loss: 521.2659 - val_reco_loss: 518.1110 - val_kl_loss: 1.8659 - val_disc_loss: 6.0239e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 40787304541462994944.0000 - reco_loss: 39088638438241918976.0000 - kl_loss: 3897498790361300992.0000 - disc_loss: 8.8039 - beta: 0.3800 - val_loss: 445.9935 - val_reco_loss: 442.0060 - val_kl_loss: 2.6664 - val_disc_loss: 0.0023 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 342.8429 - reco_loss: 339.1320 - kl_loss: 2.6160 - disc_loss: 0.0022 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 342.8441 - reco_loss: 339.1331 - kl_loss: 2.6159 - disc_loss: 0.0022 - beta: 0.4920 - val_loss: 366.6371 - val_reco_loss: 362.1501 - val_kl_loss: 3.2747 - val_disc_loss: 0.0040 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 287.3351 - reco_loss: 283.2237 - kl_loss: 3.1181 - disc_loss: 0.0041 - beta: 0.6040 - val_loss: 285.2876 - val_reco_loss: 280.3819 - val_kl_loss: 3.7748 - val_disc_loss: 0.0025 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 228.6020 - reco_loss: 224.0794 - kl_loss: 3.5494 - disc_loss: 0.0103 - beta: 0.7160 - val_loss: 205.3480 - val_reco_loss: 200.1656 - val_kl_loss: 4.1328 - val_disc_loss: 0.0174 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 173.5160 - reco_loss: 168.8975 - kl_loss: 2.9830 - disc_loss: 0.0285 - beta: 0.1280 - val_loss: 613.7145 - val_reco_loss: 611.4332 - val_kl_loss: 0.8876 - val_disc_loss: 0.0131 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 505.8773 - reco_loss: 503.4993 - kl_loss: 1.1796 - disc_loss: 0.0161 - beta: 0.2400 - val_loss: 541.8738 - val_reco_loss: 538.6812 - val_kl_loss: 1.6918 - val_disc_loss: 0.0217 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 429.7060 - reco_loss: 426.7124 - kl_loss: 1.8465 - disc_loss: 0.0156 - beta: 0.3520 - val_loss: 459.3730 - val_reco_loss: 455.5053 - val_kl_loss: 2.3889 - val_disc_loss: 0.0040 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 0.1\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 56s 20ms/step - loss: 903.8048 - reco_loss: 903.0350 - kl_loss: 0.7307 - disc_loss: 0.2133 - beta: 0.2120 - val_loss: 590.9003 - val_reco_loss: 588.6526 - val_kl_loss: 1.5786 - val_disc_loss: 0.0514 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 526.2101 - reco_loss: 523.9062 - kl_loss: 1.6602 - disc_loss: 0.0264 - beta: 0.3240 - val_loss: 507.0747 - val_reco_loss: 503.5758 - val_kl_loss: 2.3947 - val_disc_loss: 0.0441 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 434.2809 - reco_loss: 431.1887 - kl_loss: 2.3033 - disc_loss: 0.0227 - beta: 0.4360 - val_loss: 422.5381 - val_reco_loss: 418.6073 - val_kl_loss: 2.9103 - val_disc_loss: 0.0394 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 347.0283 - reco_loss: 343.4161 - kl_loss: 2.7667 - disc_loss: 0.0385 - beta: 0.5480 - val_loss: 334.7581 - val_reco_loss: 329.9851 - val_kl_loss: 3.5224 - val_disc_loss: 0.0272 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 264.7506 - reco_loss: 260.7596 - kl_loss: 3.1459 - disc_loss: 0.0330 - beta: 0.6600 - val_loss: 247.7665 - val_reco_loss: 243.1368 - val_kl_loss: 3.6628 - val_disc_loss: 0.0241 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 197.1843 - reco_loss: 192.9492 - kl_loss: 3.3378 - disc_loss: 0.0399 - beta: 0.7720 - val_loss: 169.6414 - val_reco_loss: 164.7939 - val_kl_loss: 3.8665 - val_disc_loss: 0.0260 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 295.8982 - reco_loss: 292.6543 - kl_loss: 1.4911 - disc_loss: 0.0221 - beta: 0.1840 - val_loss: 583.9470 - val_reco_loss: 581.6059 - val_kl_loss: 1.2516 - val_disc_loss: 0.0048 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 499.4388 - reco_loss: 496.9831 - kl_loss: 1.4865 - disc_loss: 0.0028 - beta: 0.2960 - val_loss: 491.7606 - val_reco_loss: 488.4538 - val_kl_loss: 1.9308 - val_disc_loss: 7.9575e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 406.8904 - reco_loss: 403.7424 - kl_loss: 2.0478 - disc_loss: 0.0047 - beta: 0.4080 - val_loss: 426.7698 - val_reco_loss: 422.8575 - val_kl_loss: 2.5898 - val_disc_loss: 5.6489e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 10554288.0865 - reco_loss: 305310.3224 - kl_loss: 176724576.0000 - disc_loss: 1.0389 - beta: 0.5200 - val_loss: 351.6983 - val_reco_loss: 347.3395 - val_kl_loss: 3.1646 - val_disc_loss: 0.0269 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 359.3040 - reco_loss: 297.0370 - kl_loss: 510.0145 - disc_loss: 0.0123 - beta: 0.6320 - val_loss: 267.3755 - val_reco_loss: 262.8387 - val_kl_loss: 3.5493 - val_disc_loss: 0.0084 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 200.9649 - reco_loss: 196.6195 - kl_loss: 3.3360 - disc_loss: 0.0141 - beta: 0.7440 - val_loss: 186.5432 - val_reco_loss: 181.4306 - val_kl_loss: 3.7097 - val_disc_loss: 0.0126 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 203.9135 - reco_loss: 199.7488 - kl_loss: 2.1411 - disc_loss: 0.0272 - beta: 0.1560 - val_loss: 585.9999 - val_reco_loss: 583.8748 - val_kl_loss: 1.0397 - val_disc_loss: 8.7235e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 514.0807 - reco_loss: 511.7363 - kl_loss: 1.2864 - disc_loss: 0.0018 - beta: 0.2680 - val_loss: 505.6461 - val_reco_loss: 502.5635 - val_kl_loss: 1.7763 - val_disc_loss: 4.6385e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 1639.7178 - reco_loss: 1610.5080 - kl_loss: 18.4103 - disc_loss: 0.0022 - beta: 0.3800 - val_loss: 437.2462 - val_reco_loss: 433.5535 - val_kl_loss: 2.4239 - val_disc_loss: 0.0011 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 351.5187 - reco_loss: 347.8576 - kl_loss: 2.4430 - disc_loss: 0.0034 - beta: 0.4920\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 351.5125 - reco_loss: 347.8513 - kl_loss: 2.4430 - disc_loss: 0.0034 - beta: 0.4920 - val_loss: 360.0149 - val_reco_loss: 355.6714 - val_kl_loss: 2.9686 - val_disc_loss: 2.1442e-04 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 281.8856 - reco_loss: 277.8695 - kl_loss: 2.9211 - disc_loss: 0.0027 - beta: 0.6040 - val_loss: 280.4536 - val_reco_loss: 275.6546 - val_kl_loss: 3.5509 - val_disc_loss: 9.1750e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 98950877.8661 - reco_loss: 97326662.5729 - kl_loss: 2485412.7500 - disc_loss: 0.7188 - beta: 0.7160 - val_loss: 200.4225 - val_reco_loss: 195.3767 - val_kl_loss: 4.0014 - val_disc_loss: 0.0186 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 571032920665927517414096896.0000 - reco_loss: 258273612620882418639831040.0000 - kl_loss: 981201944616305477417959424.0000 - disc_loss: 0.0492 - beta: 0.1280 - val_loss: 612.4108 - val_reco_loss: 610.1971 - val_kl_loss: 0.9013 - val_disc_loss: 0.0025 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 328044799.5858 - reco_loss: 326393165.9949 - kl_loss: 1735603.0000 - disc_loss: 0.0041 - beta: 0.2400 - val_loss: 537.8279 - val_reco_loss: 534.8895 - val_kl_loss: 1.6698 - val_disc_loss: 4.2395e-04 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 411.7965 - reco_loss: 408.9504 - kl_loss: 1.7658 - disc_loss: 0.0018 - beta: 0.3520 - val_loss: 450.6133 - val_reco_loss: 446.9824 - val_kl_loss: 2.3329 - val_disc_loss: 0.0030 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 55s 20ms/step - loss: 919.7610 - reco_loss: 915.0558 - kl_loss: 1.8511 - disc_loss: 0.2782 - beta: 0.2120 - val_loss: 720.8732 - val_reco_loss: 710.2339 - val_kl_loss: 5.6102 - val_disc_loss: 0.2070 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 589.4994 - reco_loss: 581.3452 - kl_loss: 3.2129 - disc_loss: 0.2015 - beta: 0.3240 - val_loss: 536.0080 - val_reco_loss: 525.2058 - val_kl_loss: 6.1073 - val_disc_loss: 0.2684 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 429.9494 - reco_loss: 422.2438 - kl_loss: 3.5881 - disc_loss: 0.3175 - beta: 0.4360 - val_loss: 431.5644 - val_reco_loss: 422.1952 - val_kl_loss: 5.5306 - val_disc_loss: 0.5908 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 356.7944 - reco_loss: 348.5867 - kl_loss: 3.7958 - disc_loss: 0.2984 - beta: 0.5480 - val_loss: 353.5202 - val_reco_loss: 343.4983 - val_kl_loss: 5.4293 - val_disc_loss: 0.2175 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 283.6137 - reco_loss: 275.6253 - kl_loss: 3.8782 - disc_loss: 0.3826 - beta: 0.6600 - val_loss: 262.1842 - val_reco_loss: 253.2665 - val_kl_loss: 5.2765 - val_disc_loss: 0.5056 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 204.5284 - reco_loss: 197.4910 - kl_loss: 3.7889 - disc_loss: 0.5443 - beta: 0.7720 - val_loss: 180.5769 - val_reco_loss: 172.5833 - val_kl_loss: 4.4924 - val_disc_loss: 0.4601 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 305.6430 - reco_loss: 300.0159 - kl_loss: 1.6282 - disc_loss: 0.5286 - beta: 0.1840 - val_loss: 627.8193 - val_reco_loss: 620.6349 - val_kl_loss: 1.3317 - val_disc_loss: 0.9232 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 474.9095 - reco_loss: 469.4007 - kl_loss: 1.5689 - disc_loss: 0.5055 - beta: 0.2960 - val_loss: 522.8981 - val_reco_loss: 516.2620 - val_kl_loss: 2.1301 - val_disc_loss: 0.2571 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 354904.8842 - reco_loss: 351006.5529 - kl_loss: 3168.8484 - disc_loss: 0.3843 - beta: 0.4080 - val_loss: 453.8006 - val_reco_loss: 445.8456 - val_kl_loss: 2.8059 - val_disc_loss: 0.3296 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 341.0743 - reco_loss: 334.6636 - kl_loss: 2.7372 - disc_loss: 0.5845 - beta: 0.5200 - val_loss: 370.4361 - val_reco_loss: 362.9069 - val_kl_loss: 3.3390 - val_disc_loss: 0.6616 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 390.2473 - reco_loss: 314.5441 - kl_loss: 215.7632 - disc_loss: 0.4618 - beta: 0.6320 - val_loss: 282.9645 - val_reco_loss: 275.2941 - val_kl_loss: 3.7942 - val_disc_loss: 0.5970 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 203.1327 - reco_loss: 195.9563 - kl_loss: 3.5421 - disc_loss: 0.4408 - beta: 0.7440 - val_loss: 200.1206 - val_reco_loss: 191.9625 - val_kl_loss: 4.0532 - val_disc_loss: 0.3125 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 214.6499 - reco_loss: 208.0172 - kl_loss: 2.2434 - disc_loss: 0.4943 - beta: 0.1560 - val_loss: 646.9672 - val_reco_loss: 640.0037 - val_kl_loss: 1.0647 - val_disc_loss: 0.2239 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 497.2204 - reco_loss: 491.3372 - kl_loss: 1.3536 - disc_loss: 0.3078 - beta: 0.2680 - val_loss: 562.5940 - val_reco_loss: 555.8427 - val_kl_loss: 1.7589 - val_disc_loss: 0.1803 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 2327396.4235 - reco_loss: 2326074.2632 - kl_loss: 5123.8218 - disc_loss: 0.3590 - beta: 0.3800 - val_loss: 462.4000 - val_reco_loss: 455.7717 - val_kl_loss: 2.4603 - val_disc_loss: 0.5020 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 368.4802 - reco_loss: 361.5763 - kl_loss: 2.6068 - disc_loss: 0.3717 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 368.4569 - reco_loss: 361.5528 - kl_loss: 2.6067 - disc_loss: 0.3717 - beta: 0.4920 - val_loss: 387.6305 - val_reco_loss: 380.4001 - val_kl_loss: 3.0848 - val_disc_loss: 0.3578 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 290.4091 - reco_loss: 283.0177 - kl_loss: 3.1104 - disc_loss: 0.3215 - beta: 0.6040 - val_loss: 302.6893 - val_reco_loss: 294.8466 - val_kl_loss: 3.4965 - val_disc_loss: 0.3403 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 17488663.2439 - reco_loss: 17424068.9604 - kl_loss: 147985.2344 - disc_loss: 0.7810 - beta: 0.7160 - val_loss: 217.3355 - val_reco_loss: 209.8826 - val_kl_loss: 4.0211 - val_disc_loss: 0.4335 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 16669.5693 - reco_loss: 16550.8333 - kl_loss: 336.7690 - disc_loss: 0.5279 - beta: 0.1280 - val_loss: 644.8314 - val_reco_loss: 640.0553 - val_kl_loss: 0.8604 - val_disc_loss: 0.3092 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 512.9934 - reco_loss: 507.5001 - kl_loss: 1.1950 - disc_loss: 0.2813 - beta: 0.2400 - val_loss: 565.1713 - val_reco_loss: 558.8051 - val_kl_loss: 1.6140 - val_disc_loss: 0.1568 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 463.1656 - reco_loss: 456.2462 - kl_loss: 25.0296 - disc_loss: 0.2367 - beta: 0.3520 - val_loss: 486.0361 - val_reco_loss: 478.8831 - val_kl_loss: 2.2880 - val_disc_loss: 0.2006 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 58s 20ms/step - loss: 921.0800 - reco_loss: 916.6000 - kl_loss: 1.1515 - disc_loss: 0.2806 - beta: 0.2120 - val_loss: 655.9702 - val_reco_loss: 649.9935 - val_kl_loss: 2.0497 - val_disc_loss: 0.1620 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 511.4229 - reco_loss: 504.7185 - kl_loss: 2.5973 - disc_loss: 0.2512 - beta: 0.3240 - val_loss: 524.1372 - val_reco_loss: 515.8071 - val_kl_loss: 3.1714 - val_disc_loss: 0.2990 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 420.1138 - reco_loss: 412.0975 - kl_loss: 3.4121 - disc_loss: 0.2360 - beta: 0.4360 - val_loss: 427.4702 - val_reco_loss: 417.8898 - val_kl_loss: 3.8264 - val_disc_loss: 0.1828 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 377.0609 - reco_loss: 369.2115 - kl_loss: 3.6905 - disc_loss: 0.3077 - beta: 0.5480 - val_loss: 345.8879 - val_reco_loss: 338.0700 - val_kl_loss: 3.9218 - val_disc_loss: 0.6106 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 280.1918 - reco_loss: 273.0707 - kl_loss: 3.8175 - disc_loss: 0.4424 - beta: 0.6600 - val_loss: 259.9983 - val_reco_loss: 253.0093 - val_kl_loss: 4.0502 - val_disc_loss: 0.4086 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 215.0870 - reco_loss: 208.3419 - kl_loss: 3.9518 - disc_loss: 0.5203 - beta: 0.7720 - val_loss: 167.7028 - val_reco_loss: 161.0427 - val_kl_loss: 4.1438 - val_disc_loss: 0.3571 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 306.8973 - reco_loss: 301.6237 - kl_loss: 1.6816 - disc_loss: 0.5032 - beta: 0.1840 - val_loss: 598.2318 - val_reco_loss: 593.8154 - val_kl_loss: 1.2807 - val_disc_loss: 0.4930 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 504.8928 - reco_loss: 499.8423 - kl_loss: 1.5986 - disc_loss: 0.3573 - beta: 0.2960 - val_loss: 497.0091 - val_reco_loss: 491.4073 - val_kl_loss: 1.9974 - val_disc_loss: 0.1994 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 420.9327 - reco_loss: 415.4558 - kl_loss: 2.2273 - disc_loss: 0.4390 - beta: 0.4080 - val_loss: 435.3175 - val_reco_loss: 429.4600 - val_kl_loss: 2.5838 - val_disc_loss: 0.6444 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 366.5259 - reco_loss: 359.9827 - kl_loss: 2.7568 - disc_loss: 0.3324 - beta: 0.5200 - val_loss: 349.1491 - val_reco_loss: 343.3405 - val_kl_loss: 3.0173 - val_disc_loss: 0.7241 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 299.0660 - reco_loss: 292.9505 - kl_loss: 3.2100 - disc_loss: 0.5976 - beta: 0.6320 - val_loss: 274.0627 - val_reco_loss: 267.7986 - val_kl_loss: 3.4900 - val_disc_loss: 0.3651 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 107889776083.6310 - reco_loss: 106885644505.8445 - kl_loss: 2999013120.0000 - disc_loss: 8.3542 - beta: 0.7440 - val_loss: 190.5705 - val_reco_loss: 182.2372 - val_kl_loss: 3.8043 - val_disc_loss: 0.1538 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 215.0683 - reco_loss: 207.8552 - kl_loss: 2.2123 - disc_loss: 0.2713 - beta: 0.1560 - val_loss: 606.3011 - val_reco_loss: 602.1159 - val_kl_loss: 1.0172 - val_disc_loss: 0.3322 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 498.2833 - reco_loss: 493.4260 - kl_loss: 1.3370 - disc_loss: 0.3102 - beta: 0.2680 - val_loss: 525.1242 - val_reco_loss: 519.4708 - val_kl_loss: 1.6792 - val_disc_loss: 0.3597 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 447.5732 - reco_loss: 441.6577 - kl_loss: 1.9640 - disc_loss: 0.3110 - beta: 0.3800 - val_loss: 437.6577 - val_reco_loss: 430.4398 - val_kl_loss: 2.2678 - val_disc_loss: 0.1227 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 378.2909 - reco_loss: 371.2860 - kl_loss: 2.5102 - disc_loss: 0.1827 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 378.2694 - reco_loss: 371.2643 - kl_loss: 2.5101 - disc_loss: 0.1828 - beta: 0.4920 - val_loss: 370.8550 - val_reco_loss: 363.8750 - val_kl_loss: 2.7740 - val_disc_loss: 0.1494 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 310.2402 - reco_loss: 303.4976 - kl_loss: 3.0259 - disc_loss: 0.3251 - beta: 0.6040 - val_loss: 289.6036 - val_reco_loss: 283.3543 - val_kl_loss: 3.2799 - val_disc_loss: 0.2447 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 224.0950 - reco_loss: 217.6671 - kl_loss: 3.4671 - disc_loss: 0.4215 - beta: 0.7160 - val_loss: 206.9393 - val_reco_loss: 200.8453 - val_kl_loss: 3.6771 - val_disc_loss: 0.4855 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 170.3161 - reco_loss: 163.7751 - kl_loss: 2.9507 - disc_loss: 0.4871 - beta: 0.1280 - val_loss: 617.1912 - val_reco_loss: 611.8029 - val_kl_loss: 0.8084 - val_disc_loss: 0.1291 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 502.5772 - reco_loss: 497.0103 - kl_loss: 1.1763 - disc_loss: 0.1229 - beta: 0.2400 - val_loss: 537.4080 - val_reco_loss: 530.6685 - val_kl_loss: 1.5055 - val_disc_loss: 0.0944 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 463.6510 - reco_loss: 457.0600 - kl_loss: 1.8293 - disc_loss: 0.1182 - beta: 0.3520 - val_loss: 467.5266 - val_reco_loss: 461.7244 - val_kl_loss: 2.0967 - val_disc_loss: 0.3806 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 55s 20ms/step - loss: 920.1136 - reco_loss: 915.9027 - kl_loss: 0.8636 - disc_loss: 0.2200 - beta: 0.2120 - val_loss: 719.5947 - val_reco_loss: 712.7090 - val_kl_loss: 1.6586 - val_disc_loss: 0.1123 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 524.6926 - reco_loss: 518.4918 - kl_loss: 1.8547 - disc_loss: 0.1993 - beta: 0.3240 - val_loss: 538.6884 - val_reco_loss: 532.4615 - val_kl_loss: 2.8076 - val_disc_loss: 0.3455 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 448.0656 - reco_loss: 441.7256 - kl_loss: 2.5249 - disc_loss: 0.3080 - beta: 0.4360 - val_loss: 440.8631 - val_reco_loss: 434.1981 - val_kl_loss: 3.7273 - val_disc_loss: 0.3589 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 340.9289 - reco_loss: 334.4096 - kl_loss: 3.0585 - disc_loss: 0.3576 - beta: 0.5480 - val_loss: 363.6507 - val_reco_loss: 355.1163 - val_kl_loss: 4.4829 - val_disc_loss: 0.3511 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 280.8394 - reco_loss: 273.8111 - kl_loss: 3.4462 - disc_loss: 0.4158 - beta: 0.6600 - val_loss: 265.6334 - val_reco_loss: 257.5031 - val_kl_loss: 4.6413 - val_disc_loss: 0.3595 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 204.3876 - reco_loss: 197.4675 - kl_loss: 3.7112 - disc_loss: 0.4877 - beta: 0.7720 - val_loss: 182.2752 - val_reco_loss: 174.1115 - val_kl_loss: 4.8860 - val_disc_loss: 0.8334 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 314.8427 - reco_loss: 308.1893 - kl_loss: 1.6221 - disc_loss: 0.2785 - beta: 0.1840 - val_loss: 599.0763 - val_reco_loss: 592.4307 - val_kl_loss: 1.5364 - val_disc_loss: 0.1763 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 468.0744 - reco_loss: 461.9772 - kl_loss: 1.5820 - disc_loss: 0.2263 - beta: 0.2960 - val_loss: 516.7147 - val_reco_loss: 508.8249 - val_kl_loss: 2.5546 - val_disc_loss: 0.1081 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 442.3899 - reco_loss: 435.3680 - kl_loss: 2.2482 - disc_loss: 0.2293 - beta: 0.4080 - val_loss: 432.9909 - val_reco_loss: 424.0273 - val_kl_loss: 3.2822 - val_disc_loss: 0.1533 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 355.9599 - reco_loss: 348.3929 - kl_loss: 2.8258 - disc_loss: 0.2321 - beta: 0.5200 - val_loss: 342.8595 - val_reco_loss: 334.0928 - val_kl_loss: 3.9496 - val_disc_loss: 0.1999 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 691.0592 - reco_loss: 677.0281 - kl_loss: 19.9430 - disc_loss: 0.1502 - beta: 0.6320 - val_loss: 265.1520 - val_reco_loss: 257.0265 - val_kl_loss: 4.3653 - val_disc_loss: 0.4403 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 213.8377 - reco_loss: 205.9093 - kl_loss: 3.6415 - disc_loss: 0.4166 - beta: 0.7440 - val_loss: 192.4514 - val_reco_loss: 182.2408 - val_kl_loss: 4.6375 - val_disc_loss: 0.4846 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 216.3255 - reco_loss: 208.2276 - kl_loss: 2.3983 - disc_loss: 0.4756 - beta: 0.1560 - val_loss: 615.0651 - val_reco_loss: 608.9692 - val_kl_loss: 1.2270 - val_disc_loss: 0.2296 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 541.8648 - reco_loss: 535.6519 - kl_loss: 1.3602 - disc_loss: 0.1733 - beta: 0.2680 - val_loss: 518.5355 - val_reco_loss: 511.4330 - val_kl_loss: 2.0205 - val_disc_loss: 0.1171 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 444.8514 - reco_loss: 437.7743 - kl_loss: 2.0083 - disc_loss: 0.1782 - beta: 0.3800 - val_loss: 450.3100 - val_reco_loss: 441.1068 - val_kl_loss: 2.7629 - val_disc_loss: 0.0558 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 385.8851 - reco_loss: 377.6111 - kl_loss: 2.6216 - disc_loss: 0.1692 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 385.8544 - reco_loss: 377.5806 - kl_loss: 2.6228 - disc_loss: 0.1693 - beta: 0.4920 - val_loss: 392.6461 - val_reco_loss: 382.2237 - val_kl_loss: 3.4592 - val_disc_loss: 0.0939 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 318.3095 - reco_loss: 310.4585 - kl_loss: 3.1634 - disc_loss: 0.2090 - beta: 0.6040 - val_loss: 323.2622 - val_reco_loss: 315.0364 - val_kl_loss: 3.9763 - val_disc_loss: 0.2482 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 223.4274 - reco_loss: 215.0645 - kl_loss: 3.5917 - disc_loss: 0.1822 - beta: 0.7160 - val_loss: 221.2561 - val_reco_loss: 211.1743 - val_kl_loss: 4.2152 - val_disc_loss: 0.2393 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 176.1097 - reco_loss: 167.8376 - kl_loss: 3.0813 - disc_loss: 0.2768 - beta: 0.1280 - val_loss: 639.9441 - val_reco_loss: 633.1813 - val_kl_loss: 0.9530 - val_disc_loss: 0.0849 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 499.4242 - reco_loss: 493.4046 - kl_loss: 1.2092 - disc_loss: 0.1323 - beta: 0.2400 - val_loss: 551.9332 - val_reco_loss: 544.7766 - val_kl_loss: 1.7441 - val_disc_loss: 0.0888 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 436.5323 - reco_loss: 429.5398 - kl_loss: 1.8739 - disc_loss: 0.1409 - beta: 0.3520 - val_loss: 506.0124 - val_reco_loss: 498.4042 - val_kl_loss: 2.4689 - val_disc_loss: 0.1767 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 55s 20ms/step - loss: 975.1433 - reco_loss: 970.9679 - kl_loss: 1.4497 - disc_loss: 0.2837 - beta: 0.2120 - val_loss: 641.3277 - val_reco_loss: 635.2257 - val_kl_loss: 2.6684 - val_disc_loss: 0.3729 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 519.1662 - reco_loss: 512.7096 - kl_loss: 2.6828 - disc_loss: 0.3170 - beta: 0.3240 - val_loss: 534.9355 - val_reco_loss: 526.9331 - val_kl_loss: 3.7121 - val_disc_loss: 0.3751 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 437.1151 - reco_loss: 430.1188 - kl_loss: 3.1937 - disc_loss: 0.3526 - beta: 0.4360 - val_loss: 461.5397 - val_reco_loss: 452.3107 - val_kl_loss: 4.3500 - val_disc_loss: 0.3833 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 351.7824 - reco_loss: 344.7940 - kl_loss: 3.4580 - disc_loss: 0.4339 - beta: 0.5480 - val_loss: 353.4633 - val_reco_loss: 344.9544 - val_kl_loss: 4.7100 - val_disc_loss: 0.3640 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 281.5439 - reco_loss: 274.7331 - kl_loss: 3.5754 - disc_loss: 0.4940 - beta: 0.6600 - val_loss: 266.3379 - val_reco_loss: 259.1333 - val_kl_loss: 4.4561 - val_disc_loss: 0.6002 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 203.0868 - reco_loss: 196.7095 - kl_loss: 3.6700 - disc_loss: 0.5681 - beta: 0.7720 - val_loss: 182.5075 - val_reco_loss: 175.5657 - val_kl_loss: 4.6023 - val_disc_loss: 0.5593 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 297.4787 - reco_loss: 292.1612 - kl_loss: 1.5994 - disc_loss: 0.4787 - beta: 0.1840 - val_loss: 629.0515 - val_reco_loss: 623.8909 - val_kl_loss: 1.4288 - val_disc_loss: 0.3800 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 503.8680 - reco_loss: 498.8106 - kl_loss: 1.5111 - disc_loss: 0.3847 - beta: 0.2960 - val_loss: 534.9416 - val_reco_loss: 529.7009 - val_kl_loss: 2.2328 - val_disc_loss: 0.2741 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 409.4132 - reco_loss: 403.7971 - kl_loss: 2.1191 - disc_loss: 0.3974 - beta: 0.4080 - val_loss: 460.5152 - val_reco_loss: 453.7504 - val_kl_loss: 3.0494 - val_disc_loss: 0.3155 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 445.4006 - reco_loss: 439.4372 - kl_loss: 2.6539 - disc_loss: 0.4677 - beta: 0.5200 - val_loss: 365.5859 - val_reco_loss: 358.9893 - val_kl_loss: 3.4765 - val_disc_loss: 0.5104 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 280.3244 - reco_loss: 274.1891 - kl_loss: 2.9743 - disc_loss: 0.5431 - beta: 0.6320 - val_loss: 278.6335 - val_reco_loss: 272.5122 - val_kl_loss: 3.9094 - val_disc_loss: 0.6734 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 244.1044 - reco_loss: 238.0762 - kl_loss: 3.4931 - disc_loss: 0.5622 - beta: 0.7440 - val_loss: 195.9008 - val_reco_loss: 189.3099 - val_kl_loss: 4.2424 - val_disc_loss: 0.3824 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1379678.3939 - reco_loss: 1352480.7036 - kl_loss: 46323.7969 - disc_loss: 0.4429 - beta: 0.1560 - val_loss: 638.2902 - val_reco_loss: 634.0838 - val_kl_loss: 1.1697 - val_disc_loss: 0.4905 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 526.0362 - reco_loss: 521.4839 - kl_loss: 1.2547 - disc_loss: 0.3428 - beta: 0.2680 - val_loss: 536.6015 - val_reco_loss: 530.9943 - val_kl_loss: 1.9364 - val_disc_loss: 0.3945 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 429.0305 - reco_loss: 423.4440 - kl_loss: 1.8250 - disc_loss: 0.3427 - beta: 0.3800 - val_loss: 463.2171 - val_reco_loss: 457.6209 - val_kl_loss: 2.5860 - val_disc_loss: 0.6516 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 359.8541 - reco_loss: 353.8109 - kl_loss: 2.3415 - disc_loss: 0.4051 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 359.8458 - reco_loss: 353.8026 - kl_loss: 2.3416 - disc_loss: 0.4051 - beta: 0.4920 - val_loss: 380.7105 - val_reco_loss: 374.7169 - val_kl_loss: 3.2872 - val_disc_loss: 0.4433 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 289.1430 - reco_loss: 283.1120 - kl_loss: 2.8252 - disc_loss: 0.4408 - beta: 0.6040 - val_loss: 294.1386 - val_reco_loss: 287.2753 - val_kl_loss: 3.7655 - val_disc_loss: 0.3223 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 233.6896 - reco_loss: 226.7215 - kl_loss: 3.1934 - disc_loss: 0.3020 - beta: 0.7160 - val_loss: 217.8124 - val_reco_loss: 210.8873 - val_kl_loss: 4.1872 - val_disc_loss: 0.4392 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 173.2658 - reco_loss: 167.0837 - kl_loss: 2.7161 - disc_loss: 0.5512 - beta: 0.1280 - val_loss: 636.2514 - val_reco_loss: 632.1287 - val_kl_loss: 0.9046 - val_disc_loss: 0.2377 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 520.4805 - reco_loss: 516.0084 - kl_loss: 1.0725 - disc_loss: 0.2910 - beta: 0.2400 - val_loss: 556.5267 - val_reco_loss: 551.0903 - val_kl_loss: 1.6758 - val_disc_loss: 0.2282 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 463.1847 - reco_loss: 457.9350 - kl_loss: 1.6634 - disc_loss: 0.2846 - beta: 0.3520 - val_loss: 478.1965 - val_reco_loss: 472.5596 - val_kl_loss: 2.3708 - val_disc_loss: 0.3327 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 56s 20ms/step - loss: 1027.8548 - reco_loss: 1023.3836 - kl_loss: 0.7395 - disc_loss: 0.2030 - beta: 0.2120 - val_loss: 721.4841 - val_reco_loss: 715.1837 - val_kl_loss: 1.7625 - val_disc_loss: 0.1816 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 529.3264 - reco_loss: 523.2505 - kl_loss: 1.9120 - disc_loss: 0.3074 - beta: 0.3240 - val_loss: 545.2018 - val_reco_loss: 537.9688 - val_kl_loss: 3.1313 - val_disc_loss: 0.3845 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 420.0475 - reco_loss: 414.2660 - kl_loss: 2.6916 - disc_loss: 0.5235 - beta: 0.4360 - val_loss: 404.0848 - val_reco_loss: 395.4644 - val_kl_loss: 4.5508 - val_disc_loss: 0.3480 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 339.9044 - reco_loss: 333.8211 - kl_loss: 3.2297 - disc_loss: 0.5537 - beta: 0.5480 - val_loss: 356.3204 - val_reco_loss: 347.2194 - val_kl_loss: 5.5204 - val_disc_loss: 0.4670 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 256.7279 - reco_loss: 250.5754 - kl_loss: 3.6229 - disc_loss: 0.5835 - beta: 0.6600 - val_loss: 282.7225 - val_reco_loss: 274.7155 - val_kl_loss: 5.3302 - val_disc_loss: 0.9930 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 201.6063 - reco_loss: 195.4185 - kl_loss: 3.7172 - disc_loss: 0.6377 - beta: 0.7720 - val_loss: 186.7775 - val_reco_loss: 178.4906 - val_kl_loss: 4.8782 - val_disc_loss: 0.3790 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 298.2384 - reco_loss: 293.0455 - kl_loss: 1.5905 - disc_loss: 0.6575 - beta: 0.1840 - val_loss: 677.3458 - val_reco_loss: 672.5238 - val_kl_loss: 1.6088 - val_disc_loss: 0.6773 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 457.5133 - reco_loss: 452.9150 - kl_loss: 1.5196 - disc_loss: 0.4847 - beta: 0.2960 - val_loss: 556.4511 - val_reco_loss: 550.7619 - val_kl_loss: 2.2572 - val_disc_loss: 0.3484 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 407.3494 - reco_loss: 402.1561 - kl_loss: 2.2345 - disc_loss: 0.5053 - beta: 0.4080 - val_loss: 492.0820 - val_reco_loss: 485.8673 - val_kl_loss: 2.9914 - val_disc_loss: 0.5073 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 343.7593 - reco_loss: 338.1014 - kl_loss: 2.6385 - disc_loss: 0.5772 - beta: 0.5200 - val_loss: 361.8641 - val_reco_loss: 355.8477 - val_kl_loss: 3.4179 - val_disc_loss: 0.7005 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 280.8722 - reco_loss: 275.0524 - kl_loss: 3.0419 - disc_loss: 0.5861 - beta: 0.6320 - val_loss: 283.8947 - val_reco_loss: 277.3346 - val_kl_loss: 3.9058 - val_disc_loss: 0.6223 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7440 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1560 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2680 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3800 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 55s 19ms/step - loss: 877.8562 - reco_loss: 874.0414 - kl_loss: 1.1870 - disc_loss: 0.3101 - beta: 0.2120 - val_loss: 639.8807 - val_reco_loss: 632.0601 - val_kl_loss: 3.2820 - val_disc_loss: 0.1120 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 556.2957 - reco_loss: 549.4605 - kl_loss: 2.5475 - disc_loss: 0.2136 - beta: 0.3240 - val_loss: 500.1159 - val_reco_loss: 489.2487 - val_kl_loss: 6.1320 - val_disc_loss: 0.2728 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 466.9822 - reco_loss: 459.3331 - kl_loss: 3.2080 - disc_loss: 0.2364 - beta: 0.4360 - val_loss: 412.0501 - val_reco_loss: 400.9742 - val_kl_loss: 6.4687 - val_disc_loss: 0.2824 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 356.9250 - reco_loss: 349.8961 - kl_loss: 3.3994 - disc_loss: 0.3972 - beta: 0.5480 - val_loss: 366.2602 - val_reco_loss: 356.4800 - val_kl_loss: 6.1806 - val_disc_loss: 0.5302 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 294.2147 - reco_loss: 287.6952 - kl_loss: 3.5386 - disc_loss: 0.5302 - beta: 0.6600 - val_loss: 254.2478 - val_reco_loss: 245.0166 - val_kl_loss: 6.0083 - val_disc_loss: 0.4031 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 219.6098 - reco_loss: 212.6770 - kl_loss: 4.2075 - disc_loss: 0.5571 - beta: 0.7720 - val_loss: 175.9652 - val_reco_loss: 167.7699 - val_kl_loss: 5.2920 - val_disc_loss: 0.5356 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 320.9266 - reco_loss: 315.1987 - kl_loss: 1.7269 - disc_loss: 0.4752 - beta: 0.1840 - val_loss: 624.2008 - val_reco_loss: 618.3759 - val_kl_loss: 1.7042 - val_disc_loss: 0.4487 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 500.8224 - reco_loss: 495.1264 - kl_loss: 1.7003 - disc_loss: 0.3579 - beta: 0.2960 - val_loss: 542.4896 - val_reco_loss: 532.7298 - val_kl_loss: 2.6907 - val_disc_loss: 0.1668 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 420.9137 - reco_loss: 413.9261 - kl_loss: 2.4088 - disc_loss: 0.3637 - beta: 0.4080 - val_loss: 438.6418 - val_reco_loss: 430.5401 - val_kl_loss: 3.6314 - val_disc_loss: 0.5530 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 353.6150 - reco_loss: 346.5007 - kl_loss: 3.0517 - disc_loss: 0.4258 - beta: 0.5200 - val_loss: 354.6649 - val_reco_loss: 345.4843 - val_kl_loss: 4.3251 - val_disc_loss: 0.4688 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 279.4967 - reco_loss: 272.1862 - kl_loss: 3.5068 - disc_loss: 0.4932 - beta: 0.6320 - val_loss: 270.7921 - val_reco_loss: 259.6925 - val_kl_loss: 4.7489 - val_disc_loss: 0.3669 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 113256829152.0707 - reco_loss: 111936834688.2199 - kl_loss: 5453035520.0000 - disc_loss: 0.4480 - beta: 0.7440 - val_loss: 198.2491 - val_reco_loss: 190.0243 - val_kl_loss: 4.9079 - val_disc_loss: 0.5503 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 213.8862 - reco_loss: 207.0604 - kl_loss: 2.3444 - disc_loss: 0.5510 - beta: 0.1560 - val_loss: 593.3560 - val_reco_loss: 587.5950 - val_kl_loss: 1.3108 - val_disc_loss: 0.2079 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 486.7572 - reco_loss: 480.9683 - kl_loss: 1.3935 - disc_loss: 0.2770 - beta: 0.2680 - val_loss: 553.3691 - val_reco_loss: 546.3764 - val_kl_loss: 2.2902 - val_disc_loss: 0.3075 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 429.0400 - reco_loss: 422.4059 - kl_loss: 2.0526 - disc_loss: 0.3077 - beta: 0.3800 - val_loss: 446.6429 - val_reco_loss: 439.4455 - val_kl_loss: 3.0937 - val_disc_loss: 0.5022 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 365.1743 - reco_loss: 358.2299 - kl_loss: 2.6825 - disc_loss: 0.3843 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 365.1710 - reco_loss: 358.2264 - kl_loss: 2.6824 - disc_loss: 0.3842 - beta: 0.4920 - val_loss: 361.5404 - val_reco_loss: 353.5076 - val_kl_loss: 3.7600 - val_disc_loss: 0.7978 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 299.5351 - reco_loss: 292.4288 - kl_loss: 3.2136 - disc_loss: 0.3520 - beta: 0.6040 - val_loss: 289.7633 - val_reco_loss: 280.6756 - val_kl_loss: 4.5071 - val_disc_loss: 0.5275 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 229.1948 - reco_loss: 221.1935 - kl_loss: 3.6223 - disc_loss: 0.2915 - beta: 0.7160 - val_loss: 207.7435 - val_reco_loss: 198.6768 - val_kl_loss: 4.9557 - val_disc_loss: 0.4659 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 3849.0949 - reco_loss: 3808.5828 - kl_loss: 99.0724 - disc_loss: 0.5247 - beta: 0.1280 - val_loss: 620.5984 - val_reco_loss: 615.7881 - val_kl_loss: 1.0492 - val_disc_loss: 0.4161 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 504.7856 - reco_loss: 499.4392 - kl_loss: 1.1976 - disc_loss: 0.3702 - beta: 0.2400 - val_loss: 538.5647 - val_reco_loss: 531.9389 - val_kl_loss: 1.9504 - val_disc_loss: 0.2655 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 433.4490 - reco_loss: 427.2265 - kl_loss: 1.8690 - disc_loss: 0.2498 - beta: 0.3520 - val_loss: 464.4761 - val_reco_loss: 457.1064 - val_kl_loss: 2.8071 - val_disc_loss: 0.1958 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 56s 20ms/step - loss: 842.4707 - reco_loss: 838.7468 - kl_loss: 0.9296 - disc_loss: 0.2859 - beta: 0.2120 - val_loss: 699.4178 - val_reco_loss: 693.8606 - val_kl_loss: 1.8714 - val_disc_loss: 0.1479 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 504.5331 - reco_loss: 498.6671 - kl_loss: 2.0873 - disc_loss: 0.2442 - beta: 0.3240 - val_loss: 524.6691 - val_reco_loss: 517.8061 - val_kl_loss: 3.2642 - val_disc_loss: 0.2133 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 431.2573 - reco_loss: 424.7461 - kl_loss: 2.9008 - disc_loss: 0.2653 - beta: 0.4360 - val_loss: 439.7080 - val_reco_loss: 431.1705 - val_kl_loss: 3.9592 - val_disc_loss: 0.1482 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 342.5567 - reco_loss: 334.7124 - kl_loss: 3.6624 - disc_loss: 0.2278 - beta: 0.5480 - val_loss: 353.1648 - val_reco_loss: 344.0304 - val_kl_loss: 4.7623 - val_disc_loss: 0.1781 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 277.8659 - reco_loss: 268.9725 - kl_loss: 3.8797 - disc_loss: 0.1796 - beta: 0.6600 - val_loss: 270.1032 - val_reco_loss: 260.7337 - val_kl_loss: 4.2655 - val_disc_loss: 0.1483 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 225951787751663411920896.0000 - reco_loss: 133421311161657053937664.0000 - kl_loss: 1071683845146081058881536.0000 - disc_loss: 0.1723 - beta: 0.7720 - val_loss: 179.8609 - val_reco_loss: 170.7272 - val_kl_loss: 4.4739 - val_disc_loss: 0.1266 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 5282694245191253.0000 - reco_loss: 5132319814487648.0000 - kl_loss: 91182541570048.0000 - disc_loss: 164385.5021 - beta: 0.1840 - val_loss: 587.4241 - val_reco_loss: 579.7445 - val_kl_loss: 1.4387 - val_disc_loss: 0.0650 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 466.2212 - reco_loss: 458.8896 - kl_loss: 1.5719 - disc_loss: 0.0693 - beta: 0.2960 - val_loss: 512.6960 - val_reco_loss: 504.9124 - val_kl_loss: 2.2958 - val_disc_loss: 0.0688 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4080 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.5200 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6320 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7440 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1560 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2680 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3800 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 60s 20ms/step - loss: 870.6337 - reco_loss: 866.5163 - kl_loss: 1.3025 - disc_loss: 0.2380 - beta: 0.2120 - val_loss: 761.3007 - val_reco_loss: 755.4650 - val_kl_loss: 1.7768 - val_disc_loss: 0.2322 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 560.1805 - reco_loss: 553.4174 - kl_loss: 2.6456 - disc_loss: 0.2224 - beta: 0.3240 - val_loss: 579.0032 - val_reco_loss: 572.0389 - val_kl_loss: 3.0076 - val_disc_loss: 0.2819 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 439.4804 - reco_loss: 432.4418 - kl_loss: 3.1414 - disc_loss: 0.3252 - beta: 0.4360 - val_loss: 528.4846 - val_reco_loss: 521.1503 - val_kl_loss: 3.3421 - val_disc_loss: 0.5861 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 355.8625 - reco_loss: 349.2358 - kl_loss: 3.7345 - disc_loss: 0.4581 - beta: 0.5480 - val_loss: 422.3412 - val_reco_loss: 415.6500 - val_kl_loss: 3.7884 - val_disc_loss: 0.6408 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 70886.0392 - reco_loss: 70278.0157 - kl_loss: 488.4572 - disc_loss: 0.5184 - beta: 0.6600 - val_loss: 314.8057 - val_reco_loss: 308.0231 - val_kl_loss: 3.7524 - val_disc_loss: 0.3822 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 208.2535 - reco_loss: 202.0527 - kl_loss: 3.6902 - disc_loss: 0.5969 - beta: 0.7720 - val_loss: 205.9538 - val_reco_loss: 199.5830 - val_kl_loss: 3.6819 - val_disc_loss: 0.8093 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 311.2798 - reco_loss: 306.1271 - kl_loss: 1.5926 - disc_loss: 0.5102 - beta: 0.1840 - val_loss: 728.9756 - val_reco_loss: 724.9108 - val_kl_loss: 1.1982 - val_disc_loss: 0.5600 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 518.7960 - reco_loss: 514.1888 - kl_loss: 1.5132 - disc_loss: 0.4069 - beta: 0.2960 - val_loss: 658.1375 - val_reco_loss: 653.0574 - val_kl_loss: 1.8102 - val_disc_loss: 0.2751 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 555.3955 - reco_loss: 549.8034 - kl_loss: 3.7779 - disc_loss: 0.4082 - beta: 0.4080 - val_loss: 521.0241 - val_reco_loss: 515.2783 - val_kl_loss: 2.4319 - val_disc_loss: 0.2560 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 353.8581 - reco_loss: 347.9560 - kl_loss: 2.6703 - disc_loss: 0.4307 - beta: 0.5200 - val_loss: 425.5227 - val_reco_loss: 419.5804 - val_kl_loss: 2.8028 - val_disc_loss: 0.5035 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 305.7727 - reco_loss: 299.4001 - kl_loss: 3.2136 - disc_loss: 0.4851 - beta: 0.6320 - val_loss: 301.8264 - val_reco_loss: 294.9574 - val_kl_loss: 3.1911 - val_disc_loss: 0.2744 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 230.3232 - reco_loss: 223.6195 - kl_loss: 3.4347 - disc_loss: 0.5557 - beta: 0.7440 - val_loss: 227.8470 - val_reco_loss: 221.2874 - val_kl_loss: 3.3603 - val_disc_loss: 0.3812 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 219.1986 - reco_loss: 213.0862 - kl_loss: 2.1834 - disc_loss: 0.4903 - beta: 0.1560 - val_loss: 681.3813 - val_reco_loss: 677.4028 - val_kl_loss: 0.9381 - val_disc_loss: 0.4306 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 521.2691 - reco_loss: 516.8287 - kl_loss: 1.2851 - disc_loss: 0.3812 - beta: 0.2680 - val_loss: 578.8931 - val_reco_loss: 573.6161 - val_kl_loss: 1.5023 - val_disc_loss: 0.1785 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 434.2935 - reco_loss: 429.1049 - kl_loss: 1.8823 - disc_loss: 0.3850 - beta: 0.3800 - val_loss: 536.7884 - val_reco_loss: 531.6001 - val_kl_loss: 2.0005 - val_disc_loss: 0.2663 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 352.4312 - reco_loss: 346.0943 - kl_loss: 2.3849 - disc_loss: 0.3559 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 352.4284 - reco_loss: 346.0913 - kl_loss: 2.3848 - disc_loss: 0.3558 - beta: 0.4920 - val_loss: 400.6319 - val_reco_loss: 394.6656 - val_kl_loss: 2.5075 - val_disc_loss: 0.1850 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 290.0267 - reco_loss: 283.8878 - kl_loss: 2.8858 - disc_loss: 0.3690 - beta: 0.6040 - val_loss: 322.5418 - val_reco_loss: 316.6815 - val_kl_loss: 2.8989 - val_disc_loss: 0.5468 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 233.5914 - reco_loss: 227.1332 - kl_loss: 3.2679 - disc_loss: 0.4244 - beta: 0.7160 - val_loss: 232.7829 - val_reco_loss: 226.4702 - val_kl_loss: 3.1883 - val_disc_loss: 0.3679 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 186.7565 - reco_loss: 179.6719 - kl_loss: 2.8042 - disc_loss: 0.3873 - beta: 0.1280 - val_loss: 727.7365 - val_reco_loss: 723.5538 - val_kl_loss: 0.7305 - val_disc_loss: 0.3087 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 486.5545 - reco_loss: 481.9479 - kl_loss: 1.1233 - disc_loss: 0.3063 - beta: 0.2400 - val_loss: 613.3221 - val_reco_loss: 608.2666 - val_kl_loss: 1.3406 - val_disc_loss: 0.3272 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 464.0222 - reco_loss: 458.5218 - kl_loss: 1.7255 - disc_loss: 0.3795 - beta: 0.3520 - val_loss: 514.2982 - val_reco_loss: 508.7418 - val_kl_loss: 1.8833 - val_disc_loss: 0.6292 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 10.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 55s 20ms/step - loss: 898.6344 - reco_loss: 877.8142 - kl_loss: 0.6585 - disc_loss: 0.6067 - beta: 0.2120 - val_loss: 698.2861 - val_reco_loss: 680.2393 - val_kl_loss: 1.2295 - val_disc_loss: 0.6848 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 555.9939 - reco_loss: 538.4120 - kl_loss: 1.6544 - disc_loss: 0.8528 - beta: 0.3240 - val_loss: 584.0134 - val_reco_loss: 565.4669 - val_kl_loss: 2.6695 - val_disc_loss: 0.9845 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 462.7337 - reco_loss: 444.7460 - kl_loss: 2.3813 - disc_loss: 0.9507 - beta: 0.4360 - val_loss: 484.8110 - val_reco_loss: 465.1139 - val_kl_loss: 3.5802 - val_disc_loss: 0.8758 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 405.0010 - reco_loss: 385.7643 - kl_loss: 2.9519 - disc_loss: 0.8961 - beta: 0.5480 - val_loss: 386.6728 - val_reco_loss: 366.0833 - val_kl_loss: 4.0390 - val_disc_loss: 0.8025 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 303.7377 - reco_loss: 284.5267 - kl_loss: 3.4403 - disc_loss: 0.9110 - beta: 0.6600 - val_loss: 331.7408 - val_reco_loss: 306.3871 - val_kl_loss: 4.0089 - val_disc_loss: 0.6959 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 236.8818 - reco_loss: 213.5566 - kl_loss: 4.0414 - disc_loss: 0.7481 - beta: 0.7720 - val_loss: 231.8399 - val_reco_loss: 206.0323 - val_kl_loss: 4.7048 - val_disc_loss: 0.9705 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 146642666710190.4688 - reco_loss: 145782572102802.1250 - kl_loss: 311308779520.0000 - disc_loss: 0.5414 - beta: 0.1840 - val_loss: 717.8382 - val_reco_loss: 689.7560 - val_kl_loss: 1.3245 - val_disc_loss: 0.4856 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 532.1173 - reco_loss: 502.4021 - kl_loss: 1.5261 - disc_loss: 0.3785 - beta: 0.2960 - val_loss: 606.1039 - val_reco_loss: 577.3430 - val_kl_loss: 1.9498 - val_disc_loss: 0.3027 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 459.4614 - reco_loss: 430.3710 - kl_loss: 2.1321 - disc_loss: 0.4021 - beta: 0.4080 - val_loss: 528.0228 - val_reco_loss: 499.9795 - val_kl_loss: 2.5429 - val_disc_loss: 0.4538 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.5200 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6320 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7440 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1560 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2680 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3800 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 10.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 57s 21ms/step - loss: 1366.6815 - reco_loss: 1345.3409 - kl_loss: 0.6389 - disc_loss: 0.6024 - beta: 0.2120 - val_loss: 695.0405 - val_reco_loss: 679.0162 - val_kl_loss: 1.2850 - val_disc_loss: 0.6407 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 566.4468 - reco_loss: 550.2000 - kl_loss: 1.6398 - disc_loss: 0.8634 - beta: 0.3240 - val_loss: 549.6420 - val_reco_loss: 534.8077 - val_kl_loss: 2.3171 - val_disc_loss: 1.0305 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 450.1178 - reco_loss: 434.9278 - kl_loss: 2.3061 - disc_loss: 0.9698 - beta: 0.4360 - val_loss: 497.6220 - val_reco_loss: 476.0143 - val_kl_loss: 3.3080 - val_disc_loss: 1.8754 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 360.6469 - reco_loss: 343.2899 - kl_loss: 2.9349 - disc_loss: 1.0479 - beta: 0.5480 - val_loss: 376.3873 - val_reco_loss: 360.3403 - val_kl_loss: 3.8898 - val_disc_loss: 1.0107 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 291.4939 - reco_loss: 274.8439 - kl_loss: 3.3115 - disc_loss: 1.0462 - beta: 0.6600 - val_loss: 271.9978 - val_reco_loss: 255.9548 - val_kl_loss: 3.9697 - val_disc_loss: 1.2285 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 222.7553 - reco_loss: 207.0605 - kl_loss: 3.5302 - disc_loss: 1.0419 - beta: 0.7720 - val_loss: 197.3015 - val_reco_loss: 180.5143 - val_kl_loss: 4.2866 - val_disc_loss: 0.9214 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 4279890584.9232 - reco_loss: 4206793081.5238 - kl_loss: 27226070.0000 - disc_loss: 17.4568 - beta: 0.1840 - val_loss: 633.9108 - val_reco_loss: 617.2665 - val_kl_loss: 1.3452 - val_disc_loss: 0.7015 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 503.5207 - reco_loss: 487.4381 - kl_loss: 1.5227 - disc_loss: 0.8918 - beta: 0.2960 - val_loss: 535.2884 - val_reco_loss: 519.2061 - val_kl_loss: 2.1367 - val_disc_loss: 0.8847 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 444.1390 - reco_loss: 427.4227 - kl_loss: 2.1778 - disc_loss: 0.9286 - beta: 0.4080 - val_loss: 492.0906 - val_reco_loss: 472.6911 - val_kl_loss: 2.7987 - val_disc_loss: 1.1214 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 30263.6312 - reco_loss: 30148.7845 - kl_loss: 48.8324 - disc_loss: 0.9555 - beta: 0.5200 - val_loss: 369.3235 - val_reco_loss: 354.8847 - val_kl_loss: 3.3981 - val_disc_loss: 1.3036 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 182462772716552.4375 - reco_loss: 175600471881775.4062 - kl_loss: 4303700623360.0000 - disc_loss: 0.9861 - beta: 0.6320 - val_loss: 301.2374 - val_reco_loss: 281.5758 - val_kl_loss: 3.9392 - val_disc_loss: 1.1445 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 221.4553 - reco_loss: 204.7708 - kl_loss: 3.6268 - disc_loss: 0.9864 - beta: 0.7440 - val_loss: 217.2229 - val_reco_loss: 196.0484 - val_kl_loss: 4.2735 - val_disc_loss: 0.9335 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 241.0775 - reco_loss: 223.6007 - kl_loss: 2.2872 - disc_loss: 1.0410 - beta: 0.1560 - val_loss: 644.6984 - val_reco_loss: 621.8261 - val_kl_loss: 1.0935 - val_disc_loss: 0.7609 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 490.9612 - reco_loss: 472.9745 - kl_loss: 1.3623 - disc_loss: 0.8445 - beta: 0.2680 - val_loss: 552.7532 - val_reco_loss: 536.0655 - val_kl_loss: 1.8705 - val_disc_loss: 0.8413 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 477.9956 - reco_loss: 459.3253 - kl_loss: 2.0044 - disc_loss: 0.8706 - beta: 0.3800 - val_loss: 474.8805 - val_reco_loss: 457.9985 - val_kl_loss: 2.5282 - val_disc_loss: 0.9099 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 370.6138 - reco_loss: 350.1702 - kl_loss: 2.5747 - disc_loss: 0.8153 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 370.6238 - reco_loss: 350.1773 - kl_loss: 2.5747 - disc_loss: 0.8152 - beta: 0.4920 - val_loss: 427.6731 - val_reco_loss: 400.3623 - val_kl_loss: 3.0870 - val_disc_loss: 0.4353 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 329.5492 - reco_loss: 306.9263 - kl_loss: 3.0882 - disc_loss: 0.6874 - beta: 0.6040 - val_loss: 321.6073 - val_reco_loss: 298.0406 - val_kl_loss: 3.5922 - val_disc_loss: 0.9135 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 249.0008 - reco_loss: 228.7927 - kl_loss: 3.5426 - disc_loss: 0.8640 - beta: 0.7160 - val_loss: 223.9228 - val_reco_loss: 206.4263 - val_kl_loss: 4.1162 - val_disc_loss: 1.0067 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 182.6402 - reco_loss: 166.3817 - kl_loss: 3.0673 - disc_loss: 0.9809 - beta: 0.1280 - val_loss: 644.4340 - val_reco_loss: 626.0530 - val_kl_loss: 0.8953 - val_disc_loss: 0.8565 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 507.4282 - reco_loss: 489.8789 - kl_loss: 1.1953 - disc_loss: 0.7983 - beta: 0.2400 - val_loss: 560.8594 - val_reco_loss: 541.4128 - val_kl_loss: 1.6586 - val_disc_loss: 0.5517 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 478.5056 - reco_loss: 458.6868 - kl_loss: 1.8343 - disc_loss: 0.7424 - beta: 0.3520 - val_loss: 487.7473 - val_reco_loss: 461.5833 - val_kl_loss: 2.3321 - val_disc_loss: 0.4124 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 10.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 57s 21ms/step - loss: 923.2587 - reco_loss: 900.1054 - kl_loss: 0.7031 - disc_loss: 0.5347 - beta: 0.2120 - val_loss: 747.4955 - val_reco_loss: 731.5100 - val_kl_loss: 1.6267 - val_disc_loss: 0.9249 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 562.8533 - reco_loss: 544.9908 - kl_loss: 1.8547 - disc_loss: 0.8234 - beta: 0.3240 - val_loss: 556.6819 - val_reco_loss: 540.1330 - val_kl_loss: 2.8727 - val_disc_loss: 0.8998 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 467.0658 - reco_loss: 450.4393 - kl_loss: 2.6148 - disc_loss: 0.9596 - beta: 0.4360 - val_loss: 468.1476 - val_reco_loss: 449.7051 - val_kl_loss: 4.1126 - val_disc_loss: 0.8448 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 376.3292 - reco_loss: 358.8191 - kl_loss: 3.3056 - disc_loss: 0.9844 - beta: 0.5480 - val_loss: 357.4925 - val_reco_loss: 340.2707 - val_kl_loss: 4.2587 - val_disc_loss: 1.0590 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 317.6934 - reco_loss: 301.4575 - kl_loss: 3.6042 - disc_loss: 1.0064 - beta: 0.6600 - val_loss: 277.3388 - val_reco_loss: 261.3697 - val_kl_loss: 4.5167 - val_disc_loss: 0.9016 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 213.4885 - reco_loss: 197.2049 - kl_loss: 3.7812 - disc_loss: 1.1120 - beta: 0.7720 - val_loss: 209.5740 - val_reco_loss: 195.1510 - val_kl_loss: 4.4014 - val_disc_loss: 1.2492 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 309.1661 - reco_loss: 293.2026 - kl_loss: 1.6754 - disc_loss: 0.9827 - beta: 0.1840 - val_loss: 648.2002 - val_reco_loss: 630.5494 - val_kl_loss: 1.3034 - val_disc_loss: 0.8273 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 520.9969 - reco_loss: 504.3865 - kl_loss: 1.5951 - disc_loss: 0.8952 - beta: 0.2960 - val_loss: 558.7573 - val_reco_loss: 542.0381 - val_kl_loss: 2.0658 - val_disc_loss: 0.7177 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 464.7166 - reco_loss: 447.9451 - kl_loss: 2.2713 - disc_loss: 0.9592 - beta: 0.4080 - val_loss: 496.8308 - val_reco_loss: 479.4431 - val_kl_loss: 2.7552 - val_disc_loss: 0.8949 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 396.0374 - reco_loss: 378.6624 - kl_loss: 2.8106 - disc_loss: 0.9206 - beta: 0.5200 - val_loss: 395.2677 - val_reco_loss: 380.6432 - val_kl_loss: 3.1918 - val_disc_loss: 0.9729 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 290.6696 - reco_loss: 274.2606 - kl_loss: 3.2362 - disc_loss: 1.0010 - beta: 0.6320 - val_loss: 322.3102 - val_reco_loss: 305.0768 - val_kl_loss: 3.5548 - val_disc_loss: 1.0945 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 230.5657 - reco_loss: 214.4881 - kl_loss: 3.5284 - disc_loss: 1.0567 - beta: 0.7440 - val_loss: 227.7861 - val_reco_loss: 213.2453 - val_kl_loss: 3.7529 - val_disc_loss: 1.2486 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 227.3180 - reco_loss: 212.9075 - kl_loss: 2.2024 - disc_loss: 1.0820 - beta: 0.1560 - val_loss: 698.3769 - val_reco_loss: 681.3046 - val_kl_loss: 1.0196 - val_disc_loss: 1.2256 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 500.4941 - reco_loss: 483.1169 - kl_loss: 1.3307 - disc_loss: 0.8383 - beta: 0.2680 - val_loss: 646.0016 - val_reco_loss: 626.2719 - val_kl_loss: 1.6712 - val_disc_loss: 1.1012 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 505.5187 - reco_loss: 486.9540 - kl_loss: 2.0925 - disc_loss: 0.8310 - beta: 0.3800 - val_loss: 532.6433 - val_reco_loss: 514.3518 - val_kl_loss: 2.1838 - val_disc_loss: 0.6425 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 374.8913 - reco_loss: 355.5302 - kl_loss: 2.4683 - disc_loss: 0.8481 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 374.8797 - reco_loss: 355.5186 - kl_loss: 2.4683 - disc_loss: 0.8481 - beta: 0.4920 - val_loss: 420.6519 - val_reco_loss: 403.0520 - val_kl_loss: 2.8506 - val_disc_loss: 1.1366 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 301.3421 - reco_loss: 282.4428 - kl_loss: 2.9747 - disc_loss: 0.8904 - beta: 0.6040 - val_loss: 334.3207 - val_reco_loss: 316.1355 - val_kl_loss: 3.2295 - val_disc_loss: 0.8000 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 246.8977 - reco_loss: 226.3261 - kl_loss: 3.6264 - disc_loss: 0.8100 - beta: 0.7160 - val_loss: 246.2883 - val_reco_loss: 227.2864 - val_kl_loss: 4.3273 - val_disc_loss: 0.9513 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 1002.8980 - reco_loss: 960.3543 - kl_loss: 19.0047 - disc_loss: 0.8192 - beta: 0.1280 - val_loss: 727.5421 - val_reco_loss: 698.7861 - val_kl_loss: 0.8383 - val_disc_loss: 0.4465 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 543.2397 - reco_loss: 514.5685 - kl_loss: 1.2231 - disc_loss: 0.4445 - beta: 0.2400 - val_loss: 635.4188 - val_reco_loss: 606.3676 - val_kl_loss: 1.6068 - val_disc_loss: 0.3368 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 42303240583730610176.0000 - reco_loss: 42082651055055101952.0000 - kl_loss: 719163342815494144.0000 - disc_loss: 0.5607 - beta: 0.3520 - val_loss: 569.4247 - val_reco_loss: 540.1566 - val_kl_loss: 2.3155 - val_disc_loss: 0.3786 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 10.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 49s 18ms/step - loss: 937.2951 - reco_loss: 910.8496 - kl_loss: 1.0550 - disc_loss: 0.4699 - beta: 0.2120 - val_loss: 829.2294 - val_reco_loss: 808.1637 - val_kl_loss: 2.4311 - val_disc_loss: 0.6843 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 577.2613 - reco_loss: 558.7312 - kl_loss: 2.5174 - disc_loss: 0.8379 - beta: 0.3240 - val_loss: 624.1074 - val_reco_loss: 607.9278 - val_kl_loss: 3.1940 - val_disc_loss: 1.1599 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 476.2947 - reco_loss: 459.5999 - kl_loss: 3.0669 - disc_loss: 0.9500 - beta: 0.4360 - val_loss: 475.0815 - val_reco_loss: 457.7227 - val_kl_loss: 3.4783 - val_disc_loss: 1.0513 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 349.0397 - reco_loss: 332.3559 - kl_loss: 3.5168 - disc_loss: 0.9989 - beta: 0.5480 - val_loss: 369.2515 - val_reco_loss: 353.5292 - val_kl_loss: 4.3124 - val_disc_loss: 1.0656 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 291.7761 - reco_loss: 275.7992 - kl_loss: 3.7626 - disc_loss: 1.0660 - beta: 0.6600 - val_loss: 291.3300 - val_reco_loss: 275.8479 - val_kl_loss: 4.2271 - val_disc_loss: 1.1649 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 209.0983 - reco_loss: 193.3919 - kl_loss: 3.9870 - disc_loss: 1.0729 - beta: 0.7720 - val_loss: 192.3961 - val_reco_loss: 177.6611 - val_kl_loss: 3.9951 - val_disc_loss: 1.1248 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 319.6936 - reco_loss: 304.8979 - kl_loss: 1.7155 - disc_loss: 1.0427 - beta: 0.1840 - val_loss: 636.8756 - val_reco_loss: 621.9255 - val_kl_loss: 1.3089 - val_disc_loss: 1.0639 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 483.1651 - reco_loss: 466.6025 - kl_loss: 1.6544 - disc_loss: 0.9247 - beta: 0.2960 - val_loss: 554.8235 - val_reco_loss: 540.0358 - val_kl_loss: 2.0634 - val_disc_loss: 0.9312 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 471.4956 - reco_loss: 454.2359 - kl_loss: 2.3345 - disc_loss: 0.9575 - beta: 0.4080 - val_loss: 468.3071 - val_reco_loss: 452.7261 - val_kl_loss: 2.7632 - val_disc_loss: 0.8904 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 368.9938 - reco_loss: 352.2819 - kl_loss: 2.8763 - disc_loss: 1.0530 - beta: 0.5200 - val_loss: 380.1653 - val_reco_loss: 364.5736 - val_kl_loss: 3.2093 - val_disc_loss: 1.2329 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 290.6885 - reco_loss: 274.9015 - kl_loss: 3.3219 - disc_loss: 1.0640 - beta: 0.6320 - val_loss: 290.1745 - val_reco_loss: 274.0636 - val_kl_loss: 3.5705 - val_disc_loss: 0.9581 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 18962.5116 - reco_loss: 18940.6775 - kl_loss: 9.4039 - disc_loss: 1.0161 - beta: 0.7440 - val_loss: 213.1863 - val_reco_loss: 196.4064 - val_kl_loss: 3.8820 - val_disc_loss: 0.9443 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 223.0582 - reco_loss: 206.7849 - kl_loss: 2.3529 - disc_loss: 0.9986 - beta: 0.1560 - val_loss: 655.1004 - val_reco_loss: 638.8063 - val_kl_loss: 1.0406 - val_disc_loss: 0.9828 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 542.9949 - reco_loss: 526.1322 - kl_loss: 1.3614 - disc_loss: 0.8564 - beta: 0.2680 - val_loss: 591.4316 - val_reco_loss: 563.9705 - val_kl_loss: 1.7109 - val_disc_loss: 0.6015 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 472.5977 - reco_loss: 450.1502 - kl_loss: 1.9730 - disc_loss: 0.7075 - beta: 0.3800 - val_loss: 479.7656 - val_reco_loss: 462.3080 - val_kl_loss: 2.4082 - val_disc_loss: 0.7085 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 368.2561 - reco_loss: 350.3006 - kl_loss: 2.5361 - disc_loss: 0.8838 - beta: 0.4918\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 368.2536 - reco_loss: 350.2985 - kl_loss: 2.5368 - disc_loss: 0.8839 - beta: 0.4920 - val_loss: 396.4380 - val_reco_loss: 380.0752 - val_kl_loss: 2.8335 - val_disc_loss: 0.9654 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 320.3051 - reco_loss: 301.9756 - kl_loss: 3.0588 - disc_loss: 0.8459 - beta: 0.6040 - val_loss: 331.6259 - val_reco_loss: 305.3260 - val_kl_loss: 3.4745 - val_disc_loss: 0.4423 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 2707.2421 - reco_loss: 2685.7751 - kl_loss: 4.1322 - disc_loss: 0.8689 - beta: 0.7160 - val_loss: 230.5240 - val_reco_loss: 211.0145 - val_kl_loss: 3.8541 - val_disc_loss: 0.6738 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 220.6273 - reco_loss: 197.5368 - kl_loss: 3.0823 - disc_loss: 0.7850 - beta: 0.1280 - val_loss: 677.1393 - val_reco_loss: 654.1755 - val_kl_loss: 0.8400 - val_disc_loss: 0.5486 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 580.3424 - reco_loss: 557.6358 - kl_loss: 1.1780 - disc_loss: 0.6263 - beta: 0.2400 - val_loss: 578.8340 - val_reco_loss: 560.1953 - val_kl_loss: 1.5698 - val_disc_loss: 0.9890 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 472.9943 - reco_loss: 453.7051 - kl_loss: 1.8367 - disc_loss: 0.8402 - beta: 0.3520 - val_loss: 488.1962 - val_reco_loss: 472.4791 - val_kl_loss: 2.2151 - val_disc_loss: 0.8696 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 10.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 49s 18ms/step - loss: 860.5422 - reco_loss: 836.3876 - kl_loss: 0.7082 - disc_loss: 0.4899 - beta: 0.2120 - val_loss: 759.1238 - val_reco_loss: 738.8091 - val_kl_loss: 1.6002 - val_disc_loss: 0.5368 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 542.4013 - reco_loss: 523.8987 - kl_loss: 1.7565 - disc_loss: 0.7636 - beta: 0.3240 - val_loss: 575.1044 - val_reco_loss: 558.6928 - val_kl_loss: 2.8128 - val_disc_loss: 0.8936 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 451.1145 - reco_loss: 434.8085 - kl_loss: 2.6505 - disc_loss: 0.9392 - beta: 0.4360 - val_loss: 465.5628 - val_reco_loss: 446.2630 - val_kl_loss: 4.1440 - val_disc_loss: 0.7782 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 382.1760 - reco_loss: 365.5627 - kl_loss: 3.2643 - disc_loss: 0.9801 - beta: 0.5480 - val_loss: 357.7015 - val_reco_loss: 338.8026 - val_kl_loss: 4.5453 - val_disc_loss: 0.9880 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 286.7039 - reco_loss: 270.5496 - kl_loss: 3.5858 - disc_loss: 1.0736 - beta: 0.6600 - val_loss: 269.9700 - val_reco_loss: 256.4895 - val_kl_loss: 4.9063 - val_disc_loss: 1.2482 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 213.5528 - reco_loss: 198.9051 - kl_loss: 3.7478 - disc_loss: 1.1495 - beta: 0.7720 - val_loss: 187.2575 - val_reco_loss: 172.8287 - val_kl_loss: 4.6225 - val_disc_loss: 1.1728 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 318.9073 - reco_loss: 304.5164 - kl_loss: 1.6556 - disc_loss: 1.0139 - beta: 0.1840 - val_loss: 616.0349 - val_reco_loss: 602.4177 - val_kl_loss: 1.5650 - val_disc_loss: 0.9092 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 486.2800 - reco_loss: 470.8280 - kl_loss: 1.5550 - disc_loss: 0.9771 - beta: 0.2960 - val_loss: 527.6406 - val_reco_loss: 512.5676 - val_kl_loss: 2.4313 - val_disc_loss: 1.0653 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 9067748.2755 - reco_loss: 8813704.3208 - kl_loss: 1474589.7500 - disc_loss: 2.6184 - beta: 0.4080 - val_loss: 476.1286 - val_reco_loss: 460.4675 - val_kl_loss: 2.8662 - val_disc_loss: 1.1830 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 378.8913 - reco_loss: 363.7131 - kl_loss: 2.8292 - disc_loss: 1.0795 - beta: 0.5200 - val_loss: 379.1368 - val_reco_loss: 362.3929 - val_kl_loss: 3.6525 - val_disc_loss: 1.0548 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 307.0384 - reco_loss: 292.2118 - kl_loss: 3.2705 - disc_loss: 1.1978 - beta: 0.6320 - val_loss: 283.3792 - val_reco_loss: 268.8640 - val_kl_loss: 4.2073 - val_disc_loss: 1.1910 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 2247215018312611.0000 - reco_loss: 2212873467332231.2500 - kl_loss: 42071436034048.0000 - disc_loss: 680.6071 - beta: 0.7440 - val_loss: 210.7252 - val_reco_loss: 197.1375 - val_kl_loss: 4.3850 - val_disc_loss: 1.4502 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 227.0528 - reco_loss: 212.0391 - kl_loss: 2.2727 - disc_loss: 1.0838 - beta: 0.1560 - val_loss: 658.4106 - val_reco_loss: 643.7868 - val_kl_loss: 1.1410 - val_disc_loss: 0.9665 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 14352107.3216 - reco_loss: 14351681.6836 - kl_loss: 176.8959 - disc_loss: 0.8755 - beta: 0.2680 - val_loss: 559.2686 - val_reco_loss: 541.4470 - val_kl_loss: 2.0141 - val_disc_loss: 0.8190 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 454.4134 - reco_loss: 435.7530 - kl_loss: 2.0006 - disc_loss: 0.8326 - beta: 0.3800 - val_loss: 475.8663 - val_reco_loss: 457.9835 - val_kl_loss: 2.8639 - val_disc_loss: 0.6786 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 382.1649 - reco_loss: 361.9619 - kl_loss: 2.5984 - disc_loss: 0.8231 - beta: 0.4920\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 382.1638 - reco_loss: 361.9599 - kl_loss: 2.5984 - disc_loss: 0.8231 - beta: 0.4920 - val_loss: 434.2634 - val_reco_loss: 405.9515 - val_kl_loss: 3.4742 - val_disc_loss: 0.5711 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 322.6677 - reco_loss: 296.8615 - kl_loss: 3.1189 - disc_loss: 0.6022 - beta: 0.6040 - val_loss: 345.7794 - val_reco_loss: 320.5746 - val_kl_loss: 4.0126 - val_disc_loss: 0.5779 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 258.8901 - reco_loss: 234.0593 - kl_loss: 3.5521 - disc_loss: 0.6127 - beta: 0.7160 - val_loss: 282.6916 - val_reco_loss: 253.6487 - val_kl_loss: 4.3370 - val_disc_loss: 0.5547 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 236.0571 - reco_loss: 206.5820 - kl_loss: 3.0038 - disc_loss: 0.6537 - beta: 0.1280 - val_loss: 707.5617 - val_reco_loss: 679.1366 - val_kl_loss: 0.9370 - val_disc_loss: 0.3850 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 580.2409 - reco_loss: 553.5886 - kl_loss: 1.1755 - disc_loss: 0.7034 - beta: 0.2400 - val_loss: 568.0567 - val_reco_loss: 554.0690 - val_kl_loss: 1.7574 - val_disc_loss: 1.0447 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 449.5914 - reco_loss: 435.8948 - kl_loss: 1.8091 - disc_loss: 1.0598 - beta: 0.3520 - val_loss: 510.0621 - val_reco_loss: 495.2570 - val_kl_loss: 2.5179 - val_disc_loss: 1.1574 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 10.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 49s 18ms/step - loss: 989.9551 - reco_loss: 966.1277 - kl_loss: 1.2102 - disc_loss: 0.5303 - beta: 0.2120 - val_loss: 804.0576 - val_reco_loss: 784.1838 - val_kl_loss: 2.2728 - val_disc_loss: 0.8190 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 532.3535 - reco_loss: 512.7671 - kl_loss: 2.4934 - disc_loss: 0.8159 - beta: 0.3240 - val_loss: 566.0109 - val_reco_loss: 544.3570 - val_kl_loss: 3.7629 - val_disc_loss: 0.8182 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 456.6194 - reco_loss: 437.9224 - kl_loss: 3.1196 - disc_loss: 0.9115 - beta: 0.4360 - val_loss: 460.4355 - val_reco_loss: 438.0414 - val_kl_loss: 4.7333 - val_disc_loss: 0.9530 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 379.4736 - reco_loss: 360.2455 - kl_loss: 3.6918 - disc_loss: 0.9696 - beta: 0.5480 - val_loss: 366.0720 - val_reco_loss: 345.0752 - val_kl_loss: 5.0297 - val_disc_loss: 0.8639 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 303.0653 - reco_loss: 283.8029 - kl_loss: 3.8888 - disc_loss: 0.9741 - beta: 0.6600 - val_loss: 289.0743 - val_reco_loss: 266.2881 - val_kl_loss: 5.3563 - val_disc_loss: 0.8869 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 225.9129 - reco_loss: 207.2776 - kl_loss: 4.0694 - disc_loss: 0.9451 - beta: 0.7720 - val_loss: 206.1514 - val_reco_loss: 185.3474 - val_kl_loss: 4.8501 - val_disc_loss: 0.8605 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 334.7585 - reco_loss: 316.1137 - kl_loss: 1.7312 - disc_loss: 0.9090 - beta: 0.1840 - val_loss: 624.9557 - val_reco_loss: 605.5619 - val_kl_loss: 1.5186 - val_disc_loss: 0.7520 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 536.5111 - reco_loss: 515.4331 - kl_loss: 1.7199 - disc_loss: 0.7375 - beta: 0.2960 - val_loss: 544.5666 - val_reco_loss: 523.7163 - val_kl_loss: 2.3390 - val_disc_loss: 0.9577 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 465.1497 - reco_loss: 443.5647 - kl_loss: 2.4099 - disc_loss: 0.7774 - beta: 0.4080 - val_loss: 479.9593 - val_reco_loss: 455.1049 - val_kl_loss: 3.1795 - val_disc_loss: 0.7581 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 394.9989 - reco_loss: 373.5628 - kl_loss: 2.9951 - disc_loss: 0.8361 - beta: 0.5200 - val_loss: 397.2849 - val_reco_loss: 371.5155 - val_kl_loss: 3.7960 - val_disc_loss: 0.7623 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 337.4446 - reco_loss: 314.5212 - kl_loss: 3.4728 - disc_loss: 0.7910 - beta: 0.6320 - val_loss: 329.6833 - val_reco_loss: 307.0835 - val_kl_loss: 3.9616 - val_disc_loss: 0.8549 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 739647540116740.5000 - reco_loss: 724359800550139.8750 - kl_loss: 11774598316032.0000 - disc_loss: 0.7355 - beta: 0.7440 - val_loss: 232.9487 - val_reco_loss: 209.2123 - val_kl_loss: 4.5206 - val_disc_loss: 0.7683 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 254.8325 - reco_loss: 229.1667 - kl_loss: 2.5398 - disc_loss: 0.6058 - beta: 0.1560 - val_loss: 665.7231 - val_reco_loss: 631.4980 - val_kl_loss: 1.3209 - val_disc_loss: 0.2990 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 1076.2024 - reco_loss: 1033.1219 - kl_loss: 9.4197 - disc_loss: 0.3089 - beta: 0.2680 - val_loss: 594.4715 - val_reco_loss: 558.3116 - val_kl_loss: 2.0933 - val_disc_loss: 0.2853 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 481.0492 - reco_loss: 449.7156 - kl_loss: 2.1312 - disc_loss: 0.3522 - beta: 0.3800 - val_loss: 498.9924 - val_reco_loss: 468.6190 - val_kl_loss: 2.9008 - val_disc_loss: 0.3683 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4918\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 10.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 48s 18ms/step - loss: 895.7290 - reco_loss: 871.0034 - kl_loss: 1.0435 - disc_loss: 0.5016 - beta: 0.2120 - val_loss: 742.6066 - val_reco_loss: 725.6288 - val_kl_loss: 2.2637 - val_disc_loss: 0.8254 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 556.8052 - reco_loss: 538.9304 - kl_loss: 1.9873 - disc_loss: 0.8311 - beta: 0.3240 - val_loss: 558.7887 - val_reco_loss: 539.6388 - val_kl_loss: 3.6511 - val_disc_loss: 0.7075 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 456.5107 - reco_loss: 439.0353 - kl_loss: 2.6254 - disc_loss: 0.8840 - beta: 0.4360 - val_loss: 460.3037 - val_reco_loss: 442.7826 - val_kl_loss: 4.2957 - val_disc_loss: 0.8904 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 384.1618 - reco_loss: 366.2579 - kl_loss: 3.1838 - disc_loss: 1.0314 - beta: 0.5480 - val_loss: 373.2209 - val_reco_loss: 356.3414 - val_kl_loss: 4.8799 - val_disc_loss: 1.2118 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 296.0289 - reco_loss: 277.6669 - kl_loss: 3.7927 - disc_loss: 0.9638 - beta: 0.6600 - val_loss: 341.2584 - val_reco_loss: 312.7609 - val_kl_loss: 4.9282 - val_disc_loss: 1.1235 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 230.7479 - reco_loss: 209.6479 - kl_loss: 4.2238 - disc_loss: 0.8645 - beta: 0.7720 - val_loss: 210.0086 - val_reco_loss: 189.8381 - val_kl_loss: 5.5718 - val_disc_loss: 0.8450 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 431.0304 - reco_loss: 409.6905 - kl_loss: 5.2712 - disc_loss: 0.7926 - beta: 0.1840 - val_loss: 637.7744 - val_reco_loss: 611.4164 - val_kl_loss: 1.6530 - val_disc_loss: 0.2858 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 736696662153461.3750 - reco_loss: 735767251478634.5000 - kl_loss: 1205133770752.0000 - disc_loss: 0.4781 - beta: 0.2960 - val_loss: 565.4668 - val_reco_loss: 537.0679 - val_kl_loss: 2.4889 - val_disc_loss: 0.3349 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 11923300141.3107 - reco_loss: 8932624283.4459 - kl_loss: 2016895232.0000 - disc_loss: 0.4080 - beta: 0.4080 - val_loss: 485.0578 - val_reco_loss: 456.5490 - val_kl_loss: 3.0955 - val_disc_loss: 0.4260 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 402.3022 - reco_loss: 374.7937 - kl_loss: 2.9121 - disc_loss: 0.5323 - beta: 0.5200 - val_loss: 410.9629 - val_reco_loss: 379.6317 - val_kl_loss: 3.2062 - val_disc_loss: 0.4557 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 53899.2805 - reco_loss: 53565.4347 - kl_loss: 706.3168 - disc_loss: 0.4533 - beta: 0.6320 - val_loss: 310.6771 - val_reco_loss: 285.2576 - val_kl_loss: 3.6894 - val_disc_loss: 0.5258 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 266.2600 - reco_loss: 237.6306 - kl_loss: 22.7661 - disc_loss: 0.5482 - beta: 0.7440 - val_loss: 223.9848 - val_reco_loss: 202.4560 - val_kl_loss: 3.9447 - val_disc_loss: 0.5538 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 234.7951 - reco_loss: 211.0474 - kl_loss: 2.3240 - disc_loss: 0.6183 - beta: 0.1560 - val_loss: 649.5543 - val_reco_loss: 619.3148 - val_kl_loss: 1.1537 - val_disc_loss: 0.3700 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 33267763274648431624192.0000 - reco_loss: 33221016454333634445312.0000 - kl_loss: 194749809597266001920.0000 - disc_loss: 0.4552 - beta: 0.2680 - val_loss: 568.8138 - val_reco_loss: 541.0158 - val_kl_loss: 2.0815 - val_disc_loss: 0.4274 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 31950395072062610894487552.0000 - reco_loss: 27770407923400472147263488.0000 - kl_loss: 14359120831044215218634752.0000 - disc_loss: 0.3864 - beta: 0.3800 - val_loss: 485.4820 - val_reco_loss: 460.2311 - val_kl_loss: 2.8715 - val_disc_loss: 0.4188 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 10.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 52s 18ms/step - loss: 997.7165 - reco_loss: 972.8905 - kl_loss: 1.1048 - disc_loss: 0.5421 - beta: 0.2120 - val_loss: 793.9821 - val_reco_loss: 774.0411 - val_kl_loss: 1.8760 - val_disc_loss: 0.6704 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 585.5537 - reco_loss: 566.1332 - kl_loss: 2.0879 - disc_loss: 0.8026 - beta: 0.3240 - val_loss: 639.7599 - val_reco_loss: 619.7142 - val_kl_loss: 2.7635 - val_disc_loss: 1.0575 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 488.0855 - reco_loss: 469.2135 - kl_loss: 2.7474 - disc_loss: 0.8922 - beta: 0.4360 - val_loss: 475.0509 - val_reco_loss: 454.1141 - val_kl_loss: 3.9791 - val_disc_loss: 0.8287 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 378.1137 - reco_loss: 359.5980 - kl_loss: 3.2376 - disc_loss: 0.9055 - beta: 0.5480 - val_loss: 402.0167 - val_reco_loss: 385.9775 - val_kl_loss: 4.0615 - val_disc_loss: 0.9946 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 298.7585 - reco_loss: 281.8055 - kl_loss: 3.5056 - disc_loss: 1.0775 - beta: 0.6600 - val_loss: 298.4491 - val_reco_loss: 280.3705 - val_kl_loss: 4.2947 - val_disc_loss: 0.8078 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 220.0031 - reco_loss: 203.7630 - kl_loss: 3.7559 - disc_loss: 0.9903 - beta: 0.7720 - val_loss: 199.6307 - val_reco_loss: 183.6470 - val_kl_loss: 4.3464 - val_disc_loss: 0.9626 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 325.0831 - reco_loss: 309.5122 - kl_loss: 1.6743 - disc_loss: 0.9954 - beta: 0.1840 - val_loss: 663.4839 - val_reco_loss: 638.2241 - val_kl_loss: 1.3480 - val_disc_loss: 0.6116 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 508.6062 - reco_loss: 490.2650 - kl_loss: 1.5862 - disc_loss: 0.8606 - beta: 0.2960 - val_loss: 589.3133 - val_reco_loss: 563.4647 - val_kl_loss: 2.1103 - val_disc_loss: 0.5187 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 464.3457 - reco_loss: 443.3671 - kl_loss: 3.2365 - disc_loss: 0.8596 - beta: 0.4080 - val_loss: 488.2948 - val_reco_loss: 472.1731 - val_kl_loss: 2.6584 - val_disc_loss: 1.0617 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 515.6422 - reco_loss: 496.8980 - kl_loss: 2.8439 - disc_loss: 0.8998 - beta: 0.5200 - val_loss: 379.7053 - val_reco_loss: 362.2622 - val_kl_loss: 3.2374 - val_disc_loss: 0.8193 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 317.8138 - reco_loss: 296.8836 - kl_loss: 3.1926 - disc_loss: 0.8352 - beta: 0.6320 - val_loss: 348.3698 - val_reco_loss: 323.3065 - val_kl_loss: 3.6576 - val_disc_loss: 0.7131 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 274.6247 - reco_loss: 245.9734 - kl_loss: 3.4562 - disc_loss: 0.4699 - beta: 0.7440 - val_loss: 252.2962 - val_reco_loss: 225.4114 - val_kl_loss: 3.8702 - val_disc_loss: 0.6106 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 243.7130 - reco_loss: 221.7391 - kl_loss: 2.2454 - disc_loss: 0.7705 - beta: 0.1560 - val_loss: 688.6788 - val_reco_loss: 661.8942 - val_kl_loss: 1.1237 - val_disc_loss: 0.3152 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 552.2677 - reco_loss: 524.8680 - kl_loss: 1.3237 - disc_loss: 0.4232 - beta: 0.2680 - val_loss: 594.8410 - val_reco_loss: 574.2903 - val_kl_loss: 1.7974 - val_disc_loss: 0.7039 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 491.7629 - reco_loss: 463.4229 - kl_loss: 1.9270 - disc_loss: 0.4440 - beta: 0.3800 - val_loss: 522.8491 - val_reco_loss: 495.6376 - val_kl_loss: 2.5446 - val_disc_loss: 0.4583 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 393.5905 - reco_loss: 366.7293 - kl_loss: 2.4537 - disc_loss: 0.4460 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 393.5778 - reco_loss: 366.7166 - kl_loss: 2.4537 - disc_loss: 0.4460 - beta: 0.4920 - val_loss: 438.2855 - val_reco_loss: 417.1950 - val_kl_loss: 3.2538 - val_disc_loss: 0.9214 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 1517978139.4969 - reco_loss: 1499304903.7305 - kl_loss: 9422383.0000 - disc_loss: 0.5371 - beta: 0.6040 - val_loss: 328.7227 - val_reco_loss: 307.1848 - val_kl_loss: 3.6626 - val_disc_loss: 0.6278 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 255.4326 - reco_loss: 232.5884 - kl_loss: 3.3350 - disc_loss: 0.6409 - beta: 0.7160 - val_loss: 257.8056 - val_reco_loss: 231.2615 - val_kl_loss: 3.9340 - val_disc_loss: 0.4799 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 206.5008 - reco_loss: 183.0788 - kl_loss: 2.8104 - disc_loss: 0.5548 - beta: 0.1280 - val_loss: 694.8297 - val_reco_loss: 668.3078 - val_kl_loss: 0.8811 - val_disc_loss: 0.3153 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 536.6389 - reco_loss: 509.2993 - kl_loss: 1.1442 - disc_loss: 0.3668 - beta: 0.2400 - val_loss: 617.7623 - val_reco_loss: 587.3592 - val_kl_loss: 1.6598 - val_disc_loss: 0.2351 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 465.6730 - reco_loss: 437.6874 - kl_loss: 1.7662 - disc_loss: 0.3908 - beta: 0.3520 - val_loss: 516.3044 - val_reco_loss: 488.3306 - val_kl_loss: 2.3768 - val_disc_loss: 0.3653 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 100.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 49s 18ms/step - loss: 1212.3800 - reco_loss: 1049.8960 - kl_loss: 0.5693 - disc_loss: 0.7961 - beta: 0.2120 - val_loss: 1081.4038 - val_reco_loss: 969.1256 - val_kl_loss: 1.0480 - val_disc_loss: 1.3650 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 849.4832 - reco_loss: 726.1790 - kl_loss: 1.3697 - disc_loss: 1.0656 - beta: 0.3240 - val_loss: 717.7269 - val_reco_loss: 634.3538 - val_kl_loss: 1.6731 - val_disc_loss: 1.4271 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 589.9575 - reco_loss: 498.7887 - kl_loss: 1.9458 - disc_loss: 1.2812 - beta: 0.4360 - val_loss: 565.6827 - val_reco_loss: 484.3987 - val_kl_loss: 2.3321 - val_disc_loss: 1.2735 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 464.2860 - reco_loss: 382.0515 - kl_loss: 2.4810 - disc_loss: 1.3305 - beta: 0.5480 - val_loss: 470.5833 - val_reco_loss: 386.5658 - val_kl_loss: 3.0831 - val_disc_loss: 1.2097 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 375.7664 - reco_loss: 292.1301 - kl_loss: 2.8811 - disc_loss: 1.3282 - beta: 0.6600 - val_loss: 369.9187 - val_reco_loss: 283.9936 - val_kl_loss: 3.5873 - val_disc_loss: 1.2173 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 305.8275 - reco_loss: 220.1732 - kl_loss: 3.2637 - disc_loss: 1.3014 - beta: 0.7720 - val_loss: 292.2993 - val_reco_loss: 217.4609 - val_kl_loss: 3.7270 - val_disc_loss: 1.4105 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 555.5089 - reco_loss: 463.1785 - kl_loss: 3.7788 - disc_loss: 1.3024 - beta: 0.1840 - val_loss: 753.5778 - val_reco_loss: 659.2009 - val_kl_loss: 1.3545 - val_disc_loss: 1.1462 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 658.9417 - reco_loss: 567.4744 - kl_loss: 1.5335 - disc_loss: 1.2400 - beta: 0.2960 - val_loss: 674.0159 - val_reco_loss: 597.5352 - val_kl_loss: 2.0513 - val_disc_loss: 1.2734 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 63995132.3705 - reco_loss: 63598582.3498 - kl_loss: 3658534.0000 - disc_loss: 1.3971 - beta: 0.4080 - val_loss: 618.8531 - val_reco_loss: 524.7043 - val_kl_loss: 2.8270 - val_disc_loss: 1.5385 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 463.7879 - reco_loss: 374.6125 - kl_loss: 2.7422 - disc_loss: 1.3072 - beta: 0.5200 - val_loss: 507.3374 - val_reco_loss: 410.6573 - val_kl_loss: 3.2230 - val_disc_loss: 1.1700 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 383.6056 - reco_loss: 297.5801 - kl_loss: 3.2101 - disc_loss: 1.2847 - beta: 0.6320 - val_loss: 404.3067 - val_reco_loss: 309.3185 - val_kl_loss: 3.6388 - val_disc_loss: 1.0479 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 444468.9584 - reco_loss: 443670.5390 - kl_loss: 938.2478 - disc_loss: 1.1713 - beta: 0.7440 - val_loss: 313.0744 - val_reco_loss: 229.0783 - val_kl_loss: 4.0986 - val_disc_loss: 1.5181 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 323.9100 - reco_loss: 239.5746 - kl_loss: 2.2439 - disc_loss: 1.3130 - beta: 0.1560 - val_loss: 765.2857 - val_reco_loss: 678.5156 - val_kl_loss: 1.0928 - val_disc_loss: 1.2896 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 641.2245 - reco_loss: 545.5672 - kl_loss: 1.2910 - disc_loss: 1.2172 - beta: 0.2680 - val_loss: 724.6735 - val_reco_loss: 625.1827 - val_kl_loss: 1.7441 - val_disc_loss: 1.1653 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 556.9259 - reco_loss: 466.4007 - kl_loss: 1.8932 - disc_loss: 1.2692 - beta: 0.3800 - val_loss: 577.7449 - val_reco_loss: 489.8310 - val_kl_loss: 2.3264 - val_disc_loss: 1.2754 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 494.0821 - reco_loss: 407.1525 - kl_loss: 2.4324 - disc_loss: 1.2531 - beta: 0.4920\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 494.0707 - reco_loss: 407.1384 - kl_loss: 2.4324 - disc_loss: 1.2531 - beta: 0.4920 - val_loss: 549.7213 - val_reco_loss: 436.5861 - val_kl_loss: 3.0435 - val_disc_loss: 0.9008 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 438.7363 - reco_loss: 330.7922 - kl_loss: 2.9786 - disc_loss: 1.1090 - beta: 0.6040 - val_loss: 415.8988 - val_reco_loss: 323.6288 - val_kl_loss: 3.3771 - val_disc_loss: 0.9924 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 374.2315 - reco_loss: 268.6292 - kl_loss: 3.4817 - disc_loss: 1.1378 - beta: 0.7160 - val_loss: 334.4236 - val_reco_loss: 239.2433 - val_kl_loss: 4.1310 - val_disc_loss: 1.3850 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 277.0343 - reco_loss: 188.9017 - kl_loss: 3.0255 - disc_loss: 1.3299 - beta: 0.1280 - val_loss: 756.8743 - val_reco_loss: 670.1340 - val_kl_loss: 0.8814 - val_disc_loss: 1.1826 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 614.2563 - reco_loss: 528.2787 - kl_loss: 1.1589 - disc_loss: 1.2284 - beta: 0.2400 - val_loss: 686.4921 - val_reco_loss: 605.3904 - val_kl_loss: 1.6085 - val_disc_loss: 1.2182 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 585.4657 - reco_loss: 492.1528 - kl_loss: 1.8297 - disc_loss: 1.2021 - beta: 0.3520 - val_loss: 597.6709 - val_reco_loss: 513.4949 - val_kl_loss: 2.3533 - val_disc_loss: 1.2039 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 100.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 48s 18ms/step - loss: 1100.5118 - reco_loss: 976.2605 - kl_loss: 0.6236 - disc_loss: 1.0198 - beta: 0.2120 - val_loss: 816.3774 - val_reco_loss: 709.4973 - val_kl_loss: 1.5048 - val_disc_loss: 1.0789 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 695.4041 - reco_loss: 598.1842 - kl_loss: 1.6015 - disc_loss: 1.2455 - beta: 0.3240 - val_loss: 670.4020 - val_reco_loss: 592.3400 - val_kl_loss: 2.9510 - val_disc_loss: 1.7267 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 558.3565 - reco_loss: 471.5403 - kl_loss: 2.4278 - disc_loss: 1.2927 - beta: 0.4360 - val_loss: 586.4023 - val_reco_loss: 497.3765 - val_kl_loss: 4.6111 - val_disc_loss: 1.3472 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 441.7368 - reco_loss: 357.3676 - kl_loss: 3.0545 - disc_loss: 1.2690 - beta: 0.5480 - val_loss: 456.8841 - val_reco_loss: 362.4060 - val_kl_loss: 5.2473 - val_disc_loss: 1.1590 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 394.8629 - reco_loss: 307.7260 - kl_loss: 3.6175 - disc_loss: 1.2821 - beta: 0.6600 - val_loss: 415.4866 - val_reco_loss: 310.8330 - val_kl_loss: 5.6404 - val_disc_loss: 1.2650 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 315.7555 - reco_loss: 226.5983 - kl_loss: 3.9425 - disc_loss: 1.2737 - beta: 0.7720 - val_loss: 309.7581 - val_reco_loss: 220.4690 - val_kl_loss: 5.2819 - val_disc_loss: 1.2132 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 433.2395 - reco_loss: 342.5511 - kl_loss: 1.8381 - disc_loss: 1.2235 - beta: 0.1840 - val_loss: 747.8472 - val_reco_loss: 654.1647 - val_kl_loss: 1.9568 - val_disc_loss: 1.3093 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 636.6538 - reco_loss: 534.1332 - kl_loss: 1.9077 - disc_loss: 1.1349 - beta: 0.2960 - val_loss: 752.0721 - val_reco_loss: 643.4153 - val_kl_loss: 3.3616 - val_disc_loss: 1.2982 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 599.5930 - reco_loss: 477.5581 - kl_loss: 2.7072 - disc_loss: 1.0875 - beta: 0.4080 - val_loss: 830.0195 - val_reco_loss: 717.4167 - val_kl_loss: 3.2306 - val_disc_loss: 1.5683 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 680.9432 - reco_loss: 509.5500 - kl_loss: 3.1965 - disc_loss: 0.9093 - beta: 0.5200 - val_loss: 708.1992 - val_reco_loss: 556.5346 - val_kl_loss: 4.9152 - val_disc_loss: 0.9667 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 22596.2784 - reco_loss: 22398.7363 - kl_loss: 5.4203 - disc_loss: 0.6239 - beta: 0.6320 - val_loss: 639.6154 - val_reco_loss: 475.3745 - val_kl_loss: 4.0157 - val_disc_loss: 0.7043 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 61108087.2897 - reco_loss: 61025448.9230 - kl_loss: 58860.8398 - disc_loss: 0.6005 - beta: 0.7440 - val_loss: 517.7631 - val_reco_loss: 317.0686 - val_kl_loss: 5.0268 - val_disc_loss: 0.4566 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 1064.2310 - reco_loss: 781.8086 - kl_loss: 3.4214 - disc_loss: 0.3745 - beta: 0.1560 - val_loss: 1072.9158 - val_reco_loss: 882.0877 - val_kl_loss: 1.3928 - val_disc_loss: 0.5821 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 112966.6753 - reco_loss: 105564.9159 - kl_loss: 10138.5078 - disc_loss: 0.7104 - beta: 0.2680 - val_loss: 968.4344 - val_reco_loss: 757.3609 - val_kl_loss: 1.7998 - val_disc_loss: 1.2925 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 905.0311 - reco_loss: 736.7538 - kl_loss: 2.1847 - disc_loss: 1.4846 - beta: 0.3800 - val_loss: 738.8367 - val_reco_loss: 634.9365 - val_kl_loss: 3.0923 - val_disc_loss: 1.1799 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 100.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 47s 17ms/step - loss: 987.3362 - reco_loss: 874.5721 - kl_loss: 0.6338 - disc_loss: 1.0853 - beta: 0.2120 - val_loss: 878.9966 - val_reco_loss: 792.5626 - val_kl_loss: 1.2704 - val_disc_loss: 1.2509 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 694.0511 - reco_loss: 606.4318 - kl_loss: 1.6659 - disc_loss: 1.2501 - beta: 0.3240 - val_loss: 651.8501 - val_reco_loss: 557.2604 - val_kl_loss: 2.6061 - val_disc_loss: 1.1549 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 547.9788 - reco_loss: 460.0784 - kl_loss: 2.3928 - disc_loss: 1.2653 - beta: 0.4360 - val_loss: 543.4108 - val_reco_loss: 459.5965 - val_kl_loss: 3.3292 - val_disc_loss: 1.2794 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 445.4895 - reco_loss: 360.1184 - kl_loss: 3.0582 - disc_loss: 1.2766 - beta: 0.5480 - val_loss: 456.3745 - val_reco_loss: 377.7372 - val_kl_loss: 3.8467 - val_disc_loss: 1.2553 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 385.0587 - reco_loss: 298.8832 - kl_loss: 3.5735 - disc_loss: 1.2672 - beta: 0.6600 - val_loss: 369.5701 - val_reco_loss: 287.0944 - val_kl_loss: 4.1202 - val_disc_loss: 1.2099 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 316.9466 - reco_loss: 227.8376 - kl_loss: 3.9994 - disc_loss: 1.2368 - beta: 0.7720 - val_loss: 334.0939 - val_reco_loss: 246.3195 - val_kl_loss: 4.8572 - val_disc_loss: 1.2343 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 477.0034 - reco_loss: 375.1487 - kl_loss: 1.8790 - disc_loss: 1.1984 - beta: 0.1840 - val_loss: 809.1279 - val_reco_loss: 712.4751 - val_kl_loss: 1.3909 - val_disc_loss: 1.2577 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 704.1124 - reco_loss: 599.9964 - kl_loss: 1.7547 - disc_loss: 1.1494 - beta: 0.2960 - val_loss: 773.2700 - val_reco_loss: 651.2141 - val_kl_loss: 2.1966 - val_disc_loss: 0.9637 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 636.0366 - reco_loss: 515.5105 - kl_loss: 2.6674 - disc_loss: 1.0432 - beta: 0.4080 - val_loss: 681.8727 - val_reco_loss: 551.0096 - val_kl_loss: 3.5470 - val_disc_loss: 0.8805 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 572.6461 - reco_loss: 451.1171 - kl_loss: 3.8510 - disc_loss: 1.0299 - beta: 0.5200 - val_loss: 660.5421 - val_reco_loss: 489.8513 - val_kl_loss: 3.6380 - val_disc_loss: 0.6289 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 516.3152 - reco_loss: 351.9299 - kl_loss: 4.2574 - disc_loss: 0.7785 - beta: 0.6320 - val_loss: 558.5535 - val_reco_loss: 398.2669 - val_kl_loss: 4.4974 - val_disc_loss: 0.9029 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 436.1748 - reco_loss: 271.1485 - kl_loss: 4.5785 - disc_loss: 0.7119 - beta: 0.7440 - val_loss: 449.8442 - val_reco_loss: 267.4902 - val_kl_loss: 4.6816 - val_disc_loss: 0.6292 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 430.6390 - reco_loss: 270.4413 - kl_loss: 2.5816 - disc_loss: 0.7492 - beta: 0.1560 - val_loss: 886.2902 - val_reco_loss: 726.2395 - val_kl_loss: 1.1197 - val_disc_loss: 0.7634 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 715.4860 - reco_loss: 554.0912 - kl_loss: 1.5064 - disc_loss: 0.7128 - beta: 0.2680 - val_loss: 844.3131 - val_reco_loss: 679.7224 - val_kl_loss: 1.9121 - val_disc_loss: 0.6473 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 716.8183 - reco_loss: 545.3167 - kl_loss: 2.2331 - disc_loss: 0.6905 - beta: 0.3800 - val_loss: 695.9696 - val_reco_loss: 530.4720 - val_kl_loss: 2.7068 - val_disc_loss: 0.5991 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 13447288.2956 - reco_loss: 13414898.4839 - kl_loss: 9195.0195 - disc_loss: 0.7536 - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 13435764.8627 - reco_loss: 13403402.6155 - kl_loss: 9187.6660 - disc_loss: 0.7536 - beta: 0.4920 - val_loss: 588.6663 - val_reco_loss: 441.9466 - val_kl_loss: 3.6043 - val_disc_loss: 0.9039 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 494.7111 - reco_loss: 346.6770 - kl_loss: 4.2389 - disc_loss: 0.8613 - beta: 0.6040 - val_loss: 547.1097 - val_reco_loss: 378.3009 - val_kl_loss: 4.2971 - val_disc_loss: 0.6396 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 4425979529.7302 - reco_loss: 3029490898.6432 - kl_loss: 15321611264.0000 - disc_loss: 4.5905 - beta: 0.7160 - val_loss: 435.5317 - val_reco_loss: 269.6824 - val_kl_loss: 4.5604 - val_disc_loss: 0.8417 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 400.1697 - reco_loss: 227.7193 - kl_loss: 3.8663 - disc_loss: 0.7118 - beta: 0.1280 - val_loss: 880.7000 - val_reco_loss: 749.2408 - val_kl_loss: 0.9309 - val_disc_loss: 0.9341 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 741.2517 - reco_loss: 595.2850 - kl_loss: 1.4368 - disc_loss: 0.7711 - beta: 0.2400 - val_loss: 843.9580 - val_reco_loss: 680.2946 - val_kl_loss: 1.9761 - val_disc_loss: 0.7251 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 760.8639 - reco_loss: 586.9996 - kl_loss: 2.4820 - disc_loss: 0.6419 - beta: 0.3520 - val_loss: 766.1262 - val_reco_loss: 583.9243 - val_kl_loss: 2.7923 - val_disc_loss: 0.5163 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 100.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 47s 17ms/step - loss: 1204.6053 - reco_loss: 1075.3053 - kl_loss: 0.5384 - disc_loss: 0.9911 - beta: 0.2120 - val_loss: 774.9584 - val_reco_loss: 689.2828 - val_kl_loss: 1.1775 - val_disc_loss: 1.3878 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 656.8386 - reco_loss: 568.7561 - kl_loss: 1.6331 - disc_loss: 1.2844 - beta: 0.3240 - val_loss: 676.7338 - val_reco_loss: 578.5782 - val_kl_loss: 2.8194 - val_disc_loss: 1.6355 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 569.9958 - reco_loss: 481.1809 - kl_loss: 2.6500 - disc_loss: 1.3244 - beta: 0.4360 - val_loss: 547.3865 - val_reco_loss: 464.8963 - val_kl_loss: 3.9740 - val_disc_loss: 1.2636 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 474.2435 - reco_loss: 383.2659 - kl_loss: 3.3588 - disc_loss: 1.2811 - beta: 0.5480 - val_loss: 432.3500 - val_reco_loss: 339.8799 - val_kl_loss: 4.5364 - val_disc_loss: 1.1642 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 385.0982 - reco_loss: 291.7875 - kl_loss: 3.9410 - disc_loss: 1.2217 - beta: 0.6600 - val_loss: 429.1346 - val_reco_loss: 305.0633 - val_kl_loss: 4.8849 - val_disc_loss: 0.9828 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 53989401296465231872.0000 - reco_loss: 53851187713531322368.0000 - kl_loss: 718319673799606272.0000 - disc_loss: 168996.3091 - beta: 0.7720 - val_loss: 486.5364 - val_reco_loss: 317.5475 - val_kl_loss: 4.1160 - val_disc_loss: 0.8082 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 581.2130 - reco_loss: 428.2167 - kl_loss: 1.8375 - disc_loss: 1.3989 - beta: 0.1840 - val_loss: 753.3975 - val_reco_loss: 669.0215 - val_kl_loss: 1.5930 - val_disc_loss: 1.3844 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 587.0969 - reco_loss: 506.1875 - kl_loss: 1.7497 - disc_loss: 1.3600 - beta: 0.2960 - val_loss: 634.4508 - val_reco_loss: 555.3353 - val_kl_loss: 2.6244 - val_disc_loss: 1.2712 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 507.7872 - reco_loss: 428.4049 - kl_loss: 2.5551 - disc_loss: 1.3061 - beta: 0.4080 - val_loss: 537.3184 - val_reco_loss: 453.7859 - val_kl_loss: 3.5965 - val_disc_loss: 1.2625 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 463.2694 - reco_loss: 377.5788 - kl_loss: 3.2839 - disc_loss: 1.2657 - beta: 0.5200 - val_loss: 454.5627 - val_reco_loss: 368.4129 - val_kl_loss: 4.2980 - val_disc_loss: 1.2224 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 1005.1717 - reco_loss: 915.9870 - kl_loss: 7.6749 - disc_loss: 1.2857 - beta: 0.6320 - val_loss: 373.1567 - val_reco_loss: 289.2466 - val_kl_loss: 4.8323 - val_disc_loss: 1.2546 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 304.2383 - reco_loss: 217.8422 - kl_loss: 4.2697 - disc_loss: 1.2810 - beta: 0.7440 - val_loss: 297.2124 - val_reco_loss: 209.6065 - val_kl_loss: 5.1849 - val_disc_loss: 1.2965 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 345.1284 - reco_loss: 244.7416 - kl_loss: 2.7464 - disc_loss: 1.1899 - beta: 0.1560 - val_loss: 871.1155 - val_reco_loss: 750.3074 - val_kl_loss: 1.3124 - val_disc_loss: 0.8027 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 6743578714.0927 - reco_loss: 6742773086.3494 - kl_loss: 2335507.7500 - disc_loss: 0.9170 - beta: 0.2680 - val_loss: 846.5547 - val_reco_loss: 658.6738 - val_kl_loss: 2.2139 - val_disc_loss: 0.4852 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 861.9109 - reco_loss: 639.7503 - kl_loss: 2.1998 - disc_loss: 0.5890 - beta: 0.3800 - val_loss: 917.1490 - val_reco_loss: 633.1077 - val_kl_loss: 2.4334 - val_disc_loss: 0.1599 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 1247457.2904 - reco_loss: 1232189.9537 - kl_loss: 25360.5977 - disc_loss: 1.3353 - beta: 0.4920 - val_loss: 883.2730 - val_reco_loss: 677.6684 - val_kl_loss: 3.2249 - val_disc_loss: 0.5975 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4640\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4640 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.5760 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6880 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.8000 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2120 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3240 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 100.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 46s 17ms/step - loss: 1113.1767 - reco_loss: 978.3335 - kl_loss: 0.5974 - disc_loss: 0.9659 - beta: 0.2120 - val_loss: 1017.6917 - val_reco_loss: 912.0568 - val_kl_loss: 1.1794 - val_disc_loss: 1.4072 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 756.6150 - reco_loss: 654.6606 - kl_loss: 1.5367 - disc_loss: 1.2250 - beta: 0.3240 - val_loss: 783.6735 - val_reco_loss: 696.5193 - val_kl_loss: 1.7925 - val_disc_loss: 1.2867 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 591.8682 - reco_loss: 503.3320 - kl_loss: 2.1853 - disc_loss: 1.2820 - beta: 0.4360 - val_loss: 624.0725 - val_reco_loss: 526.4495 - val_kl_loss: 2.8283 - val_disc_loss: 1.2000 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 532.9605 - reco_loss: 435.2430 - kl_loss: 2.7811 - disc_loss: 1.1977 - beta: 0.5480 - val_loss: 527.8701 - val_reco_loss: 424.8293 - val_kl_loss: 3.8711 - val_disc_loss: 1.1011 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 460.4492 - reco_loss: 352.5953 - kl_loss: 3.4556 - disc_loss: 1.1401 - beta: 0.6600 - val_loss: 578.2100 - val_reco_loss: 437.9581 - val_kl_loss: 4.1302 - val_disc_loss: 1.0567 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 476.5544 - reco_loss: 328.3005 - kl_loss: 4.1408 - disc_loss: 0.9525 - beta: 0.7720 - val_loss: 487.4237 - val_reco_loss: 274.1533 - val_kl_loss: 4.0270 - val_disc_loss: 0.3129 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 623.2203 - reco_loss: 466.2900 - kl_loss: 1.7844 - disc_loss: 0.8260 - beta: 0.1840 - val_loss: 949.3083 - val_reco_loss: 811.0159 - val_kl_loss: 1.6770 - val_disc_loss: 0.7522 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 865.2177 - reco_loss: 704.9742 - kl_loss: 1.8474 - disc_loss: 0.7535 - beta: 0.2960 - val_loss: 1000.2023 - val_reco_loss: 805.4078 - val_kl_loss: 2.2824 - val_disc_loss: 0.4480 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 906.4170 - reco_loss: 662.6048 - kl_loss: 2.2610 - disc_loss: 0.3676 - beta: 0.4080 - val_loss: 901.1167 - val_reco_loss: 653.0541 - val_kl_loss: 2.9197 - val_disc_loss: 0.4346 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 841.3544 - reco_loss: 580.4670 - kl_loss: 2.9329 - disc_loss: 0.4491 - beta: 0.5200 - val_loss: 917.4170 - val_reco_loss: 609.9225 - val_kl_loss: 3.0549 - val_disc_loss: 0.2472 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 777.3986 - reco_loss: 500.4332 - kl_loss: 3.1424 - disc_loss: 0.3636 - beta: 0.6320 - val_loss: 650.2582 - val_reco_loss: 449.9943 - val_kl_loss: 4.0447 - val_disc_loss: 0.5894 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 90507846709.4126 - reco_loss: 90438292793.1622 - kl_loss: 1117528448.0000 - disc_loss: 0.4280 - beta: 0.7440 - val_loss: 689.0295 - val_reco_loss: 415.0968 - val_kl_loss: 5.0426 - val_disc_loss: 0.3703 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 635.6443 - reco_loss: 368.2209 - kl_loss: 2.3675 - disc_loss: 0.3147 - beta: 0.1560 - val_loss: 1019.8831 - val_reco_loss: 788.9481 - val_kl_loss: 1.0332 - val_disc_loss: 0.4470 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 2755093583.4880 - reco_loss: 2753603242.6477 - kl_loss: 2281872.7500 - disc_loss: 0.4708 - beta: 0.2680 - val_loss: 1058.1528 - val_reco_loss: 807.9335 - val_kl_loss: 2.6693 - val_disc_loss: 0.3995 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 947.2558 - reco_loss: 669.5512 - kl_loss: 2.6699 - disc_loss: 0.4214 - beta: 0.3800 - val_loss: 965.7156 - val_reco_loss: 673.1945 - val_kl_loss: 2.9230 - val_disc_loss: 0.2828 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 872.5529 - reco_loss: 542.3913 - kl_loss: 2.4854 - disc_loss: 0.2495 - beta: 0.4920\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 872.5363 - reco_loss: 542.3776 - kl_loss: 2.4854 - disc_loss: 0.2495 - beta: 0.4920 - val_loss: 836.1741 - val_reco_loss: 501.6008 - val_kl_loss: 3.2841 - val_disc_loss: 0.1416 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 22532101474610208323475079168.0000 - reco_loss: 22300978885512033001103425536.0000 - kl_loss: 1014093005808563671816732672.0000 - disc_loss: 0.2474 - beta: 0.6040 - val_loss: 768.8762 - val_reco_loss: 496.9781 - val_kl_loss: 4.4359 - val_disc_loss: 0.6953 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 12438198504488080.0000 - reco_loss: 12097804099967550.0000 - kl_loss: 198642656870400.0000 - disc_loss: 0.6606 - beta: 0.7160 - val_loss: 565.6609 - val_reco_loss: 334.9011 - val_kl_loss: 5.0169 - val_disc_loss: 0.7636 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 494.9665 - reco_loss: 286.2324 - kl_loss: 3.6868 - disc_loss: 0.8358 - beta: 0.1280 - val_loss: 1006.9869 - val_reco_loss: 867.9622 - val_kl_loss: 1.0967 - val_disc_loss: 0.6647 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 7210.6766 - reco_loss: 7065.1856 - kl_loss: 70.5274 - disc_loss: 0.9772 - beta: 0.2400 - val_loss: 913.4760 - val_reco_loss: 764.8266 - val_kl_loss: 2.3033 - val_disc_loss: 0.6100 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 832.5842 - reco_loss: 678.9789 - kl_loss: 2.4733 - disc_loss: 0.8361 - beta: 0.3520 - val_loss: 879.6108 - val_reco_loss: 726.8220 - val_kl_loss: 3.2748 - val_disc_loss: 0.5784 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 100.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 49s 18ms/step - loss: 1119.8117 - reco_loss: 972.7695 - kl_loss: 0.5937 - disc_loss: 1.0036 - beta: 0.2120 - val_loss: 863.4316 - val_reco_loss: 769.3300 - val_kl_loss: 1.1352 - val_disc_loss: 1.2030 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 677.2202 - reco_loss: 579.8117 - kl_loss: 1.5787 - disc_loss: 1.2035 - beta: 0.3240 - val_loss: 710.9900 - val_reco_loss: 619.1351 - val_kl_loss: 2.1309 - val_disc_loss: 1.2242 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 544.7127 - reco_loss: 452.8988 - kl_loss: 2.3486 - disc_loss: 1.2515 - beta: 0.4360 - val_loss: 615.0552 - val_reco_loss: 512.4415 - val_kl_loss: 2.9890 - val_disc_loss: 1.1458 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 517.8775 - reco_loss: 419.8775 - kl_loss: 2.9370 - disc_loss: 1.2218 - beta: 0.5480 - val_loss: 506.7220 - val_reco_loss: 412.3522 - val_kl_loss: 3.7303 - val_disc_loss: 1.2357 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 450.9017 - reco_loss: 350.4792 - kl_loss: 3.5072 - disc_loss: 1.1976 - beta: 0.6600 - val_loss: 576.2418 - val_reco_loss: 410.2922 - val_kl_loss: 3.7996 - val_disc_loss: 0.8092 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 470.8493 - reco_loss: 327.6564 - kl_loss: 3.5612 - disc_loss: 1.0756 - beta: 0.7720 - val_loss: 476.2703 - val_reco_loss: 336.7694 - val_kl_loss: 4.1839 - val_disc_loss: 1.1332 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 518.9180 - reco_loss: 415.4989 - kl_loss: 1.6832 - disc_loss: 1.2187 - beta: 0.1840 - val_loss: 833.5226 - val_reco_loss: 737.4313 - val_kl_loss: 1.4704 - val_disc_loss: 1.4798 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 699.1696 - reco_loss: 599.5170 - kl_loss: 1.7347 - disc_loss: 1.1759 - beta: 0.2960 - val_loss: 664.5919 - val_reco_loss: 575.2117 - val_kl_loss: 2.4129 - val_disc_loss: 1.1853 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 97439434621701537792.0000 - reco_loss: 97144667401411690496.0000 - kl_loss: 532968298556424192.0000 - disc_loss: 1.1869 - beta: 0.4080 - val_loss: 582.9595 - val_reco_loss: 492.3035 - val_kl_loss: 3.3698 - val_disc_loss: 1.1919 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.5200 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6320 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7440 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1560 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2680 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3800 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4919\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 100.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 47s 17ms/step - loss: 1118.9241 - reco_loss: 977.0932 - kl_loss: 0.5395 - disc_loss: 0.9160 - beta: 0.2120 - val_loss: 894.2727 - val_reco_loss: 795.9434 - val_kl_loss: 1.2804 - val_disc_loss: 1.2031 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 681.0014 - reco_loss: 587.0852 - kl_loss: 1.4734 - disc_loss: 1.2354 - beta: 0.3240 - val_loss: 690.2320 - val_reco_loss: 604.8496 - val_kl_loss: 2.3680 - val_disc_loss: 1.3281 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 560.6948 - reco_loss: 474.8008 - kl_loss: 2.2505 - disc_loss: 1.2794 - beta: 0.4360 - val_loss: 563.5225 - val_reco_loss: 480.4302 - val_kl_loss: 3.3874 - val_disc_loss: 1.3052 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 454.7836 - reco_loss: 372.1332 - kl_loss: 2.8701 - disc_loss: 1.3086 - beta: 0.5480 - val_loss: 479.8472 - val_reco_loss: 390.4994 - val_kl_loss: 3.8546 - val_disc_loss: 1.3152 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 373.9438 - reco_loss: 291.0706 - kl_loss: 3.2494 - disc_loss: 1.3235 - beta: 0.6600 - val_loss: 414.4179 - val_reco_loss: 322.9951 - val_kl_loss: 4.0729 - val_disc_loss: 1.1531 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 306.2667 - reco_loss: 224.0968 - kl_loss: 3.5131 - disc_loss: 1.3248 - beta: 0.7720 - val_loss: 271.8054 - val_reco_loss: 189.6380 - val_kl_loss: 4.1776 - val_disc_loss: 1.2883 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 393.3653 - reco_loss: 310.4096 - kl_loss: 1.5995 - disc_loss: 1.2664 - beta: 0.1840 - val_loss: 720.0902 - val_reco_loss: 632.7306 - val_kl_loss: 1.3437 - val_disc_loss: 1.2607 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 585.2758 - reco_loss: 497.5030 - kl_loss: 1.5557 - disc_loss: 1.2312 - beta: 0.2960 - val_loss: 622.4594 - val_reco_loss: 539.5903 - val_kl_loss: 2.1722 - val_disc_loss: 1.3373 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 547.4375 - reco_loss: 458.1737 - kl_loss: 2.2318 - disc_loss: 1.2456 - beta: 0.4080 - val_loss: 553.5127 - val_reco_loss: 459.2912 - val_kl_loss: 3.0324 - val_disc_loss: 1.2801 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 461.2294 - reco_loss: 374.2028 - kl_loss: 2.8885 - disc_loss: 1.2634 - beta: 0.5200 - val_loss: 456.7725 - val_reco_loss: 396.4042 - val_kl_loss: 3.6271 - val_disc_loss: 1.4236 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 396.6542 - reco_loss: 309.1448 - kl_loss: 3.4400 - disc_loss: 1.2411 - beta: 0.6320 - val_loss: 471.6855 - val_reco_loss: 351.2366 - val_kl_loss: 4.1582 - val_disc_loss: 1.2083 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 445.2785 - reco_loss: 308.9261 - kl_loss: 3.9187 - disc_loss: 1.1811 - beta: 0.7440 - val_loss: 318.4377 - val_reco_loss: 235.3100 - val_kl_loss: 4.2359 - val_disc_loss: 1.2469 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 326.7583 - reco_loss: 242.3583 - kl_loss: 2.3932 - disc_loss: 1.2737 - beta: 0.1560 - val_loss: 762.2866 - val_reco_loss: 673.8782 - val_kl_loss: 1.1664 - val_disc_loss: 1.2594 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 591.7461 - reco_loss: 504.2165 - kl_loss: 1.4703 - disc_loss: 1.2299 - beta: 0.2680 - val_loss: 698.4047 - val_reco_loss: 637.7278 - val_kl_loss: 1.9434 - val_disc_loss: 1.8321 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 545.7873 - reco_loss: 460.9775 - kl_loss: 2.2142 - disc_loss: 1.3113 - beta: 0.3800 - val_loss: 584.6457 - val_reco_loss: 504.7117 - val_kl_loss: 2.5868 - val_disc_loss: 1.2624 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 479.7481 - reco_loss: 395.3044 - kl_loss: 2.8850 - disc_loss: 1.2756 - beta: 0.4920\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 479.7324 - reco_loss: 395.2887 - kl_loss: 2.8850 - disc_loss: 1.2756 - beta: 0.4920 - val_loss: 559.6748 - val_reco_loss: 475.5168 - val_kl_loss: 3.2827 - val_disc_loss: 1.3498 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 379.6487 - reco_loss: 295.9705 - kl_loss: 3.5370 - disc_loss: 1.2781 - beta: 0.6040 - val_loss: 423.5024 - val_reco_loss: 333.7827 - val_kl_loss: 3.8433 - val_disc_loss: 1.2791 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 335.0312 - reco_loss: 246.2818 - kl_loss: 4.0913 - disc_loss: 1.2178 - beta: 0.7160 - val_loss: 336.9700 - val_reco_loss: 242.8866 - val_kl_loss: 4.3454 - val_disc_loss: 1.3036 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 267.5578 - reco_loss: 180.3064 - kl_loss: 3.4301 - disc_loss: 1.3120 - beta: 0.1280 - val_loss: 825.6930 - val_reco_loss: 728.5981 - val_kl_loss: 0.9256 - val_disc_loss: 0.9456 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 621.4592 - reco_loss: 533.2836 - kl_loss: 1.3021 - disc_loss: 1.2420 - beta: 0.2400 - val_loss: 735.4854 - val_reco_loss: 651.8394 - val_kl_loss: 1.7223 - val_disc_loss: 1.3724 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 567.3323 - reco_loss: 472.6834 - kl_loss: 2.0370 - disc_loss: 1.2420 - beta: 0.3520 - val_loss: 646.2911 - val_reco_loss: 556.5859 - val_kl_loss: 2.5056 - val_disc_loss: 1.3481 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 100.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 49s 18ms/step - loss: 1018.8067 - reco_loss: 890.8199 - kl_loss: 0.6429 - disc_loss: 0.9840 - beta: 0.2120 - val_loss: 997.6207 - val_reco_loss: 874.8523 - val_kl_loss: 1.1478 - val_disc_loss: 1.0682 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 737.3191 - reco_loss: 638.9525 - kl_loss: 1.6748 - disc_loss: 1.2273 - beta: 0.3240 - val_loss: 733.2754 - val_reco_loss: 639.7795 - val_kl_loss: 2.2189 - val_disc_loss: 1.5850 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 57s 23ms/step - loss: 595.6891 - reco_loss: 495.4350 - kl_loss: 2.5174 - disc_loss: 1.1786 - beta: 0.4360 - val_loss: 659.9023 - val_reco_loss: 550.8181 - val_kl_loss: 3.0686 - val_disc_loss: 1.0151 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 603.6164 - reco_loss: 483.9555 - kl_loss: 3.3651 - disc_loss: 1.0380 - beta: 0.5480 - val_loss: 665.4326 - val_reco_loss: 532.8010 - val_kl_loss: 3.3280 - val_disc_loss: 0.9941 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 591.0522 - reco_loss: 420.7579 - kl_loss: 3.4070 - disc_loss: 0.7959 - beta: 0.6600 - val_loss: 560.3853 - val_reco_loss: 436.7870 - val_kl_loss: 3.3214 - val_disc_loss: 0.9417 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 504.7064 - reco_loss: 318.8234 - kl_loss: 3.0696 - disc_loss: 0.5242 - beta: 0.7720 - val_loss: 666.8342 - val_reco_loss: 501.9352 - val_kl_loss: 3.1795 - val_disc_loss: 0.6545 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 51s 20ms/step - loss: 862.7916 - reco_loss: 672.7233 - kl_loss: 1.6544 - disc_loss: 1.8138 - beta: 0.1840 - val_loss: 1080.5515 - val_reco_loss: 948.7932 - val_kl_loss: 1.2738 - val_disc_loss: 1.1760 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 62s 25ms/step - loss: 815.5762 - reco_loss: 699.4876 - kl_loss: 1.4929 - disc_loss: 1.1165 - beta: 0.2960 - val_loss: 829.3394 - val_reco_loss: 734.4836 - val_kl_loss: 2.0335 - val_disc_loss: 1.1498 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 678.4495 - reco_loss: 554.5467 - kl_loss: 2.2052 - disc_loss: 1.0731 - beta: 0.4080 - val_loss: 759.6643 - val_reco_loss: 615.5790 - val_kl_loss: 2.3229 - val_disc_loss: 0.7673 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 641.7232 - reco_loss: 491.9800 - kl_loss: 2.9287 - disc_loss: 0.8586 - beta: 0.5200 - val_loss: 664.2087 - val_reco_loss: 512.4987 - val_kl_loss: 3.4217 - val_disc_loss: 0.7269 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 1385.8582 - reco_loss: 1215.2317 - kl_loss: 11.1070 - disc_loss: 0.8015 - beta: 0.6320 - val_loss: 569.1357 - val_reco_loss: 415.9009 - val_kl_loss: 4.0322 - val_disc_loss: 0.5743 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 528.4613 - reco_loss: 362.6388 - kl_loss: 8.2631 - disc_loss: 0.8359 - beta: 0.7440 - val_loss: 471.2862 - val_reco_loss: 343.8573 - val_kl_loss: 4.8889 - val_disc_loss: 0.9843 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 499.4345 - reco_loss: 342.7260 - kl_loss: 2.5560 - disc_loss: 0.8382 - beta: 0.1560 - val_loss: 1034.3782 - val_reco_loss: 850.7722 - val_kl_loss: 1.2672 - val_disc_loss: 0.6505 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2680 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3800 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2400 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3520 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4639\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4640 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.5760 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6880 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.8000 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2120 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3240 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1000.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 58s 21ms/step - loss: 1943.8218 - reco_loss: 1204.5749 - kl_loss: 0.4251 - disc_loss: 1.4517 - beta: 0.2120 - val_loss: 1595.9753 - val_reco_loss: 870.4899 - val_kl_loss: 0.6064 - val_disc_loss: 1.2410 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 1520.6255 - reco_loss: 777.4988 - kl_loss: 1.0170 - disc_loss: 1.4853 - beta: 0.3240 - val_loss: 1368.3148 - val_reco_loss: 827.2282 - val_kl_loss: 1.2930 - val_disc_loss: 1.5980 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1334.9521 - reco_loss: 605.7172 - kl_loss: 1.6185 - disc_loss: 1.3844 - beta: 0.4360 - val_loss: 1261.5742 - val_reco_loss: 555.0928 - val_kl_loss: 2.1188 - val_disc_loss: 1.3446 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1128.9541 - reco_loss: 429.6726 - kl_loss: 2.2422 - disc_loss: 1.3888 - beta: 0.5480 - val_loss: 1118.3672 - val_reco_loss: 420.6047 - val_kl_loss: 2.5427 - val_disc_loss: 1.3915 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1041.3538 - reco_loss: 344.3950 - kl_loss: 2.5751 - disc_loss: 1.3882 - beta: 0.6600 - val_loss: 991.7280 - val_reco_loss: 296.6711 - val_kl_loss: 3.0689 - val_disc_loss: 1.3873 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 929.5966 - reco_loss: 233.7104 - kl_loss: 2.8984 - disc_loss: 1.3865 - beta: 0.7720 - val_loss: 884.1333 - val_reco_loss: 187.4398 - val_kl_loss: 3.5410 - val_disc_loss: 1.3863 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 1018.4810 - reco_loss: 322.6198 - kl_loss: 1.4142 - disc_loss: 1.3862 - beta: 0.1840 - val_loss: 1372.5873 - val_reco_loss: 672.9143 - val_kl_loss: 1.1859 - val_disc_loss: 1.3859 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 1258.1483 - reco_loss: 553.6508 - kl_loss: 1.3234 - disc_loss: 1.3856 - beta: 0.2960 - val_loss: 1297.9729 - val_reco_loss: 587.9166 - val_kl_loss: 1.9097 - val_disc_loss: 1.3869 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 1185.1581 - reco_loss: 481.8288 - kl_loss: 1.8596 - disc_loss: 1.3920 - beta: 0.4080 - val_loss: 1178.5104 - val_reco_loss: 476.0798 - val_kl_loss: 2.5538 - val_disc_loss: 1.3860 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 1082.4086 - reco_loss: 384.3397 - kl_loss: 2.3022 - disc_loss: 1.3875 - beta: 0.5200 - val_loss: 1047.7170 - val_reco_loss: 351.4052 - val_kl_loss: 3.1514 - val_disc_loss: 1.3833 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 179235.2664 - reco_loss: 178308.7594 - kl_loss: 132.6763 - disc_loss: 1.4033 - beta: 0.6320 - val_loss: 989.3882 - val_reco_loss: 282.4139 - val_kl_loss: 3.5460 - val_disc_loss: 1.3894 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 941.7458 - reco_loss: 238.2919 - kl_loss: 2.9742 - disc_loss: 1.3919 - beta: 0.7440 - val_loss: 880.2543 - val_reco_loss: 181.3586 - val_kl_loss: 4.1604 - val_disc_loss: 1.3868 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 18797232502616.8281 - reco_loss: 18794405812490.9141 - kl_loss: 22292140032.0000 - disc_loss: 1.3879 - beta: 0.1560 - val_loss: 1367.1152 - val_reco_loss: 704.1710 - val_kl_loss: 1.1618 - val_disc_loss: 1.4394 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 1209.0110 - reco_loss: 507.8949 - kl_loss: 1.2246 - disc_loss: 1.3867 - beta: 0.2680 - val_loss: 1232.9495 - val_reco_loss: 537.3241 - val_kl_loss: 2.0352 - val_disc_loss: 1.3838 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 1156.5745 - reco_loss: 456.4816 - kl_loss: 1.7903 - disc_loss: 1.3888 - beta: 0.3800 - val_loss: 1127.7140 - val_reco_loss: 456.1014 - val_kl_loss: 2.7945 - val_disc_loss: 1.3907 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1078.0754 - reco_loss: 378.7830 - kl_loss: 2.3032 - disc_loss: 1.3910 - beta: 0.4920 - val_loss: 1056.0720 - val_reco_loss: 357.9325 - val_kl_loss: 3.2103 - val_disc_loss: 1.3987 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 1009.1720 - reco_loss: 313.2996 - kl_loss: 2.7596 - disc_loss: 1.3889 - beta: 0.6040 - val_loss: 980.4771 - val_reco_loss: 283.9582 - val_kl_loss: 3.8750 - val_disc_loss: 1.3693 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 941.1524 - reco_loss: 243.4125 - kl_loss: 3.1066 - disc_loss: 1.3913 - beta: 0.7160 - val_loss: 906.2724 - val_reco_loss: 209.8287 - val_kl_loss: 4.3466 - val_disc_loss: 1.3878 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 3807.5454 - reco_loss: 3088.1420 - kl_loss: 17.0209 - disc_loss: 1.3872 - beta: 0.1280 - val_loss: 1339.4829 - val_reco_loss: 631.0335 - val_kl_loss: 0.9274 - val_disc_loss: 1.3819 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 1233.2817 - reco_loss: 536.1389 - kl_loss: 1.1089 - disc_loss: 1.3870 - beta: 0.2400 - val_loss: 1223.0339 - val_reco_loss: 613.0331 - val_kl_loss: 1.7578 - val_disc_loss: 1.5004 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 1175.8079 - reco_loss: 474.1016 - kl_loss: 1.6439 - disc_loss: 1.4039 - beta: 0.3520 - val_loss: 1210.2820 - val_reco_loss: 476.5475 - val_kl_loss: 2.2483 - val_disc_loss: 1.3816 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1099.6332 - reco_loss: 401.3975 - kl_loss: 2.1129 - disc_loss: 1.3883 - beta: 0.4640\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 1099.6192 - reco_loss: 401.3842 - kl_loss: 2.1129 - disc_loss: 1.3883 - beta: 0.4640 - val_loss: 1151.0120 - val_reco_loss: 442.7057 - val_kl_loss: 2.9017 - val_disc_loss: 1.4119 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 1031.2951 - reco_loss: 328.4673 - kl_loss: 2.5768 - disc_loss: 1.3883 - beta: 0.5760 - val_loss: 998.6138 - val_reco_loss: 304.2435 - val_kl_loss: 3.3972 - val_disc_loss: 1.3910 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 937.7050 - reco_loss: 242.3052 - kl_loss: 2.9899 - disc_loss: 1.3879 - beta: 0.6880 - val_loss: 966.9010 - val_reco_loss: 243.7416 - val_kl_loss: 3.9260 - val_disc_loss: 1.3990 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 891.8168 - reco_loss: 193.0752 - kl_loss: 3.2817 - disc_loss: 1.3898 - beta: 0.8000 - val_loss: 841.0768 - val_reco_loss: 142.9836 - val_kl_loss: 4.3413 - val_disc_loss: 1.3865 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 1233.1782 - reco_loss: 537.5078 - kl_loss: 0.9353 - disc_loss: 1.3853 - beta: 0.2120 - val_loss: 1249.8418 - val_reco_loss: 547.7575 - val_kl_loss: 1.5548 - val_disc_loss: 1.3904 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 1145.6956 - reco_loss: 447.5413 - kl_loss: 1.6274 - disc_loss: 1.3845 - beta: 0.3240 - val_loss: 1179.4305 - val_reco_loss: 478.3873 - val_kl_loss: 2.3368 - val_disc_loss: 1.3820 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 1625683.5429 - reco_loss: 1611713.0615 - kl_loss: 52152.8555 - disc_loss: 1.3840 - beta: 0.4360 - val_loss: 1108.5859 - val_reco_loss: 402.9759 - val_kl_loss: 3.0630 - val_disc_loss: 1.3816 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 1044.4646 - reco_loss: 348.3184 - kl_loss: 2.7171 - disc_loss: 1.4326 - beta: 0.5480 - val_loss: 1024.1682 - val_reco_loss: 320.6064 - val_kl_loss: 3.7438 - val_disc_loss: 1.3752 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 11492.2564 - reco_loss: 10757.3622 - kl_loss: 246.7491 - disc_loss: 1.3948 - beta: 0.6600 - val_loss: 919.7735 - val_reco_loss: 245.6716 - val_kl_loss: 4.1487 - val_disc_loss: 1.4293 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 887.4988 - reco_loss: 189.5085 - kl_loss: 3.3394 - disc_loss: 1.3932 - beta: 0.7720 - val_loss: 853.4205 - val_reco_loss: 155.3385 - val_kl_loss: 4.4172 - val_disc_loss: 1.3851 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 996.0280 - reco_loss: 297.3917 - kl_loss: 1.4822 - disc_loss: 1.3860 - beta: 0.1840 - val_loss: 1255.7671 - val_reco_loss: 553.5262 - val_kl_loss: 1.3320 - val_disc_loss: 1.3592 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 1211.0517 - reco_loss: 512.8264 - kl_loss: 1.4210 - disc_loss: 1.3830 - beta: 0.2960 - val_loss: 1393.1812 - val_reco_loss: 654.9525 - val_kl_loss: 2.1260 - val_disc_loss: 1.4371 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 1115.0674 - reco_loss: 415.7154 - kl_loss: 2.0009 - disc_loss: 1.3919 - beta: 0.4080 - val_loss: 1109.3802 - val_reco_loss: 431.1236 - val_kl_loss: 2.8681 - val_disc_loss: 1.3896 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 1037.8098 - reco_loss: 338.4823 - kl_loss: 2.5441 - disc_loss: 1.3854 - beta: 0.5199\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 1037.8026 - reco_loss: 338.4708 - kl_loss: 2.5439 - disc_loss: 1.3854 - beta: 0.5200 - val_loss: 1044.8684 - val_reco_loss: 337.5565 - val_kl_loss: 3.4141 - val_disc_loss: 1.3817 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 968.1826 - reco_loss: 267.4185 - kl_loss: 3.0603 - disc_loss: 1.3814 - beta: 0.6320 - val_loss: 976.7025 - val_reco_loss: 267.5959 - val_kl_loss: 4.1162 - val_disc_loss: 1.3854 - val_beta: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 895.7900 - reco_loss: 194.8167 - kl_loss: 3.4736 - disc_loss: 1.3842 - beta: 0.7440 - val_loss: 886.7240 - val_reco_loss: 180.3165 - val_kl_loss: 4.6038 - val_disc_loss: 1.3804 - val_beta: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 964.8501 - reco_loss: 262.4207 - kl_loss: 3.5301 - disc_loss: 1.3844 - beta: 0.1560 - val_loss: 1290.7571 - val_reco_loss: 599.4289 - val_kl_loss: 1.1229 - val_disc_loss: 1.3933 - val_beta: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 1200.4316 - reco_loss: 500.7038 - kl_loss: 1.2895 - disc_loss: 1.3849 - beta: 0.2680 - val_loss: 1237.0288 - val_reco_loss: 520.0679 - val_kl_loss: 1.9571 - val_disc_loss: 1.3857 - val_beta: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 1138.6409 - reco_loss: 435.4164 - kl_loss: 1.9276 - disc_loss: 1.3781 - beta: 0.3800 - val_loss: 1162.4229 - val_reco_loss: 456.4709 - val_kl_loss: 2.7257 - val_disc_loss: 1.3875 - val_beta: 0.0000e+00 - lr: 2.5000e-04\n",
      "Training with gamma = 1000.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 54s 19ms/step - loss: 1820.6149 - reco_loss: 1121.4720 - kl_loss: 0.4397 - disc_loss: 1.4370 - beta: 0.2120 - val_loss: 1932.9795 - val_reco_loss: 939.9224 - val_kl_loss: 0.6591 - val_disc_loss: 1.3935 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 1817.4704 - reco_loss: 882.6674 - kl_loss: 1.0699 - disc_loss: 1.2649 - beta: 0.3240 - val_loss: 1628.9595 - val_reco_loss: 840.9604 - val_kl_loss: 0.9564 - val_disc_loss: 1.1705 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 2046.1388 - reco_loss: 818.4013 - kl_loss: 1.4151 - disc_loss: 1.1253 - beta: 0.4360 - val_loss: 1853.7588 - val_reco_loss: 754.3233 - val_kl_loss: 0.7523 - val_disc_loss: 0.7608 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 2272.9321 - reco_loss: 673.4226 - kl_loss: 2.4425 - disc_loss: 0.6796 - beta: 0.5480 - val_loss: 4708.3618 - val_reco_loss: 1056.9310 - val_kl_loss: 2.1696 - val_disc_loss: 0.2592 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3350.2379 - reco_loss: 712.0984 - kl_loss: 4.1004 - disc_loss: 0.5535 - beta: 0.6600 - val_loss: 3269.5276 - val_reco_loss: 837.2310 - val_kl_loss: 6.9864 - val_disc_loss: 0.3267 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 3541.9734 - reco_loss: 562.3461 - kl_loss: 4.4521 - disc_loss: 0.2691 - beta: 0.7720 - val_loss: 3022.4712 - val_reco_loss: 313.7399 - val_kl_loss: 5.5167 - val_disc_loss: 0.3274 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3766.6546 - reco_loss: 682.1358 - kl_loss: 1.7289 - disc_loss: 0.4712 - beta: 0.1840 - val_loss: 3927.1738 - val_reco_loss: 1312.2802 - val_kl_loss: 1.7619 - val_disc_loss: 1.0848 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3698.8456 - reco_loss: 1077.6065 - kl_loss: 1.8000 - disc_loss: 0.5774 - beta: 0.2960 - val_loss: 5322.7939 - val_reco_loss: 1727.3110 - val_kl_loss: 2.5501 - val_disc_loss: 0.2520 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3997.8339 - reco_loss: 929.4525 - kl_loss: 2.4014 - disc_loss: 0.3490 - beta: 0.4080 - val_loss: 3507.3755 - val_reco_loss: 890.1951 - val_kl_loss: 2.2127 - val_disc_loss: 0.3393 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 4180.0158 - reco_loss: 866.6251 - kl_loss: 4.1404 - disc_loss: 0.3103 - beta: 0.5200 - val_loss: 4888.8545 - val_reco_loss: 701.2891 - val_kl_loss: 3.8851 - val_disc_loss: 0.0582 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 4739.6414 - reco_loss: 531.7937 - kl_loss: 3.1526 - disc_loss: 0.0763 - beta: 0.6320 - val_loss: 3405.6221 - val_reco_loss: 552.3989 - val_kl_loss: 2.9170 - val_disc_loss: 0.2293 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 4057.9286 - reco_loss: 629.2134 - kl_loss: 4.2333 - disc_loss: 0.2834 - beta: 0.7440\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 4057.7619 - reco_loss: 629.1530 - kl_loss: 4.2333 - disc_loss: 0.2835 - beta: 0.7440 - val_loss: 2623.2793 - val_reco_loss: 313.0377 - val_kl_loss: 4.8198 - val_disc_loss: 0.4091 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3598.6173 - reco_loss: 491.9289 - kl_loss: 3.4152 - disc_loss: 0.2850 - beta: 0.1560 - val_loss: 4460.7656 - val_reco_loss: 1586.6631 - val_kl_loss: 1.7300 - val_disc_loss: 0.3061 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.2680 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.3800 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.4920 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.6040 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1000.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 48s 18ms/step - loss: 2549.6659 - reco_loss: 1245.2157 - kl_loss: 0.5469 - disc_loss: 1.0543 - beta: 0.2120 - val_loss: 2362.5835 - val_reco_loss: 1103.1746 - val_kl_loss: 1.0498 - val_disc_loss: 0.8858 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3037.6236 - reco_loss: 1034.4963 - kl_loss: 1.3320 - disc_loss: 0.7741 - beta: 0.3240 - val_loss: 2016.0524 - val_reco_loss: 868.3234 - val_kl_loss: 1.3603 - val_disc_loss: 0.5743 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 3679.4267 - reco_loss: 912.5548 - kl_loss: 2.0768 - disc_loss: 0.3559 - beta: 0.4360 - val_loss: 5382.1455 - val_reco_loss: 1468.9315 - val_kl_loss: 2.5895 - val_disc_loss: 0.0942 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 4806.0460 - reco_loss: 924.3788 - kl_loss: 2.6005 - disc_loss: 0.2212 - beta: 0.5480 - val_loss: 4954.8823 - val_reco_loss: 1799.7711 - val_kl_loss: 4.7947 - val_disc_loss: 0.4442 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 54s 22ms/step - loss: 4988.0077 - reco_loss: 972.0957 - kl_loss: 5.0756 - disc_loss: 0.2058 - beta: 0.6600 - val_loss: 6635.8315 - val_reco_loss: 645.1451 - val_kl_loss: 4.2621 - val_disc_loss: 0.0220 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 5542.5582 - reco_loss: 534.7460 - kl_loss: 4.3910 - disc_loss: 0.1188 - beta: 0.7720 - val_loss: 3446.7795 - val_reco_loss: 570.6243 - val_kl_loss: 7.5454 - val_disc_loss: 0.1113 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 52s 21ms/step - loss: 5649.3436 - reco_loss: 1271.1086 - kl_loss: 2.5530 - disc_loss: 0.1557 - beta: 0.1840 - val_loss: 4764.5029 - val_reco_loss: 1699.8153 - val_kl_loss: 1.0200 - val_disc_loss: 0.0613 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 51s 20ms/step - loss: 6684.1161 - reco_loss: 1730.0044 - kl_loss: 2.4985 - disc_loss: 0.0610 - beta: 0.2960 - val_loss: 7355.5239 - val_reco_loss: 2160.7041 - val_kl_loss: 1.8391 - val_disc_loss: 0.0080 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 7217.7473 - reco_loss: 1652.9233 - kl_loss: 2.6427 - disc_loss: 0.0340 - beta: 0.4080 - val_loss: 8740.1680 - val_reco_loss: 2503.6882 - val_kl_loss: 5.1583 - val_disc_loss: 0.0719 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 51s 20ms/step - loss: 25904798.8050 - reco_loss: 25883548.8134 - kl_loss: 9801.0098 - disc_loss: 0.0450 - beta: 0.5200 - val_loss: 9301.5293 - val_reco_loss: 3787.6504 - val_kl_loss: 4.9490 - val_disc_loss: 0.0288 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 8782.9776 - reco_loss: 3037.4350 - kl_loss: 5.2136 - disc_loss: 0.0339 - beta: 0.6320 - val_loss: 9984.3740 - val_reco_loss: 2825.9683 - val_kl_loss: 4.5682 - val_disc_loss: 0.0047 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 9030.5316 - reco_loss: 2331.7964 - kl_loss: 5.2196 - disc_loss: 0.0258 - beta: 0.7439\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 9030.9604 - reco_loss: 2332.0297 - kl_loss: 5.2191 - disc_loss: 0.0258 - beta: 0.7440 - val_loss: 9502.1426 - val_reco_loss: 1983.9448 - val_kl_loss: 4.5396 - val_disc_loss: 0.0034 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 32646.0078 - reco_loss: 25278.6929 - kl_loss: 13.6638 - disc_loss: 0.0117 - beta: 0.1560 - val_loss: 8237.2637 - val_reco_loss: 2426.9321 - val_kl_loss: 1.1899 - val_disc_loss: 0.0059 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 9649.7845 - reco_loss: 3458.1957 - kl_loss: 1.6857 - disc_loss: 0.0170 - beta: 0.2680 - val_loss: 11649.8672 - val_reco_loss: 5036.4141 - val_kl_loss: 2.6426 - val_disc_loss: 0.0189 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 8750.6211 - reco_loss: 2026.0331 - kl_loss: 2.8621 - disc_loss: 0.0193 - beta: 0.3800 - val_loss: 9022.4785 - val_reco_loss: 2891.7554 - val_kl_loss: 3.9993 - val_disc_loss: 0.0050 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 52s 21ms/step - loss: 10328.5489 - reco_loss: 2830.4214 - kl_loss: 5.6300 - disc_loss: 0.0071 - beta: 0.4920 - val_loss: 9714.6172 - val_reco_loss: 3083.7581 - val_kl_loss: 4.5976 - val_disc_loss: 0.0153 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 51s 20ms/step - loss: 8426.7358 - reco_loss: 2458.9126 - kl_loss: 4.1256 - disc_loss: 0.0157 - beta: 0.6040 - val_loss: 8511.1836 - val_reco_loss: 1890.3408 - val_kl_loss: 4.2062 - val_disc_loss: 0.0137 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1000.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 57s 21ms/step - loss: 2564.4071 - reco_loss: 1187.7596 - kl_loss: 0.4022 - disc_loss: 1.0301 - beta: 0.2120 - val_loss: 2078.8931 - val_reco_loss: 1052.2789 - val_kl_loss: 0.9865 - val_disc_loss: 1.0165 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 2384.5916 - reco_loss: 1001.3889 - kl_loss: 1.1736 - disc_loss: 1.1153 - beta: 0.3240 - val_loss: 2468.5168 - val_reco_loss: 957.0072 - val_kl_loss: 1.1466 - val_disc_loss: 0.7253 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 2777.6504 - reco_loss: 869.5361 - kl_loss: 1.8364 - disc_loss: 0.6898 - beta: 0.4360 - val_loss: 5362.8467 - val_reco_loss: 1226.0892 - val_kl_loss: 3.9763 - val_disc_loss: 0.2699 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 3607.5153 - reco_loss: 785.7849 - kl_loss: 4.3204 - disc_loss: 0.5026 - beta: 0.5480 - val_loss: 2652.5930 - val_reco_loss: 628.0891 - val_kl_loss: 3.4978 - val_disc_loss: 0.3701 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 45s 18ms/step - loss: 3385.9061 - reco_loss: 686.8011 - kl_loss: 4.7762 - disc_loss: 0.3788 - beta: 0.6600 - val_loss: 3754.8579 - val_reco_loss: 573.6895 - val_kl_loss: 5.2870 - val_disc_loss: 0.1851 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3858.8891 - reco_loss: 510.0347 - kl_loss: 5.3496 - disc_loss: 0.2939 - beta: 0.7720 - val_loss: 3855.0735 - val_reco_loss: 522.0692 - val_kl_loss: 6.5029 - val_disc_loss: 0.1340 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 4839.8859 - reco_loss: 1063.6337 - kl_loss: 2.2867 - disc_loss: 0.1885 - beta: 0.1840 - val_loss: 5398.0327 - val_reco_loss: 1793.7550 - val_kl_loss: 1.0818 - val_disc_loss: 0.1046 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 5985.2329 - reco_loss: 1821.8766 - kl_loss: 1.8275 - disc_loss: 0.1749 - beta: 0.2960 - val_loss: 6754.6636 - val_reco_loss: 1936.1650 - val_kl_loss: 2.3516 - val_disc_loss: 0.0479 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 22849923937863.1914 - reco_loss: 22845854174478.5039 - kl_loss: 16567724032.0000 - disc_loss: 110.4948 - beta: 0.4080 - val_loss: 3964.3708 - val_reco_loss: 1132.0161 - val_kl_loss: 4.0621 - val_disc_loss: 0.3561 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 4937.4644 - reco_loss: 1484.2367 - kl_loss: 4.5385 - disc_loss: 0.4155 - beta: 0.5200 - val_loss: 5834.4604 - val_reco_loss: 1420.1930 - val_kl_loss: 3.8600 - val_disc_loss: 0.2422 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 5763.2092 - reco_loss: 1515.4411 - kl_loss: 3.9557 - disc_loss: 0.5225 - beta: 0.6319\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 5762.5030 - reco_loss: 1515.1416 - kl_loss: 3.9560 - disc_loss: 0.5224 - beta: 0.6320 - val_loss: 3617.6167 - val_reco_loss: 744.3273 - val_kl_loss: 4.8156 - val_disc_loss: 0.3124 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 4047.5233 - reco_loss: 602.7129 - kl_loss: 5.4267 - disc_loss: 0.2736 - beta: 0.7440 - val_loss: 4171.1997 - val_reco_loss: 619.3355 - val_kl_loss: 5.2111 - val_disc_loss: 0.1742 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 4238.4546 - reco_loss: 623.5970 - kl_loss: 3.1861 - disc_loss: 0.1800 - beta: 0.1560 - val_loss: 4709.5898 - val_reco_loss: 1460.7362 - val_kl_loss: 1.1918 - val_disc_loss: 0.1392 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 5224.4969 - reco_loss: 1409.3553 - kl_loss: 1.7771 - disc_loss: 0.1297 - beta: 0.2680 - val_loss: 5375.3237 - val_reco_loss: 1487.5199 - val_kl_loss: 2.6264 - val_disc_loss: 0.0966 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 5367.4058 - reco_loss: 1290.0158 - kl_loss: 2.8391 - disc_loss: 0.1248 - beta: 0.3800 - val_loss: 6747.5601 - val_reco_loss: 2637.0889 - val_kl_loss: 3.2713 - val_disc_loss: 0.1421 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 6703.8949 - reco_loss: 1870.5641 - kl_loss: 3.4156 - disc_loss: 0.0985 - beta: 0.4920 - val_loss: 4816.5762 - val_reco_loss: 1215.0002 - val_kl_loss: 3.6703 - val_disc_loss: 0.1255 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1000.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 50s 18ms/step - loss: 2157.6315 - reco_loss: 1148.9577 - kl_loss: 0.3815 - disc_loss: 1.2267 - beta: 0.2120 - val_loss: 4231.7012 - val_reco_loss: 1351.4332 - val_kl_loss: 1.1476 - val_disc_loss: 0.2339 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3338.8748 - reco_loss: 1131.8695 - kl_loss: 0.9670 - disc_loss: 0.7342 - beta: 0.3240 - val_loss: 3063.1814 - val_reco_loss: 798.6921 - val_kl_loss: 1.2213 - val_disc_loss: 0.3285 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3050.9961 - reco_loss: 932.8333 - kl_loss: 1.7650 - disc_loss: 0.7462 - beta: 0.4360 - val_loss: 2845.6987 - val_reco_loss: 1059.2424 - val_kl_loss: 2.6530 - val_disc_loss: 0.3145 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 2618.3112 - reco_loss: 716.9594 - kl_loss: 2.9748 - disc_loss: 0.5143 - beta: 0.5480 - val_loss: 2976.6887 - val_reco_loss: 529.4521 - val_kl_loss: 3.6292 - val_disc_loss: 0.1642 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 2856.2376 - reco_loss: 561.7655 - kl_loss: 3.7605 - disc_loss: 0.4292 - beta: 0.6600 - val_loss: 3516.7332 - val_reco_loss: 399.1372 - val_kl_loss: 3.8819 - val_disc_loss: 0.1107 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3505.4416 - reco_loss: 314.6497 - kl_loss: 4.3896 - disc_loss: 0.1705 - beta: 0.7720 - val_loss: 4852.7656 - val_reco_loss: 372.6466 - val_kl_loss: 5.6633 - val_disc_loss: 0.3676 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3998.3429 - reco_loss: 631.2148 - kl_loss: 2.1915 - disc_loss: 0.2244 - beta: 0.1840 - val_loss: 4591.8818 - val_reco_loss: 1196.0098 - val_kl_loss: 1.2786 - val_disc_loss: 0.1126 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 4392.1437 - reco_loss: 818.8020 - kl_loss: 1.3092 - disc_loss: 0.1019 - beta: 0.2960 - val_loss: 5249.6895 - val_reco_loss: 1013.1055 - val_kl_loss: 1.5692 - val_disc_loss: 0.0536 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 5023.6108 - reco_loss: 852.8488 - kl_loss: 3.0913 - disc_loss: 0.0796 - beta: 0.4080 - val_loss: 5272.9736 - val_reco_loss: 1008.0852 - val_kl_loss: 1.9959 - val_disc_loss: 0.0710 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 5228.2176 - reco_loss: 966.8403 - kl_loss: 3.5108 - disc_loss: 0.1247 - beta: 0.5200 - val_loss: 5583.4546 - val_reco_loss: 1393.4591 - val_kl_loss: 5.9477 - val_disc_loss: 0.0471 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 5577.4105 - reco_loss: 1031.7989 - kl_loss: 9.5917 - disc_loss: 0.0601 - beta: 0.6320 - val_loss: 5853.6758 - val_reco_loss: 979.0513 - val_kl_loss: 4.3799 - val_disc_loss: 0.0463 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 7000774119998168064.0000 - reco_loss: 6831598852527187968.0000 - kl_loss: 96302418135875584.0000 - disc_loss: 0.3221 - beta: 0.7440 - val_loss: 5549.0093 - val_reco_loss: 545.3353 - val_kl_loss: 6.2665 - val_disc_loss: 0.0561 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 5214.3017 - reco_loss: 499.0358 - kl_loss: 3.0971 - disc_loss: 0.1266 - beta: 0.1560\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 5214.1994 - reco_loss: 499.1220 - kl_loss: 3.0971 - disc_loss: 0.1267 - beta: 0.1560 - val_loss: 4926.1016 - val_reco_loss: 1315.2968 - val_kl_loss: 0.8820 - val_disc_loss: 0.2069 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 4640.9245 - reco_loss: 891.5032 - kl_loss: 1.2714 - disc_loss: 0.1154 - beta: 0.2680 - val_loss: 4736.4473 - val_reco_loss: 877.7069 - val_kl_loss: 1.8433 - val_disc_loss: 0.0471 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 4649.0607 - reco_loss: 724.0648 - kl_loss: 2.0783 - disc_loss: 0.0576 - beta: 0.3800 - val_loss: 4988.3154 - val_reco_loss: 776.7048 - val_kl_loss: 2.7618 - val_disc_loss: 0.0441 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 4837.7271 - reco_loss: 693.7262 - kl_loss: 2.9110 - disc_loss: 0.3372 - beta: 0.4920 - val_loss: 2980.6829 - val_reco_loss: 829.8858 - val_kl_loss: 3.7339 - val_disc_loss: 2.4846 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 2493.4171 - reco_loss: 705.9824 - kl_loss: 4.4680 - disc_loss: 1.5974 - beta: 0.6040 - val_loss: 2690.3843 - val_reco_loss: 612.5980 - val_kl_loss: 4.3740 - val_disc_loss: 0.9872 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 2375.8466 - reco_loss: 457.2836 - kl_loss: 4.8402 - disc_loss: 0.8318 - beta: 0.7160 - val_loss: 2513.7917 - val_reco_loss: 615.9443 - val_kl_loss: 5.8079 - val_disc_loss: 0.5285 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 2266.2691 - reco_loss: 517.4679 - kl_loss: 4.3249 - disc_loss: 1.4498 - beta: 0.1280 - val_loss: 2916.7876 - val_reco_loss: 1187.5770 - val_kl_loss: 0.9493 - val_disc_loss: 0.9546 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 2483.6919 - reco_loss: 850.9604 - kl_loss: 1.5086 - disc_loss: 0.8431 - beta: 0.2400 - val_loss: 2406.7915 - val_reco_loss: 897.1459 - val_kl_loss: 1.7966 - val_disc_loss: 1.0701 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 2482.1118 - reco_loss: 749.6249 - kl_loss: 2.1498 - disc_loss: 0.6566 - beta: 0.3520 - val_loss: 3025.8708 - val_reco_loss: 794.8392 - val_kl_loss: 2.6296 - val_disc_loss: 0.3843 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 2575.7504 - reco_loss: 639.1781 - kl_loss: 3.1161 - disc_loss: 0.6441 - beta: 0.4640 - val_loss: 2689.4504 - val_reco_loss: 571.3815 - val_kl_loss: 3.5617 - val_disc_loss: 0.4017 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 2807.6973 - reco_loss: 457.2958 - kl_loss: 3.6344 - disc_loss: 0.2998 - beta: 0.5760 - val_loss: 3304.7532 - val_reco_loss: 406.3399 - val_kl_loss: 3.9027 - val_disc_loss: 0.1377 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3160.6890 - reco_loss: 357.3494 - kl_loss: 4.2946 - disc_loss: 0.2516 - beta: 0.6880 - val_loss: 3083.0198 - val_reco_loss: 329.3177 - val_kl_loss: 4.5971 - val_disc_loss: 0.2670 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3121.9708 - reco_loss: 270.5612 - kl_loss: 4.5867 - disc_loss: 0.2331 - beta: 0.8000 - val_loss: 3549.1777 - val_reco_loss: 197.0124 - val_kl_loss: 3.8746 - val_disc_loss: 0.1015 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 3943.6917 - reco_loss: 813.8313 - kl_loss: 0.9478 - disc_loss: 0.3896 - beta: 0.2120 - val_loss: 4094.1377 - val_reco_loss: 1032.0718 - val_kl_loss: 1.4165 - val_disc_loss: 0.3572 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 3978.3646 - reco_loss: 749.0922 - kl_loss: 1.8712 - disc_loss: 0.3582 - beta: 0.3240 - val_loss: 4259.5278 - val_reco_loss: 641.4789 - val_kl_loss: 2.1124 - val_disc_loss: 0.1216 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 3977.4884 - reco_loss: 588.3379 - kl_loss: 2.7019 - disc_loss: 0.3505 - beta: 0.4360 - val_loss: 3945.0449 - val_reco_loss: 589.5753 - val_kl_loss: 3.2953 - val_disc_loss: 0.1464 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 3804.1197 - reco_loss: 443.7476 - kl_loss: 3.2924 - disc_loss: 0.1559 - beta: 0.5480 - val_loss: 2960.1372 - val_reco_loss: 472.5840 - val_kl_loss: 3.6175 - val_disc_loss: 0.4331 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 3316.7030 - reco_loss: 432.7933 - kl_loss: 3.7399 - disc_loss: 0.4124 - beta: 0.6600\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 3316.7199 - reco_loss: 432.7742 - kl_loss: 3.7399 - disc_loss: 0.4124 - beta: 0.6600 - val_loss: 3434.5623 - val_reco_loss: 339.6896 - val_kl_loss: 3.8560 - val_disc_loss: 0.1409 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 3419.7035 - reco_loss: 265.3592 - kl_loss: 3.6662 - disc_loss: 0.1463 - beta: 0.7720 - val_loss: 3414.6455 - val_reco_loss: 230.5152 - val_kl_loss: 4.1225 - val_disc_loss: 0.1743 - val_beta: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 3913.5027 - reco_loss: 422.7275 - kl_loss: 1.5047 - disc_loss: 0.1197 - beta: 0.1840 - val_loss: 4467.9336 - val_reco_loss: 732.7025 - val_kl_loss: 0.9561 - val_disc_loss: 0.0571 - val_beta: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 4086.7864 - reco_loss: 643.6122 - kl_loss: 1.5259 - disc_loss: 0.2018 - beta: 0.2960 - val_loss: 4144.2100 - val_reco_loss: 986.7803 - val_kl_loss: 2.3952 - val_disc_loss: 0.2512 - val_beta: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 4411.0556 - reco_loss: 712.4570 - kl_loss: 2.7568 - disc_loss: 0.1647 - beta: 0.4080 - val_loss: 4257.5400 - val_reco_loss: 606.1394 - val_kl_loss: 3.3191 - val_disc_loss: 0.1122 - val_beta: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 44s 17ms/step - loss: 3961.0992 - reco_loss: 595.9307 - kl_loss: 3.5620 - disc_loss: 0.2199 - beta: 0.5200 - val_loss: 3445.1528 - val_reco_loss: 544.7053 - val_kl_loss: 3.9108 - val_disc_loss: 0.3768 - val_beta: 0.0000e+00 - lr: 2.5000e-04\n",
      "Training with gamma = 1000.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 55s 20ms/step - loss: 2480.8377 - reco_loss: 1300.8345 - kl_loss: 0.4423 - disc_loss: 1.1149 - beta: 0.2120 - val_loss: 2447.8984 - val_reco_loss: 1068.1670 - val_kl_loss: 0.4353 - val_disc_loss: 0.6743 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 2975.5289 - reco_loss: 1039.7880 - kl_loss: 0.9715 - disc_loss: 0.6566 - beta: 0.3240 - val_loss: 2934.6636 - val_reco_loss: 959.7853 - val_kl_loss: 1.5551 - val_disc_loss: 0.2260 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 3328.1298 - reco_loss: 908.0396 - kl_loss: 2.1859 - disc_loss: 0.4909 - beta: 0.4360 - val_loss: 2826.2834 - val_reco_loss: 754.8508 - val_kl_loss: 2.2424 - val_disc_loss: 0.6163 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 3510.3345 - reco_loss: 773.4557 - kl_loss: 2.6886 - disc_loss: 0.4438 - beta: 0.5480 - val_loss: 820.7679 - val_reco_loss: 596.2252 - val_kl_loss: 2.1063 - val_disc_loss: 2.4243 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 44s 18ms/step - loss: 3447.1106 - reco_loss: 610.0296 - kl_loss: 3.4565 - disc_loss: 0.4947 - beta: 0.6600 - val_loss: 3214.9253 - val_reco_loss: 645.2166 - val_kl_loss: 2.9720 - val_disc_loss: 0.2669 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 4792.8480 - reco_loss: 673.6055 - kl_loss: 4.9921 - disc_loss: 0.3638 - beta: 0.7720 - val_loss: 5296.6382 - val_reco_loss: 942.7674 - val_kl_loss: 6.2489 - val_disc_loss: 0.1840 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 5173.5964 - reco_loss: 917.9859 - kl_loss: 1.9444 - disc_loss: 0.1094 - beta: 0.1840 - val_loss: 4478.4360 - val_reco_loss: 1143.3060 - val_kl_loss: 1.1239 - val_disc_loss: 0.1332 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 4791.1936 - reco_loss: 907.7722 - kl_loss: 1.8023 - disc_loss: 0.1330 - beta: 0.2960 - val_loss: 4324.5986 - val_reco_loss: 898.4391 - val_kl_loss: 1.7434 - val_disc_loss: 0.0650 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 7655.4731 - reco_loss: 1960.1375 - kl_loss: 2.6926 - disc_loss: 0.4113 - beta: 0.4080 - val_loss: 5633.0386 - val_reco_loss: 1709.1193 - val_kl_loss: 3.4850 - val_disc_loss: 0.1655 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 5108.5173 - reco_loss: 947.9001 - kl_loss: 4.2523 - disc_loss: 0.2508 - beta: 0.5200 - val_loss: 3717.1643 - val_reco_loss: 648.9509 - val_kl_loss: 3.5431 - val_disc_loss: 0.0714 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 59s 24ms/step - loss: 4903.6830 - reco_loss: 939.6770 - kl_loss: 4.2876 - disc_loss: 0.2018 - beta: 0.6320 - val_loss: 5408.6641 - val_reco_loss: 740.6617 - val_kl_loss: 3.1106 - val_disc_loss: 0.0245 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 6394.8668 - reco_loss: 959.7807 - kl_loss: 5.9809 - disc_loss: 0.0716 - beta: 0.7440 - val_loss: 5343.2246 - val_reco_loss: 686.9641 - val_kl_loss: 6.3927 - val_disc_loss: 0.0498 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 967824969538168160256.0000 - reco_loss: 963759463711841189888.0000 - kl_loss: 2081484225592164352.0000 - disc_loss: 131892.9307 - beta: 0.1560 - val_loss: 5931.8911 - val_reco_loss: 1619.5674 - val_kl_loss: 0.8489 - val_disc_loss: 0.0533 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 5987.6929 - reco_loss: 1408.8170 - kl_loss: 1.2669 - disc_loss: 0.0824 - beta: 0.2679\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 5987.7746 - reco_loss: 1408.8275 - kl_loss: 1.2671 - disc_loss: 0.0825 - beta: 0.2680 - val_loss: 3739.6445 - val_reco_loss: 951.7307 - val_kl_loss: 1.8239 - val_disc_loss: 0.2806 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 4487.3948 - reco_loss: 769.5781 - kl_loss: 2.4999 - disc_loss: 0.2172 - beta: 0.3800 - val_loss: 6242.2119 - val_reco_loss: 811.4643 - val_kl_loss: 2.9295 - val_disc_loss: 0.0131 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 46s 18ms/step - loss: 6106.0601 - reco_loss: 845.7426 - kl_loss: 4.5813 - disc_loss: 0.0397 - beta: 0.4920 - val_loss: 6604.2109 - val_reco_loss: 1062.3109 - val_kl_loss: 8.4557 - val_disc_loss: 0.0553 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 7023.2701 - reco_loss: 949.3559 - kl_loss: 5.4405 - disc_loss: 0.0700 - beta: 0.6040 - val_loss: 5965.5479 - val_reco_loss: 1023.7627 - val_kl_loss: 2.4042 - val_disc_loss: 0.0608 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 60141.5936 - reco_loss: 55177.1432 - kl_loss: 38.6603 - disc_loss: 0.2103 - beta: 0.7160 - val_loss: 3253.8296 - val_reco_loss: 463.0637 - val_kl_loss: 4.7220 - val_disc_loss: 0.2534 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 4384.1386 - reco_loss: 888.3616 - kl_loss: 4.6548 - disc_loss: 0.4105 - beta: 0.1280 - val_loss: 8475.7217 - val_reco_loss: 2886.9612 - val_kl_loss: 1.4476 - val_disc_loss: 0.1532 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1000.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 60s 22ms/step - loss: 2870.3523 - reco_loss: 1178.3977 - kl_loss: 0.4355 - disc_loss: 0.8457 - beta: 0.2120 - val_loss: 3322.8340 - val_reco_loss: 1011.6880 - val_kl_loss: 0.7788 - val_disc_loss: 0.2636 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 3795.9493 - reco_loss: 996.5054 - kl_loss: 1.1966 - disc_loss: 0.3248 - beta: 0.3240 - val_loss: 3353.6660 - val_reco_loss: 1021.6156 - val_kl_loss: 1.1794 - val_disc_loss: 0.3212 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 3699.3369 - reco_loss: 865.7099 - kl_loss: 2.2060 - disc_loss: 0.2032 - beta: 0.4360 - val_loss: 5122.7734 - val_reco_loss: 1133.1829 - val_kl_loss: 3.5737 - val_disc_loss: 0.1284 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 49s 20ms/step - loss: 5435.9456 - reco_loss: 981.1813 - kl_loss: 3.5786 - disc_loss: 0.2104 - beta: 0.5480 - val_loss: 4107.6143 - val_reco_loss: 598.9974 - val_kl_loss: 3.3520 - val_disc_loss: 0.1106 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 4982.5733 - reco_loss: 869.1105 - kl_loss: 3.1058 - disc_loss: 0.2467 - beta: 0.6600 - val_loss: 4372.5742 - val_reco_loss: 451.9170 - val_kl_loss: 3.4142 - val_disc_loss: 0.0430 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 53s 21ms/step - loss: 5334.8428 - reco_loss: 578.1114 - kl_loss: 9.1495 - disc_loss: 0.1474 - beta: 0.7720 - val_loss: 4538.0835 - val_reco_loss: 391.9164 - val_kl_loss: 12.5461 - val_disc_loss: 0.1529 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 52s 21ms/step - loss: 5815.2076 - reco_loss: 942.5151 - kl_loss: 3.3753 - disc_loss: 0.0995 - beta: 0.1840 - val_loss: 5759.1899 - val_reco_loss: 1558.7723 - val_kl_loss: 1.5327 - val_disc_loss: 0.0441 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 49s 19ms/step - loss: 5800.5876 - reco_loss: 1310.8534 - kl_loss: 1.4685 - disc_loss: 0.0451 - beta: 0.2960 - val_loss: 5610.7603 - val_reco_loss: 2212.8064 - val_kl_loss: 0.6189 - val_disc_loss: 0.0700 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 6847.9515 - reco_loss: 1826.8419 - kl_loss: 1.9202 - disc_loss: 0.0390 - beta: 0.4080 - val_loss: 8344.3730 - val_reco_loss: 1007.7313 - val_kl_loss: 2.8487 - val_disc_loss: 0.0941 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 7044.7631 - reco_loss: 1152.9414 - kl_loss: 3.1965 - disc_loss: 0.0446 - beta: 0.5200 - val_loss: 7433.1729 - val_reco_loss: 1095.0170 - val_kl_loss: 4.0006 - val_disc_loss: 0.0137 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 7538.8162 - reco_loss: 1647.9827 - kl_loss: 3.4101 - disc_loss: 0.0795 - beta: 0.6319\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 7538.3398 - reco_loss: 1647.6749 - kl_loss: 3.4118 - disc_loss: 0.0796 - beta: 0.6320 - val_loss: 6655.4082 - val_reco_loss: 1516.6428 - val_kl_loss: 5.5780 - val_disc_loss: 0.2236 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 5230.3378 - reco_loss: 918.4965 - kl_loss: 6.6637 - disc_loss: 0.2121 - beta: 0.7440 - val_loss: 4010.5059 - val_reco_loss: 775.5724 - val_kl_loss: 7.4141 - val_disc_loss: 0.2561 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 208s 83ms/step - loss: 4626.9347 - reco_loss: 809.6009 - kl_loss: 4.6033 - disc_loss: 0.2997 - beta: 0.1560 - val_loss: 4816.2466 - val_reco_loss: 1910.0952 - val_kl_loss: 1.7033 - val_disc_loss: 0.2420 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 5058.6325 - reco_loss: 1617.9197 - kl_loss: 2.2638 - disc_loss: 0.2693 - beta: 0.2680 - val_loss: 4726.5601 - val_reco_loss: 1310.9734 - val_kl_loss: 2.8239 - val_disc_loss: 0.2578 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 55s 22ms/step - loss: 4902.6450 - reco_loss: 1465.7804 - kl_loss: 3.3596 - disc_loss: 0.2981 - beta: 0.3800 - val_loss: 5011.4072 - val_reco_loss: 1590.2942 - val_kl_loss: 3.8174 - val_disc_loss: 0.1357 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 50s 20ms/step - loss: 5132.1217 - reco_loss: 1533.8255 - kl_loss: 3.7757 - disc_loss: 0.2697 - beta: 0.4920 - val_loss: 4177.2061 - val_reco_loss: 1336.7537 - val_kl_loss: 4.1022 - val_disc_loss: 0.4270 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Training with gamma = 1000.0\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 1279s 328ms/step - loss: 3068.0245 - reco_loss: 1331.0378 - kl_loss: 0.7821 - disc_loss: 0.9875 - beta: 0.2120 - val_loss: 2287.6018 - val_reco_loss: 1080.3062 - val_kl_loss: 0.7214 - val_disc_loss: 0.7261 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 2981.0089 - reco_loss: 1076.9970 - kl_loss: 1.1913 - disc_loss: 0.8750 - beta: 0.3240 - val_loss: 2608.8228 - val_reco_loss: 948.2872 - val_kl_loss: 0.5694 - val_disc_loss: 1.3759 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 3038.5580 - reco_loss: 934.1549 - kl_loss: 1.4833 - disc_loss: 1.0692 - beta: 0.4360 - val_loss: 2874.5032 - val_reco_loss: 699.1974 - val_kl_loss: 2.1382 - val_disc_loss: 0.3668 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 3098.0553 - reco_loss: 816.7829 - kl_loss: 2.3495 - disc_loss: 0.7475 - beta: 0.5480 - val_loss: 1722.8438 - val_reco_loss: 592.4430 - val_kl_loss: 1.9814 - val_disc_loss: 0.7037 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3190.8528 - reco_loss: 608.5060 - kl_loss: 3.6758 - disc_loss: 0.5002 - beta: 0.6600 - val_loss: 3621.1504 - val_reco_loss: 571.2135 - val_kl_loss: 4.6421 - val_disc_loss: 0.1491 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 3855.4018 - reco_loss: 510.1750 - kl_loss: 4.5805 - disc_loss: 0.2644 - beta: 0.7720 - val_loss: 4545.4116 - val_reco_loss: 881.5798 - val_kl_loss: 2.6396 - val_disc_loss: 0.1935 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: 5046.5648 - reco_loss: 825.8624 - kl_loss: 1.9219 - disc_loss: 0.1731 - beta: 0.1840 - val_loss: 5532.8418 - val_reco_loss: 1046.7454 - val_kl_loss: 1.5454 - val_disc_loss: 0.0439 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 6456.6243 - reco_loss: 1448.7532 - kl_loss: 2.6153 - disc_loss: 0.0717 - beta: 0.2960 - val_loss: 4985.8037 - val_reco_loss: 1098.1333 - val_kl_loss: 3.6010 - val_disc_loss: 0.0566 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 8003.3008 - reco_loss: 2062.7321 - kl_loss: 3.9159 - disc_loss: 0.1124 - beta: 0.4080 - val_loss: 5680.2881 - val_reco_loss: 1450.7747 - val_kl_loss: 2.9492 - val_disc_loss: 0.0321 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 7895.5872 - reco_loss: 1563.8543 - kl_loss: 3.0616 - disc_loss: 0.0488 - beta: 0.5200 - val_loss: 5953.9609 - val_reco_loss: 1345.0022 - val_kl_loss: 3.5193 - val_disc_loss: 0.1304 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 5055.9406 - reco_loss: 744.2250 - kl_loss: 4.3000 - disc_loss: 0.4229 - beta: 0.6320 - val_loss: 6281.7363 - val_reco_loss: 2420.8059 - val_kl_loss: 5.4364 - val_disc_loss: 0.3482 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 2754113783641216647168.0000 - reco_loss: 2736159871358132551680.0000 - kl_loss: 13672771238534053888.0000 - disc_loss: 40458353.6366 - beta: 0.7440 - val_loss: 3156.5151 - val_reco_loss: 385.3447 - val_kl_loss: 4.7826 - val_disc_loss: 0.4640 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 4430.4578 - reco_loss: 615.5016 - kl_loss: 4.0569 - disc_loss: 0.3751 - beta: 0.1560 - val_loss: 4554.1597 - val_reco_loss: 1171.7002 - val_kl_loss: 1.2425 - val_disc_loss: 0.1897 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 4357.1399 - reco_loss: 1000.5381 - kl_loss: 1.7768 - disc_loss: 0.2294 - beta: 0.2678\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 4358.0859 - reco_loss: 1000.8305 - kl_loss: 1.7773 - disc_loss: 0.2294 - beta: 0.2680 - val_loss: 5158.6240 - val_reco_loss: 1326.5511 - val_kl_loss: 2.1675 - val_disc_loss: 0.1598 - val_beta: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 42s 17ms/step - loss: 634633.4599 - reco_loss: 628064.2958 - kl_loss: 2603.1838 - disc_loss: 0.1899 - beta: 0.3800 - val_loss: 4403.1504 - val_reco_loss: 1103.2561 - val_kl_loss: 2.7104 - val_disc_loss: 0.2099 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 41s 16ms/step - loss: 4323.6405 - reco_loss: 893.1716 - kl_loss: 3.0965 - disc_loss: 0.1844 - beta: 0.4920 - val_loss: 4424.2749 - val_reco_loss: 778.0257 - val_kl_loss: 3.6993 - val_disc_loss: 0.2214 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 41s 17ms/step - loss: 4615.9539 - reco_loss: 867.6749 - kl_loss: 4.2309 - disc_loss: 0.2254 - beta: 0.6040 - val_loss: 4007.3950 - val_reco_loss: 784.9502 - val_kl_loss: 5.1448 - val_disc_loss: 0.1868 - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.7160 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 43s 17ms/step - loss: nan - reco_loss: nan - kl_loss: nan - disc_loss: nan - beta: 0.1280 - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - val_disc_loss: nan - val_beta: 0.0000e+00 - lr: 5.0000e-04\n",
      "[[ 174.04347229  167.25761414  189.17958069  174.49554443  178.68135071\n",
      "   173.51437378  172.12483215  172.62138367]\n",
      " [ 183.94143677           nan           nan           nan  157.3302002\n",
      "   171.34295654  182.50662231  169.64137268]\n",
      " [ 180.57687378  167.70283508  182.27520752  182.50753784           nan\n",
      "   175.96522522           nan  205.95376587]\n",
      " [          nan  197.30148315  209.57402039  192.39611816  187.25750732\n",
      "            nan           nan  199.63067627]\n",
      " [ 292.29934692           nan  334.09387207           nan  487.42370605\n",
      "            nan  271.8053894            nan]\n",
      " [ 841.07684326           nan 2016.05236816 2078.89306641 2406.79150391\n",
      "   820.76794434 3322.83398438           nan]]\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning Loop for gamma\n",
    "\n",
    "for g, gamma in enumerate(gamma_values):\n",
    "    for i in range(iters) : \n",
    "        print(f\"Training with gamma = {gamma}\")\n",
    "\n",
    "        T2A_enc = Qmake_encoder_set_weights(X_train.shape[1],32,16,3)\n",
    "        T2A_dec = Qmake_decoder_set_weights(X_train.shape[1],32,16,3)\n",
    "        T2A_discriminator = Qmake_discriminator(input_dim, h_dim_1, h_dim_2)\n",
    "\n",
    "        steps_per_epoch = X_train.shape[0] // BATCH_SIZE\n",
    "        T2A = VAE_GAN_Model(T2A_enc, T2A_dec, T2A_discriminator, steps_per_epoch=steps_per_epoch, cycle_length=10, min_beta=0.1, max_beta=0.8, gamma=gamma)\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.001, clipnorm=1000)  # gradient global_norm ~2000 \n",
    "        T2A.compile(optimizer=opt,weighted_metrics=[weighted_mse]) \n",
    "\n",
    "        early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=LR_PATIENCE, verbose=1)\n",
    "\n",
    "        callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        history = T2A.fit(x=X_train, validation_split=0.2, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks, shuffle=True)\n",
    "\n",
    "        best_epoch = np.argmin(history.history['val_loss'])  # Best epoch index based on validation loss\n",
    "        val_loss = history.history['val_loss'][best_epoch]\n",
    "\n",
    "        best_epoch = np.argmin(history.history['val_reco_loss'])  \n",
    "        val_reco_loss = history.history['val_reco_loss'][best_epoch]\n",
    "\n",
    "\n",
    "        # best_gamma = gamma if val_loss < best_loss else best_gamma\n",
    "        # best_loss = val_loss if val_loss < best_loss else best_loss\n",
    "        loss_arr[g][i] = val_loss\n",
    "        reco_loss_arr[g][i] = val_reco_loss\n",
    "        history_array[g][i] = history\n",
    "        models_array[g][i] = T2A\n",
    "\n",
    "        # T2A.save_weights(filepath=home_path+'software_dev/trained_models/small_2A_fixed_{}/'.format(i), save_format='tf')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ind = np.unravel_index(np.argmin(loss_arr, axis=None), loss_arr.shape)\n",
    "\n",
    "# print(f\"Best gamma: {best_gamma}\") \n",
    "# print(f\"Best validation loss: {best_loss}\")\n",
    "print(loss_arr)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "136cfd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(models_array):\n",
    "  for j, mod in enumerate(row):\n",
    "    # print(home_path+f'software_dev/trained_models/gamma_tuning/gamma{gamma_values[i]:.0e}_{j}/')\n",
    "    mod.save_weights(filepath=home_path+f'software_dev/trained_models/gamma_tuning/gamma{gamma_values[i]:.0e}/iter_{j}/', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e81fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iterate 20 times\n",
    "# for i in range(0,20):\n",
    "#     T2A_enc = Qmake_encoder_set_weights(X_train.shape[1],32,16,3)\n",
    "#     T2A_dec = Qmake_decoder_set_weights(X_train.shape[1],32,16,3)\n",
    "#     steps_per_epoch = X_train.shape[0] // BATCH_SIZE\n",
    "#     T2A = VAE_Model(T2A_enc, T2A_dec, steps_per_epoch=steps_per_epoch, cycle_length=10, min_beta=0.1, max_beta=0.7)\n",
    "#     # T2A.set_beta(beta)\n",
    "#     opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "#     T2A.compile(optimizer=opt,weighted_metrics=[weighted_mse]) #,weighted_metrics=[weighted_mse]\n",
    "\n",
    "#     early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "#     reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=LR_PATIENCE, verbose=1)\n",
    "\n",
    "#     callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "#     tf.keras.backend.clear_session()\n",
    "#     history = T2A.fit(x=X_train, validation_split=0.2, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks, shuffle=True)\n",
    "#     T2A.save_weights(filepath=home_path+'software_dev/trained_models/small_2A_fixed_{}/'.format(i), save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'history' is the object returned by your model.fit() call\n",
    "\n",
    "# Extract the loss values\n",
    "total_loss = history.history['loss']\n",
    "reco_loss = history.history['reco_loss']\n",
    "kl_loss = history.history['kl_loss']\n",
    "val_total_loss = history.history['val_loss']\n",
    "val_reco_loss = history.history['val_reco_loss']\n",
    "val_kl_loss = history.history['val_kl_loss']\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot training losses\n",
    "plt.plot(total_loss, label='Total Loss', color='blue')\n",
    "plt.plot(reco_loss, label='Reconstruction Loss', color='green')\n",
    "plt.plot(kl_loss, label='KL Loss', color='red')\n",
    "\n",
    "# Plot validation losses\n",
    "plt.plot(val_total_loss, label='Val Total Loss', color='blue', linestyle='--')\n",
    "plt.plot(val_reco_loss, label='Val Reconstruction Loss', color='green', linestyle='--')\n",
    "plt.plot(val_kl_loss, label='Val KL Loss', color='red', linestyle='--')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "405e3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AD_score_KL(z_mean, z_log_var):\n",
    "    kl_loss = np.mean(-0.5 * (1 + z_log_var - (z_mean) ** 2 - np.exp(z_log_var)))\n",
    "    return kl_loss\n",
    "\n",
    "def AD_score_CKL(z_mean, z_log_var):\n",
    "    CKL = np.mean(z_mean**2)\n",
    "    return CKL\n",
    "\n",
    "def AD_score_MSE(s, p):\n",
    "    mask = s != 0\n",
    "    s1 = s * mask\n",
    "    p1 = p * mask\n",
    "    re_loss = np.mean((s1 - p1) ** 2)\n",
    "    return re_loss\n",
    "\n",
    "class Model_Evaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path,\n",
    "        background,\n",
    "        br_weights,\n",
    "        signal,\n",
    "        signal_weights,\n",
    "        input_dim,\n",
    "        title=\"placeholder\",\n",
    "        save=False,\n",
    "        labels=None,\n",
    "    ):\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        vae_enc = Qmake_encoder_set_weights(input_dim, 32,16,3)\n",
    "        vae_dec = Qmake_decoder_set_weights(input_dim, 32,16,3)\n",
    "        vae_disc = Qmake_discriminator(input_dim, h_dim_1, h_dim_2)\n",
    "        self.model = VAE_GAN_Model(vae_enc, vae_dec, vae_disc)\n",
    "        self.model.load_weights(model_path).expect_partial()\n",
    "        self.encoder = self.model.get_layer(\"encoder\")\n",
    "        self.signal = signal\n",
    "        self.background = background\n",
    "        self.br_loss = []\n",
    "        self.signal_loss = []\n",
    "        self.background_outputs = []\n",
    "        self.signal_outputs = []\n",
    "        self.title = title\n",
    "        self.saveplots = save\n",
    "        self.labels = labels\n",
    "        self.latent_info = []\n",
    "        self.br_weights = br_weights\n",
    "        self.signal_weights = signal_weights\n",
    "\n",
    "    def calculate_loss(self, l_type):\n",
    "        self.signal_loss = []\n",
    "        self.br_loss = []\n",
    "        br = self.background\n",
    "\n",
    "        if l_type == \"CKL\":\n",
    "            br_latent = np.array(self.encoder.predict(br))\n",
    "            self.latent_info += [br_latent[0]]\n",
    "            l = []\n",
    "            for i in range(0, br.shape[0]):\n",
    "                loss = AD_score_CKL(br_latent[0][i], br_latent[1][i])\n",
    "                l += [loss]\n",
    "            self.br_loss = l\n",
    "\n",
    "            for i, batch in enumerate(self.signal):\n",
    "                sg_latent = np.array(self.encoder.predict(batch))\n",
    "                self.latent_info += [sg_latent[0]]\n",
    "                l = []\n",
    "\n",
    "                for i in range(0, batch.shape[0]):\n",
    "                    loss = AD_score_CKL(sg_latent[0][i], sg_latent[1][i])\n",
    "                    l += [loss]\n",
    "\n",
    "                sg_loss = l\n",
    "\n",
    "                self.signal_loss += [sg_loss]\n",
    "\n",
    "        if l_type == \"KL\":\n",
    "            br_latent = np.array(self.encoder.predict(br))\n",
    "            l = []\n",
    "            for i in range(0, br.shape[0]):\n",
    "                loss = AD_score_KL(br_latent[0][i], br_latent[1][i])\n",
    "                l += [loss]\n",
    "            self.br_loss = l\n",
    "\n",
    "            for i, batch in enumerate(self.signal):\n",
    "                sg_latent = np.array(self.encoder.predict(batch))\n",
    "\n",
    "                l = []\n",
    "\n",
    "                for i in range(0, batch.shape[0]):\n",
    "                    loss = AD_score_KL(sg_latent[0][i], sg_latent[1][i])\n",
    "                    l += [loss]\n",
    "\n",
    "                sg_loss = l\n",
    "\n",
    "                self.signal_loss += [sg_loss]      \n",
    "\n",
    "        if l_type == \"MSE\":\n",
    "            br_predict = np.array(self.model.predict(br)[\"reconstruction\"])\n",
    "            l = []\n",
    "            for i in range(0, br.shape[0]):\n",
    "                loss = AD_score_MSE(br[i], br_predict[i])\n",
    "                l += [loss]\n",
    "            self.br_loss = l\n",
    "\n",
    "            for i, batch in enumerate(self.signal):\n",
    "                sg_predict = np.array(self.model.predict(batch)[\"reconstruction\"])\n",
    "                l = []\n",
    "\n",
    "                for i in range(0, batch.shape[0]):\n",
    "                    loss = AD_score_MSE(batch[i], sg_predict[i])\n",
    "                    l += [loss]\n",
    "\n",
    "                sg_loss = l\n",
    "                self.signal_loss += [sg_loss]\n",
    "\n",
    "        return [self.br_loss, self.signal_loss]  \n",
    "\n",
    "    def GetPerformance(self, show_plot=True):\n",
    "        target_fpr = 1e-5\n",
    "        tpr_at_target = []\n",
    "\n",
    "        print(f\"Number of signal losses: {len(self.signal_loss)}\")\n",
    "        print(f\"Number of labels: {len(self.labels)}\")\n",
    "        print(f\"Number of signal weights: {len(self.signal_weights)}\")\n",
    "        print(f\"Length of br_loss: {len(self.br_loss)}\")\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(np.linspace(0, 1, 1000), np.linspace(0, 1, 1000), \"--\", label=\"diagonal\")\n",
    "\n",
    "        for j, batch in enumerate(self.signal_loss):\n",
    "            print(f\"Processing batch {j}\")\n",
    "            print(f\"Batch length: {len(batch)}\")\n",
    "            print(f\"Signal weight length: {len(self.signal_weights[j])}\")\n",
    "\n",
    "            sig_w = self.signal_weights[j]\n",
    "            br_w = self.br_weights\n",
    "            weights = np.concatenate((br_w, sig_w))\n",
    "            truth = np.concatenate([np.zeros(len(self.br_loss)), np.ones(len(batch))])\n",
    "            ROC_data = np.concatenate((self.br_loss, batch))\n",
    "\n",
    "            print(f\"ROC_data shape: {ROC_data.shape}\")\n",
    "            print(f\"truth shape: {truth.shape}\")\n",
    "            print(f\"weights shape: {weights.shape}\")\n",
    "\n",
    "            try:\n",
    "                fpr, tpr, _ = sk.roc_curve(truth, ROC_data, sample_weight=weights)\n",
    "                auc = sk.roc_auc_score(truth, ROC_data)\n",
    "\n",
    "                plt.plot(fpr, tpr, label=f\"{self.labels[j]}: {auc:.3f}\")\n",
    "\n",
    "                idx = np.argmin(np.abs(fpr - target_fpr))\n",
    "                tpr_at_target.append(tpr[idx])\n",
    "\n",
    "                print(f\"Successfully processed batch {j}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch {j}: {str(e)}\")\n",
    "\n",
    "        if show_plot:\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.xscale('log')\n",
    "            plt.yscale('log')\n",
    "            plt.title(f\"{self.title} ROC\")\n",
    "            plt.vlines(target_fpr, 0, 1, colors=\"r\", linestyles=\"dashed\")\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            if self.saveplots:\n",
    "                plt.savefig(\n",
    "                    home_path+f\"software_dev/plots/small/{self.title}_ROC.png\",\n",
    "                    format=\"png\",\n",
    "                    bbox_inches=\"tight\",\n",
    "                )\n",
    "            plt.show()\n",
    "\n",
    "        print(f\"\\nTPR at FPR = {target_fpr} for each channel:\")\n",
    "        results = list(zip(self.labels, tpr_at_target))\n",
    "        for label, tpr in results:\n",
    "            print(f\"{label}: {tpr*100:.6f}%\")\n",
    "\n",
    "        print(f\"Number of results: {len(results)}\")\n",
    "        return results\n",
    "    \n",
    "\n",
    "    def histogram(self, bins, bg_only=False):\n",
    "        plt.hist(\n",
    "            self.br_loss,\n",
    "            weights=self.br_weights,\n",
    "            bins=bins,\n",
    "            histtype=\"step\",\n",
    "            label=\"backround num_events:{}\".format(len(self.br_loss)),\n",
    "        )\n",
    "        if not bg_only:\n",
    "            for i, batch in enumerate(self.signal_loss):\n",
    "                plt.hist(\n",
    "                    batch,\n",
    "                    weights=self.signal_weights[i],\n",
    "                    bins=bins,\n",
    "                    histtype=\"step\",\n",
    "                    label=str(self.labels[i]) + \" num_events:{}\".format(len(batch)),\n",
    "                )\n",
    "        plt.xlabel(\"loss\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.title(\"{}_Hist\".format(self.title))\n",
    "        plt.legend()\n",
    "        if self.saveplots == True:\n",
    "            plt.savefig(\n",
    "                home_path+\"/analyses_plots/VAE_Varying_Plots/{}_Hist.png\".format(\n",
    "                    self.title\n",
    "                ),\n",
    "                format=\"png\",\n",
    "                bbox_inches=\"tight\",\n",
    "            )\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def ROC(self, labels_to_plot=None):\n",
    "        target_fpr = 1e-5\n",
    "        tpr_at_target = []\n",
    "        thresholds_at_target = []\n",
    "\n",
    "        plt.plot(\n",
    "            np.linspace(0, 1, 1000), np.linspace(0, 1, 1000), \"--\", label=\"diagonal\"\n",
    "        )\n",
    "        for j, batch in enumerate(self.signal_loss):\n",
    "            if labels_to_plot is None or self.labels[j] in labels_to_plot :\n",
    "                sig_w = self.signal_weights[j]\n",
    "                br_w = self.br_weights\n",
    "                weights = np.concatenate((br_w, sig_w))\n",
    "                truth = []\n",
    "                for i in range(len(self.br_loss)):\n",
    "                    truth += [0]\n",
    "                for i in range(len(batch)):\n",
    "                    truth += [1]\n",
    "                ROC_data = np.concatenate((self.br_loss, batch))\n",
    "                fpr, tpr, thresholds = sk.roc_curve(truth, ROC_data, sample_weight=weights)\n",
    "                # auc=np.trapz(tpr,fpr)\n",
    "                auc = sk.roc_auc_score(truth, ROC_data)\n",
    "                plt.plot(fpr, tpr, label=self.labels[j] + \": \" + str(round(auc, 3)))\n",
    "                \n",
    "                idx = np.argmin(np.abs(fpr - target_fpr))\n",
    "                tpr_at_target.append(tpr[idx])\n",
    "                thresholds_at_target.append(thresholds[idx])\n",
    "\n",
    "        plt.xlabel(\"fpr\")\n",
    "        plt.xlim(1e-7, 1)\n",
    "        plt.ylim(1e-7, 1)\n",
    "        plt.semilogx()\n",
    "        plt.ylabel(\"tpr\")\n",
    "        plt.semilogy()\n",
    "        plt.title(\"{}_ROC\".format(self.title))\n",
    "        plt.vlines(10**-5, 0, 1, colors=\"r\", linestyles=\"dashed\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        if self.saveplots == True:\n",
    "            plt.savefig(\n",
    "                home_path+f\"software_dev/plots/small/{self.title}_ROC.png\",\n",
    "                format=\"png\",\n",
    "                bbox_inches=\"tight\",\n",
    "            )\n",
    "        # plt.show()\n",
    "        \n",
    "        print(f\"\\nTPR at FPR = {target_fpr} for each channel:\")\n",
    "        for label, tpr, threshold in zip(self.labels, tpr_at_target, thresholds_at_target):\n",
    "            print(f\"{label}: {tpr*100:.6f}%, Threshold = {threshold:.6f}\")\n",
    "\n",
    "\n",
    "    def plot_anomaly_score_distribution(self):\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        bins = 10000\n",
    "        # Determine the range for the bins\n",
    "        all_scores = np.concatenate([self.br_loss] + self.signal_loss)\n",
    "        min_score, max_score = 0.01, np.max(all_scores)\n",
    "        bin_edges = np.linspace(min_score, max_score, bins + 1)\n",
    "\n",
    "        # Plot background distribution\n",
    "        br_weights = self.br_weights / np.sum(self.br_weights)  # Normalize weights\n",
    "        counts, _, _ = ax.hist(self.br_loss, bins=bin_edges, weights=br_weights, \n",
    "                               histtype='step', label='Background',\n",
    "                               color='black', density=True, linewidth=3)\n",
    "\n",
    "        # Plot signal distributions\n",
    "        colors = plt.cm.rainbow(np.linspace(0, 1, len(self.signal_loss)))\n",
    "        for i, (signal_scores, signal_weights, label) in enumerate(zip(self.signal_loss, self.signal_weights, self.labels)):\n",
    "            signal_weights = signal_weights / np.sum(signal_weights)  # Normalize weights\n",
    "            ax.hist(signal_scores, bins=bin_edges, weights=signal_weights,\n",
    "                    histtype='step', label=label, color=colors[i],\n",
    "                    density=True, linewidth=2)\n",
    "\n",
    "        ax.set_xlabel('Anomaly Score')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_title(f'{self.title} Anomaly Score Distribution')\n",
    "        ax.legend()\n",
    "        ax.grid(True, which='both', linestyle='--', alpha=0.7)\n",
    "\n",
    "        ax.set_ylim(bottom=1e-4, top=10)\n",
    "\n",
    "        # ax.set_xscale('log')\n",
    "        # ax.set_yscale('log')\n",
    "\n",
    "        if self.saveplots:\n",
    "            plt.savefig(\n",
    "                f\"/eos/home-w/wsherman/AD_Work/ML_git_repo/AD_trigger_training/analyses_plots/VAE_Varying_Plots/{self.title}_Anomaly_Score_Distribution_Histogram.png\",\n",
    "                format=\"png\",\n",
    "                bbox_inches=\"tight\",\n",
    "            )\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate and print the mean anomaly score for each distribution\n",
    "        print(\"\\nMean Anomaly Scores:\")\n",
    "        print(f\"Background: {np.average(self.br_loss, weights=self.br_weights):.6f}\")\n",
    "        for signal_scores, signal_weights, label in zip(self.signal_loss, self.signal_weights, self.labels):\n",
    "            mean_score = np.average(signal_scores, weights=signal_weights)\n",
    "            print(f\"{label}: {mean_score:.6f}\")\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf252553",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_histogram(eval: Model_Evaluator, bins, bg_only=False, range=None, log_scale=False):\n",
    "    plt.hist(\n",
    "        eval.br_loss,\n",
    "        weights=eval.br_weights,\n",
    "        bins=bins,\n",
    "        histtype=\"step\",\n",
    "        range=range,\n",
    "        label=\"backround num_events:{}\".format(len(eval.br_loss)),\n",
    "    )\n",
    "    if not bg_only:\n",
    "        for i, batch in enumerate(eval.signal_loss):\n",
    "            plt.hist(\n",
    "                batch,\n",
    "                weights=eval.signal_weights[i],\n",
    "                bins=bins,\n",
    "                histtype=\"step\",\n",
    "                range=range,\n",
    "                label=str(eval.labels[i]) + \" num_events:{}\".format(len(batch)),\n",
    "            )\n",
    "    plt.xlabel(\"loss\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"{}_Hist\".format(eval.title))\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    print(\"Mean Loss\")\n",
    "    print(f\"Background: mean:{np.average(eval.br_loss, weights=eval.br_weights):.6f} std:{np.std(eval.br_loss):.6f}\")\n",
    "    for signal_scores, signal_weights, label in zip(eval.signal_loss, eval.signal_weights, eval.labels):\n",
    "        mean_score = np.average(signal_scores, weights=signal_weights)\n",
    "        print(f\"{label}: mean: {mean_score:.6f}  std:{np.std(signal_scores):.6f}\")\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "def get_threshold_from_ROC(eval: Model_Evaluator, target_fprs = [1e-5]):\n",
    "    tpr_at_target = []\n",
    "    thresholds_at_target = []\n",
    "\n",
    "    for target_fpr in target_fprs:\n",
    "        for j, batch in enumerate(eval.signal_loss):\n",
    "            sig_w = eval.signal_weights[j]\n",
    "            br_w = eval.br_weights\n",
    "            weights = np.concatenate((br_w, sig_w))\n",
    "            truth = []\n",
    "            for i in range(len(eval.br_loss)):\n",
    "                truth += [0]\n",
    "            for i in range(len(batch)):\n",
    "                truth += [1]\n",
    "            ROC_data = np.concatenate((eval.br_loss, batch))\n",
    "            if np.isnan(ROC_data).any() or np.isinf(ROC_data).any():\n",
    "                print(\"NaN in ROC_data:\", np.isnan(ROC_data).any())\n",
    "                print(\"Inf in ROC_data:\", np.isinf(ROC_data).any())\n",
    "                return \n",
    "\n",
    "            fpr, tpr, thresholds = sk.roc_curve(truth, ROC_data, sample_weight=weights)\n",
    "            break  # took this loop from ROC but really only need to do once\n",
    "                \n",
    "        idx = np.argmin(np.abs(fpr - target_fpr))\n",
    "        tpr_at_target.append(tpr[idx])\n",
    "        thresholds_at_target.append(thresholds[idx])\n",
    "\n",
    "    # print(f\"\\nTPR at FPR = {target_fpr} for each channel:\")\n",
    "    # for label, tpr, threshold in zip(eval.labels, tpr_at_target, thresholds_at_target):\n",
    "    #     print(f\"{label}: {tpr*100:.6f}%, Threshold = {threshold:.6f}\")\n",
    "    return tpr_at_target, thresholds_at_target\n",
    "\n",
    "\n",
    "def plot_ROC(eval: Model_Evaluator, labels_to_plot=None):\n",
    "    target_fpr = 1e-5\n",
    "    tpr_at_target = []\n",
    "    thresholds_at_target = []\n",
    "\n",
    "    plt.plot(\n",
    "        np.linspace(0, 1, 1000), np.linspace(0, 1, 1000), \"--\", label=\"diagonal\"\n",
    "    )\n",
    "    for j, batch in enumerate(eval.signal_loss):\n",
    "        if labels_to_plot is None or eval.labels[j] in labels_to_plot :\n",
    "            sig_w = eval.signal_weights[j]\n",
    "            br_w = eval.br_weights\n",
    "            weights = np.concatenate((br_w, sig_w))\n",
    "            truth = []\n",
    "            for i in range(len(eval.br_loss)):\n",
    "                truth += [0]\n",
    "            for i in range(len(batch)):\n",
    "                truth += [1]\n",
    "            ROC_data = np.concatenate((eval.br_loss, batch))\n",
    "            if np.isnan(ROC_data).any() or np.isinf(ROC_data).any():\n",
    "                print(\"NaN in ROC_data:\", np.isnan(ROC_data).any())\n",
    "                print(\"Inf in ROC_data:\", np.isinf(ROC_data).any())\n",
    "                return \n",
    "\n",
    "            fpr, tpr, thresholds = sk.roc_curve(truth, ROC_data, sample_weight=weights)\n",
    "            # auc=np.trapz(tpr,fpr)\n",
    "            auc = sk.roc_auc_score(truth, ROC_data)\n",
    "            plt.plot(fpr, tpr, label=eval.labels[j] + \": \" + str(round(auc, 3)))\n",
    "            \n",
    "            idx = np.argmin(np.abs(fpr - target_fpr))\n",
    "            tpr_at_target.append(tpr[idx])\n",
    "            thresholds_at_target.append(thresholds[idx])\n",
    "\n",
    "    plt.xlabel(\"fpr\")\n",
    "    plt.xlim(1e-7, 1)\n",
    "    plt.ylim(1e-7, 1)\n",
    "    plt.semilogx()\n",
    "    plt.ylabel(\"tpr\")\n",
    "    plt.semilogy()\n",
    "    plt.title(\"{}_ROC\".format(eval.title))\n",
    "    plt.vlines(10**-5, 0, 1, colors=\"r\", linestyles=\"dashed\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    # plt.show()\n",
    "    \n",
    "    print(f\"\\nTPR at FPR = {target_fpr} for each channel:\")\n",
    "    for label, tpr, threshold in zip(eval.labels, tpr_at_target, thresholds_at_target):\n",
    "        print(f\"{label}: {tpr*100:.6f}%, Threshold = {threshold:.6f}\")\n",
    "\n",
    "def plot_anomaly_score_distribution(eval, bins=1000, range=None):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    # Determine the range for the bins\n",
    "    all_scores = np.concatenate([eval.br_loss] + eval.signal_loss)\n",
    "    min_score, max_score = 0.01, np.max(all_scores)\n",
    "    # bin_edges = np.linspace(min_score, max_score, bins + 1)\n",
    "    # bin_edges = np.logspace(np.log10(min_score), np.log10(max_score), bins + 1)\n",
    "    min_range, max_range = range\n",
    "    bin_edges = np.logspace(np.log10(min_range), np.log10(max_range), bins + 1)\n",
    "\n",
    "\n",
    "    # Plot background distribution\n",
    "    br_weights = eval.br_weights / np.sum(eval.br_weights)  # Normalize weights\n",
    "    ax.hist(eval.br_loss, \n",
    "            bins=bin_edges, \n",
    "            weights=br_weights, \n",
    "            histtype='step', \n",
    "            label='Background',\n",
    "            color='black', \n",
    "            density=True,\n",
    "            range=range)\n",
    "\n",
    "    # Plot signal distributions\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(eval.signal_loss)))\n",
    "    for i, (signal_scores, signal_weights, label) in enumerate(zip(eval.signal_loss, eval.signal_weights, eval.labels)):\n",
    "        signal_weights = signal_weights / np.sum(signal_weights)  # Normalize weights\n",
    "        ax.hist(signal_scores, \n",
    "                bins=bin_edges, \n",
    "                weights=signal_weights,\n",
    "                histtype='step', \n",
    "                label=label, \n",
    "                color=colors[i],\n",
    "                density=True, \n",
    "                range=range)\n",
    "\n",
    "    ax.set_xlabel('Anomaly Score')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'{eval.title} Anomaly Score Distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, which='both', linestyle='--', alpha=0.7)\n",
    "\n",
    "    ax.set_ylim(bottom=1e-4, top=10)\n",
    "    ax.set_xlim(range)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    # Calculate and print the mean anomaly score for each distribution\n",
    "    print(\"\\nMean Anomaly Scores:\")\n",
    "    print(f\"Background: {np.average(eval.br_loss, weights=eval.br_weights):.6f}\")\n",
    "    for signal_scores, signal_weights, label in zip(eval.signal_loss, eval.signal_weights, eval.labels):\n",
    "        mean_score = np.average(signal_scores, weights=signal_weights)\n",
    "        print(f\"{label}: {mean_score:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "signal_labels = [\"Ato4l\",\n",
    "                \"hToTauTau\",\n",
    "                \"hChToTauNu\",\n",
    "                \"leptoquark\"\n",
    "                ]\n",
    "signal_data = [Ato4l_data,\n",
    "               hToTauTau_data,\n",
    "               hChToTauNu_data,\n",
    "               leptoquark_data\n",
    "               ]\n",
    "models_to_eval = [\n",
    "    (0,4),(4,7),\n",
    "    (5,0) ,\n",
    "    (5,2),\n",
    "    (5,5)\n",
    "]\n",
    "\n",
    "evals_CKL = np.empty((6, 8), dtype=object)\n",
    "evals_KL = np.empty((6, 8), dtype=object)\n",
    "channel_results = {}    # dict with key:channel value:channel[gamma][iter] \n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(iters) : \n",
    "# for i,j in models_to_eval : \n",
    "# for j in range(iters) : \n",
    "        try:\n",
    "            model_path = home_path+f'software_dev/trained_models/gamma_tuning/gamma{gamma_values[i]:.0e}/iter_{j}_LB/'\n",
    "            # model_path = home_path+f'software_dev/trained_models/gamma_tuning/VAE_only/iter_{j}/'\n",
    "\n",
    "            print(f\"Evaluating model from path: {model_path}\")\n",
    "            evaluation = Model_Evaluator(model_path,\n",
    "                                X_test,\n",
    "                                np.ones(len(X_test)),\n",
    "                                signal_data,\n",
    "                                [np.ones(len(Ato4l_data)),\n",
    "                                        np.ones(len(hToTauTau_data)),\n",
    "                                        np.ones(len(hChToTauNu_data)),\n",
    "                                        np.ones(len(leptoquark_data))],\n",
    "                                input_dim = X_test.shape[1],\n",
    "                                title=f'VAE Model gamma{gamma_values[i]:.0e} iter {j} large batch',\n",
    "                                # title=f'VAE Model iter {j}',\n",
    "                                save = False,\n",
    "                                labels = signal_labels)\n",
    "            \n",
    "            print(\"Model_Evaluator instance created successfully\")\n",
    "            \n",
    "            print(\"Calculating losses...\")\n",
    "            evaluation.calculate_loss('CKL')\n",
    "            print(\"Losses calculated\")\n",
    "            \n",
    "            print(\"Getting performance...\")\n",
    "            result = evaluation.GetPerformance(show_plot=True)\n",
    "            print(f\"GetPerformance() returned: {result}\")\n",
    "            \n",
    "            if not result:\n",
    "                print(f\"Warning: GetPerformance() returned an empty result for model {j}\")\n",
    "            else:\n",
    "                evals_CKL[i][j] = evaluation\n",
    "                # evals[0][j] = evaluation\n",
    "                for channel, tpr in result:\n",
    "                    if channel not in channel_results:\n",
    "                        channel_results[channel] = [[] for _ in range(6)]\n",
    "                    channel_results[channel][i].append(tpr)\n",
    "                    # channel_results[channel][0].append(tpr)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while evaluating model {i}:\")\n",
    "            print(traceback.format_exc())\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Final channel results:\", channel_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d133a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE \n",
    "for i in range(1):\n",
    "    for j in range(iters) : \n",
    "        curr_eval = evals_CKL[i][j]\n",
    "        if curr_eval is not None:\n",
    "            plot_ROC(curr_eval)\n",
    "            plt.show()\n",
    "            plot_anomaly_score_distribution(curr_eval, bins=300, range=(1e-2, 1e3))\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CKL \n",
    "for i in range(6):\n",
    "    for j in range(iters) : \n",
    "        curr_eval = evals_CKL[i][j]\n",
    "        if curr_eval is not None:\n",
    "            plot_ROC(curr_eval)\n",
    "            plt.show()\n",
    "            plot_anomaly_score_distribution(curr_eval, bins=300, range=(1e-2, 1e3))\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92361d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TPR at FPR = 1e-05 for each channel:\n",
      "Ato4l: 5.383337%, Threshold = 8222.2695312500\n",
      "hToTauTau: 0.120935%, Threshold = 8222.2695312500\n",
      "hChToTauNu: 0.093651%, Threshold = 8222.2695312500\n",
      "leptoquark: 0.081340%, Threshold = 8222.2695312500\n"
     ]
    }
   ],
   "source": [
    "notable_models = [\n",
    "  # (5,2),\n",
    "  # (0,4),(4,7),\n",
    "  # (5,2),\n",
    "  (5,0)\n",
    "  # (5,5)\n",
    "]\n",
    "\n",
    "for (i, j) in notable_models:\n",
    "  curr_eval = evals[i][j]\n",
    "  thrs = get_threshold_from_ROC(curr_eval)\n",
    "  # plot_anomaly_score_distribution(curr_eval, bins=300, range=(1e-1, 1e3))\n",
    "  # plt.show()\n",
    "  # plot_histogram(curr_eval, bins=100, bg_only=False)\n",
    "  # plt.show()\n",
    "  # plot_ROC(curr_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6522d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "  for j in range(iters) : \n",
    "    curr_eval = evals[i][j]\n",
    "    if curr_eval is not None:\n",
    "        plot_anomaly_score_distribution(curr_eval, bins=300, range=(1e-1, 1e3))\n",
    "        \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffbf311",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_plot = [\"Ato4l\",\n",
    "                \"hToTauTau\",\n",
    "                \"hChToTauNu\",\n",
    "                \"leptoquark\"\n",
    "                ]\n",
    "\n",
    "for i in range(1):\n",
    "  for j in range(8) : \n",
    "    if evals[i][j]  is not None:\n",
    "      curr_eval = evals[i][j] \n",
    "      # curr_eval.ROC(labels_to_plot=labels_to_plot)\n",
    "      plot_ROC(curr_eval, labels_to_plot=labels_to_plot)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a17ec7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Ato4l', 'hToTauTau', 'hChToTauNu', 'leptoquark'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6982b930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0008134044352565307,\n",
       " 9.690377748543507e-05,\n",
       " 0.001201019545198271,\n",
       " 0.001115861680135313,\n",
       " 6.166604021800414e-05,\n",
       " 0.0012039560233038902,\n",
       " 0.0004140434128923135,\n",
       " 0.0009279270813756813]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_results['leptoquark'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55ba3d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel Statistics:\n",
      "Ato4l: Mean TPR = 3.2337%, Std Dev = 0.0145\n",
      "hToTauTau: Mean TPR = 0.0805%, Std Dev = 0.0004\n",
      "hChToTauNu: Mean TPR = 0.0632%, Std Dev = 0.0003\n",
      "leptoquark: Mean TPR = 0.0469%, Std Dev = 0.0003\n"
     ]
    }
   ],
   "source": [
    "# VAE\n",
    "if channel_results:\n",
    "    for g in range(1):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        channels = list(channel_results.keys())\n",
    "        n_channels = len(channels)\n",
    "        # n_models = len(channel_results[channels[0]][g])\n",
    "        \n",
    "        # x = np.arange(n_models)\n",
    "        width = 0.8 / n_channels\n",
    "        \n",
    "        for i, channel in enumerate(channels):\n",
    "            n_models = len(channel_results[channel][g])\n",
    "            x = np.arange(n_models)\n",
    "\n",
    "            tprs = channel_results[channel][g]\n",
    "            plt.bar(x + i * width, tprs, width, label=channel)\n",
    "        \n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel('True Positive Rate (TPR) at FPR = 1e-5')\n",
    "        plt.title(f'TPR Comparison Across Models for VAE')\n",
    "        plt.xticks(x + width * (n_channels - 1) / 2, [f'Model {i}' for i in range(n_models)])\n",
    "        plt.yscale('log')\n",
    "        plt.ylim(1e-4, 1e-1)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        # plt.savefig('VAE_tpr_comparison_plot.png', dpi=600, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nChannel Statistics:\")\n",
    "        for channel in channels:\n",
    "            tprs = channel_results[channel][g]\n",
    "            mean = np.mean(tprs)\n",
    "            std = np.std(tprs)\n",
    "            print(f\"{channel}: Mean TPR = {mean*100:.4f}%, Std Dev = {std:.4f}\")\n",
    "else:\n",
    "    print(\"No results were obtained. Cannot create comparison plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a742a3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel Statistics:\n",
      "Ato4l: Mean TPR = 3.3481%, Std Dev = 0.0224\n",
      "hToTauTau: Mean TPR = 0.0745%, Std Dev = 0.0003\n",
      "hChToTauNu: Mean TPR = 0.0601%, Std Dev = 0.0003\n",
      "leptoquark: Mean TPR = 0.0469%, Std Dev = 0.0003\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel Statistics:\n",
      "Ato4l: Mean TPR = nan%, Std Dev = nan\n",
      "hToTauTau: Mean TPR = nan%, Std Dev = nan\n",
      "hChToTauNu: Mean TPR = nan%, Std Dev = nan\n",
      "leptoquark: Mean TPR = nan%, Std Dev = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs/ddn/sdf/group/atlas/d/lizhx/anaconda3/envs/FastML/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/fs/ddn/sdf/group/atlas/d/lizhx/anaconda3/envs/FastML/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/fs/ddn/sdf/group/atlas/d/lizhx/anaconda3/envs/FastML/lib/python3.8/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/fs/ddn/sdf/group/atlas/d/lizhx/anaconda3/envs/FastML/lib/python3.8/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/fs/ddn/sdf/group/atlas/d/lizhx/anaconda3/envs/FastML/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel Statistics:\n",
      "Ato4l: Mean TPR = nan%, Std Dev = nan\n",
      "hToTauTau: Mean TPR = nan%, Std Dev = nan\n",
      "hChToTauNu: Mean TPR = nan%, Std Dev = nan\n",
      "leptoquark: Mean TPR = nan%, Std Dev = nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel Statistics:\n",
      "Ato4l: Mean TPR = nan%, Std Dev = nan\n",
      "hToTauTau: Mean TPR = nan%, Std Dev = nan\n",
      "hChToTauNu: Mean TPR = nan%, Std Dev = nan\n",
      "leptoquark: Mean TPR = nan%, Std Dev = nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel Statistics:\n",
      "Ato4l: Mean TPR = 2.2588%, Std Dev = 0.0156\n",
      "hToTauTau: Mean TPR = 0.0613%, Std Dev = 0.0003\n",
      "hChToTauNu: Mean TPR = 0.0444%, Std Dev = 0.0002\n",
      "leptoquark: Mean TPR = 0.0282%, Std Dev = 0.0002\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel Statistics:\n",
      "Ato4l: Mean TPR = 3.3117%, Std Dev = 0.0169\n",
      "hToTauTau: Mean TPR = 0.0776%, Std Dev = 0.0003\n",
      "hChToTauNu: Mean TPR = 0.0567%, Std Dev = 0.0003\n",
      "leptoquark: Mean TPR = 0.0445%, Std Dev = 0.0003\n"
     ]
    }
   ],
   "source": [
    "if channel_results:\n",
    "    for g in range(6):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        channels = list(channel_results.keys())\n",
    "        n_channels = len(channels)\n",
    "        # n_models = len(channel_results[channels[0]][g])\n",
    "        \n",
    "        # x = np.arange(n_models)\n",
    "        width = 0.8 / n_channels\n",
    "        \n",
    "        for i, channel in enumerate(channels):\n",
    "            n_models = len(channel_results[channel][g])\n",
    "            x = np.arange(n_models)\n",
    "\n",
    "            tprs = channel_results[channel][g]\n",
    "            plt.bar(x + i * width, tprs, width, label=channel)\n",
    "        \n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel('True Positive Rate (TPR) at FPR = 1e-5')\n",
    "        plt.title(f'TPR Comparison Across Models for Gamma={gamma_values[g]} large batch')\n",
    "        plt.xticks(x + width * (n_channels - 1) / 2, [f'Model {i}' for i in range(n_models)])\n",
    "        plt.yscale('log')\n",
    "        plt.ylim(1e-5, 1e-1)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('VAE_tpr_comparison_plot.png', dpi=600, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nChannel Statistics:\")\n",
    "        for channel in channels:\n",
    "            tprs = channel_results[channel][g]\n",
    "            mean = np.mean(tprs)\n",
    "            std = np.std(tprs)\n",
    "            print(f\"{channel}: Mean TPR = {mean*100:.4f}%, Std Dev = {std:.4f}\")\n",
    "else:\n",
    "    print(\"No results were obtained. Cannot create comparison plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe94984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if channel_results:\n",
    "    plt.figure(figsize=(14, 8))  # Increased figure size to accommodate the legend\n",
    "    channels = list(channel_results.keys())\n",
    "    n_channels = len(channels)\n",
    "    n_models = len(channel_results[channels[0]])\n",
    "    \n",
    "    for i, channel in enumerate(channels):\n",
    "        tprs = channel_results[channel]\n",
    "        plt.scatter(range(n_models), tprs, label=channel, s=50)\n",
    "    \n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('True Positive Rate (TPR) at FPR = 1e-5')\n",
    "    plt.semilogy()\n",
    "    plt.title('TPR Comparison Across Models and Channels')\n",
    "    plt.xticks(range(n_models), [f'{i}' for i in range(n_models)])\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Place legend outside the plot\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('VAE_tpr_comparison_plot.png', dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nChannel Statistics:\")\n",
    "    for channel in channels:\n",
    "        tprs = channel_results[channel]\n",
    "        mean = np.mean(tprs)\n",
    "        std = np.std(tprs)\n",
    "        print(f\"{channel}: Mean TPR = {mean:.4f}, Std Dev = {std:.4f}\")\n",
    "else:\n",
    "    print(\"No results were obtained. Cannot create comparison plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2eb001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 45s 2ms/step\n",
      "1750/1750 [==============================] - 3s 2ms/step\n",
      "21603/21603 [==============================] - 40s 2ms/step\n",
      "23759/23759 [==============================] - 43s 2ms/step\n",
      "10642/10642 [==============================] - 19s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TPR at FPR = 1e-05 for each channel:\n",
      "Ato4l: 4.840179%, Theshold = 177382.706232\n",
      "hToTauTau: 0.104733%, Theshold = 177382.706232\n",
      "hChToTauNu: 0.080761%, Theshold = 177382.706232\n",
      "leptoquark: 0.069888%, Theshold = 177382.706232\n"
     ]
    }
   ],
   "source": [
    "Losses=['MSE']\n",
    "for string in Losses:\n",
    "    evaluation=Model_Evaluator('/eos/user/h/hjia/AnomalyDetection/trained_models/VAE_model/version1/',\n",
    "                               X_test,\n",
    "                               np.ones(len(X_test)),\n",
    "                               signal_data,\n",
    "                               [np.ones(len(Ato4l_data)),\n",
    "                                    np.ones(len(hToTauTau_data)),\n",
    "                                    np.ones(len(hChToTauNu_data)),\n",
    "                                    np.ones(len(leptoquark_data))],\n",
    "                               input_dim = X_test.shape[1],\n",
    "                               title='VAE Model',\n",
    "                               save = False,\n",
    "                               labels = signal_labels)\n",
    "#     A2_MSE=evaluation.calculate_loss('MSE')[0]\n",
    "    A2_loss=evaluation.calculate_loss(string)[1][0]\n",
    "    evaluation.ROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5176b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 42s 2ms/step\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).beta\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).beta_tracker.total\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).beta_tracker.count\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
      "1750/1750 [==============================] - 3s 2ms/step\n",
      "21603/21603 [==============================] - 38s 2ms/step\n",
      "23759/23759 [==============================] - 42s 2ms/step\n",
      "10642/10642 [==============================] - 18s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TPR at FPR = 1e-05 for each channel:\n",
      "Ato4l: 3.791385%, Theshold = 34789.515625\n",
      "hToTauTau: 0.083323%, Theshold = 34789.515625\n",
      "hChToTauNu: 0.062741%, Theshold = 34789.515625\n",
      "leptoquark: 0.049039%, Theshold = 34789.515625\n"
     ]
    }
   ],
   "source": [
    "Losses=['CKL']\n",
    "for string in Losses:\n",
    "    evaluation=Model_Evaluator('/eos/user/h/hjia/AnomalyDetection/trained_models/VAE_model/version1/',\n",
    "                               X_test,\n",
    "                               np.ones(len(X_test)),\n",
    "                               signal_data,\n",
    "                               [np.ones(len(Ato4l_data)),\n",
    "                                    np.ones(len(hToTauTau_data)),\n",
    "                                    np.ones(len(hChToTauNu_data)),\n",
    "                                    np.ones(len(leptoquark_data))],\n",
    "                               input_dim = X_test.shape[1],\n",
    "                               title='VAE Model',\n",
    "                               save = False,\n",
    "                               labels = signal_labels)\n",
    "#     A2_MSE=evaluation.calculate_loss('MSE')[0]\n",
    "    A2_loss=evaluation.calculate_loss(string)[1][0]\n",
    "    evaluation.ROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c8971",
   "metadata": {},
   "outputs": [],
   "source": [
    "Losses=['KL']\n",
    "for string in Losses:\n",
    "    evaluation=Model_Evaluator('/eos/user/h/hjia/AnomalyDetection/trained_models/VAE_model/version1/',\n",
    "                               X_test,\n",
    "                               np.ones(len(X_test)),\n",
    "                               signal_data,\n",
    "                               [np.ones(len(Ato4l_data)),\n",
    "                                    np.ones(len(hToTauTau_data)),\n",
    "                                    np.ones(len(hChToTauNu_data)),\n",
    "                                    np.ones(len(leptoquark_data))],\n",
    "                               input_dim = X_test.shape[1],\n",
    "                               title='VAE Model',\n",
    "                               save = False,\n",
    "                               labels = signal_labels)\n",
    "#     A2_MSE=evaluation.calculate_loss('MSE')[0]\n",
    "    A2_loss=evaluation.calculate_loss(string)[1][0]\n",
    "    evaluation.ROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70086212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55969, 57)\n",
      "(691283, 57)\n",
      "(760272, 57)\n",
      "(340544, 57)\n"
     ]
    }
   ],
   "source": [
    "print(Ato4l_data.shape)\n",
    "print(hToTauTau_data.shape)\n",
    "print(hChToTauNu_data.shape)\n",
    "print(leptoquark_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee2a4aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_vae_enc = Qmake_encoder_set_weights(57,32,16,3)\n",
    "ori_vae_dec = Qmake_decoder_set_weights(57,32,16,3)\n",
    "orginal_model = VAE_Model(ori_vae_enc, ori_vae_dec)\n",
    "# orginal_model.predict(Ato4l_data)\n",
    "orginal_model.load_weights(\"/eos/user/h/hjia/AnomalyDetection/trained_models/VAE_model/version1/\")\n",
    "\n",
    "\n",
    "def make_simplified_encoder(input_dim, h_dim_1, h_dim_2, latent_dim):\n",
    "    inputs = keras.Input(shape=(input_dim,), name='inputs')\n",
    "#     x = BatchNormalization(name=\"BN0\")(inputs)\n",
    "    x = Dense(h_dim_1,\n",
    "             kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "             bias_initializer=keras.initializers.Zeros(),\n",
    "             name = \"dense1\")(inputs)\n",
    "#     x = BatchNormalization(name=\"BN1\")(x)\n",
    "    x = ReLU(name=\"relu1\")(x)\n",
    "    x = Dense(h_dim_2,\n",
    "             kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "             bias_initializer=keras.initializers.Zeros(),\n",
    "             name = \"dense2\")(x)    \n",
    "#     x = BatchNormalization(name=\"BN2\")(x)\n",
    "    x = ReLU(name=\"relu2\")(x)\n",
    "    z_mean=Dense(latent_dim, name='z_mean',\n",
    "                  kernel_initializer=keras.initializers.HeNormal(seed=None),\n",
    "                  bias_initializer=keras.initializers.Zeros())(x)\n",
    "    new_encoder = keras.Model(inputs,z_mean,name='encoder')\n",
    "    return new_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff3c5876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set weight for  <keras.src.engine.input_layer.InputLayer object at 0x7f406719ac40>\n",
      "[]\n",
      "set weight for  <keras.src.layers.core.dense.Dense object at 0x7f40671e1f70>\n",
      "[array([[-0.02705688,  0.01632243, -0.01023644, ...,  0.01554523,\n",
      "        -0.04189352,  0.02415809],\n",
      "       [-0.15308043, -0.17816576, -0.05987004, ...,  0.41958103,\n",
      "        -0.03714512,  0.11331005],\n",
      "       [-0.02266147,  0.00731888, -0.01881623, ...,  0.06766188,\n",
      "        -0.02835458, -0.0037509 ],\n",
      "       ...,\n",
      "       [-0.48511454, -0.3142542 , -0.20712487, ..., -0.22189808,\n",
      "        -0.38092145, -0.21758635],\n",
      "       [ 0.06738944,  0.11053742, -0.16982073, ..., -0.02774048,\n",
      "        -0.00193155,  0.0117031 ],\n",
      "       [ 0.08419731,  0.39925635, -0.11098306, ...,  0.04465427,\n",
      "        -0.30307958, -0.07810986]], dtype=float32), array([ 0.04321184, -0.20232144,  0.18984695, -0.20244434,  0.45105204,\n",
      "       -0.7102164 ,  0.09523638, -0.02751441,  0.54759014,  0.00984198,\n",
      "       -0.3603616 , -0.558122  ,  0.5383631 ,  0.33886376,  0.1056056 ,\n",
      "       -0.05399363, -0.1850081 ,  0.19585428, -0.24920127,  0.63460624,\n",
      "        0.317433  ,  0.31583235,  0.72001904, -0.00823396,  0.60704577,\n",
      "        0.07507917, -0.7435786 ,  0.2932002 ,  0.04214797,  1.41782   ,\n",
      "       -0.20832804, -0.01269355], dtype=float32)]\n",
      "set weight for  <keras.src.layers.activation.relu.ReLU object at 0x7f40671e1d00>\n",
      "[]\n",
      "set weight for  <keras.src.layers.core.dense.Dense object at 0x7f4067131af0>\n",
      "[array([[-5.00188589e-01, -5.30416593e-02,  7.25402385e-02,\n",
      "        -1.45215869e-01,  9.23595801e-02,  3.75598222e-01,\n",
      "         2.77780414e-01,  8.00229609e-02,  3.97720516e-01,\n",
      "        -1.37818545e-01, -3.27211767e-01,  1.02717504e-01,\n",
      "        -1.28840089e-01,  3.09176922e-01,  7.93438330e-02,\n",
      "         2.30592847e-01],\n",
      "       [-1.58148363e-01,  9.51669738e-02, -2.06720494e-02,\n",
      "        -2.70101547e-01,  5.60647324e-02,  2.69160062e-01,\n",
      "        -5.09954751e-01,  1.85553551e-01,  6.81227073e-03,\n",
      "        -2.88182437e-01, -7.23497793e-02,  3.18148732e-01,\n",
      "        -9.56117436e-02, -2.98128337e-01, -1.37762725e-01,\n",
      "         3.22881907e-01],\n",
      "       [-5.74760199e-01, -8.78342986e-02, -2.03440130e-01,\n",
      "         2.82578290e-01,  1.70890968e-02, -1.62528187e-01,\n",
      "         2.08498880e-01, -3.05598319e-01,  2.15918854e-01,\n",
      "         1.54928759e-01,  1.23089820e-01,  3.20997030e-01,\n",
      "        -4.54761744e-01, -5.16039670e-01,  5.06074633e-03,\n",
      "         2.90502191e-01],\n",
      "       [-5.01936227e-02,  1.22956224e-01, -4.08949614e-01,\n",
      "         2.01725945e-01,  1.73608795e-01,  3.96296643e-02,\n",
      "        -2.06509441e-01,  1.73616573e-01,  4.18482721e-02,\n",
      "        -1.47401497e-01,  1.37366029e-02, -1.65412918e-01,\n",
      "         5.65804303e-01, -2.56477863e-01, -6.17581680e-02,\n",
      "         1.77407870e-03],\n",
      "       [-4.04257029e-01,  5.00675976e-01, -3.72289181e-01,\n",
      "         3.44767004e-01, -1.77878991e-01, -2.63430417e-01,\n",
      "         1.58944070e-01, -1.76832780e-01,  1.37933612e-01,\n",
      "         4.36129384e-02,  6.68224273e-03, -7.56580830e-02,\n",
      "         4.29600328e-01,  1.96527615e-01,  3.92188370e-01,\n",
      "         3.41765016e-01],\n",
      "       [-4.87424195e-01,  5.26401758e-01, -3.92203405e-02,\n",
      "        -6.35318577e-01, -2.10752010e-01,  3.10947508e-01,\n",
      "        -5.77871501e-01, -1.10670052e-01,  3.54878634e-01,\n",
      "        -4.26490963e-01, -9.35309231e-02,  3.41004848e-01,\n",
      "         1.50384232e-01,  2.52635747e-01,  7.00989842e-01,\n",
      "        -5.51664233e-01],\n",
      "       [ 5.13832092e-01, -8.60428140e-02, -2.25781277e-01,\n",
      "         2.12023631e-02, -5.93608618e-02, -1.21029578e-02,\n",
      "        -2.22590879e-01,  1.37417808e-01, -6.81800321e-02,\n",
      "         1.12636931e-01, -9.02320817e-03,  1.37990549e-01,\n",
      "         6.56491220e-01, -1.01391487e-01, -2.34295845e-01,\n",
      "        -1.59153759e-01],\n",
      "       [ 6.45198151e-02,  4.46027279e-01, -3.90307009e-01,\n",
      "        -6.93025365e-02, -3.35381329e-02, -8.70183855e-02,\n",
      "         1.08311214e-01,  1.60117913e-02,  7.67182335e-02,\n",
      "        -1.88036397e-01,  1.14017971e-01,  2.37188041e-01,\n",
      "         2.31015131e-01,  1.02107674e-01,  6.71630740e-01,\n",
      "        -6.50513351e-01],\n",
      "       [ 3.04113269e-01,  7.24149793e-02,  3.20006721e-03,\n",
      "        -2.11950064e-01,  2.70908713e-01,  3.02207381e-01,\n",
      "        -4.00400549e-01, -1.95796385e-01, -3.37311387e-01,\n",
      "        -1.11475356e-01,  2.47620061e-01,  3.18935454e-01,\n",
      "         3.11243922e-01, -1.27917260e-01, -1.49354234e-01,\n",
      "        -1.87904999e-01],\n",
      "       [ 1.05267800e-01,  5.85006356e-01,  3.20802450e-01,\n",
      "        -3.37939829e-01,  5.96644431e-02,  6.02551810e-02,\n",
      "        -5.33938706e-01, -2.64100954e-02,  8.56401250e-02,\n",
      "         2.24897832e-01, -2.97764335e-02,  1.43846884e-01,\n",
      "        -3.66645120e-02,  7.89621696e-02, -2.89045900e-01,\n",
      "         2.93896884e-01],\n",
      "       [-2.22309127e-01, -1.33606702e-01, -1.03433073e-01,\n",
      "        -1.75453529e-01, -1.76213756e-01,  2.89899915e-01,\n",
      "        -1.31420299e-01, -1.79453269e-01,  2.63845861e-01,\n",
      "        -2.24525392e-01, -3.60596269e-01, -4.72217128e-02,\n",
      "        -2.87545711e-01,  3.67907256e-01,  2.44341999e-01,\n",
      "        -3.55287455e-02],\n",
      "       [ 8.37161690e-02,  2.86161125e-01, -4.89087366e-02,\n",
      "         2.50885725e-01,  1.03545286e-01,  4.37700003e-01,\n",
      "        -3.65901172e-01,  3.06894153e-01,  8.02465901e-03,\n",
      "         2.18165666e-01, -3.62059206e-01, -2.58802567e-02,\n",
      "         2.91321456e-01, -4.93075997e-02, -3.97062391e-01,\n",
      "         5.09832084e-01],\n",
      "       [ 2.27877915e-01, -1.77309200e-01,  2.61757188e-02,\n",
      "        -2.61751294e-01,  1.13304079e-01,  7.23205090e-01,\n",
      "         1.33654431e-01, -8.95088986e-02, -3.20448786e-01,\n",
      "         1.51196331e-01,  1.29860118e-01,  2.93029577e-01,\n",
      "         5.72312057e-01,  3.08894187e-01,  6.56742930e-01,\n",
      "        -1.97207808e+00],\n",
      "       [-1.53453751e-02,  4.38937038e-01,  1.17318235e-01,\n",
      "         2.36686498e-01, -4.44804549e-01,  6.55618489e-01,\n",
      "         5.22563942e-02, -1.85197726e-01, -7.00441003e-02,\n",
      "        -8.11178610e-02,  2.72232592e-01,  4.86567259e-01,\n",
      "        -5.33327818e-01,  3.20492178e-01, -3.79034460e-01,\n",
      "         5.90260774e-02],\n",
      "       [ 1.32527128e-01, -2.87964288e-03, -3.73108424e-02,\n",
      "        -1.33165908e+00, -3.50106396e-02, -2.37512633e-01,\n",
      "        -8.23209465e-01,  1.57628991e-02,  1.37835786e-01,\n",
      "        -6.47532344e-02, -1.55474737e-01, -1.44828260e-01,\n",
      "        -5.15002429e-01, -4.99087088e-02,  1.25490353e-01,\n",
      "         2.14952692e-01],\n",
      "       [-2.97710001e-01, -8.55916142e-01, -1.40951335e-01,\n",
      "        -3.00185055e-01, -1.31400019e-01, -2.89164066e-01,\n",
      "         1.55926883e-01, -1.67764783e+00,  4.11537960e-02,\n",
      "        -3.32015187e-01,  3.40179265e-01,  3.23429435e-01,\n",
      "        -6.58826530e-02,  4.55322042e-02,  5.44393137e-02,\n",
      "         1.23880766e-02],\n",
      "       [-2.57611662e-01,  2.95922250e-01,  4.06242274e-02,\n",
      "        -2.24734023e-01,  1.03685878e-01,  2.02801183e-01,\n",
      "        -3.61109167e-01,  6.06267035e-01,  6.36648312e-02,\n",
      "         5.12331307e-01, -5.84323332e-02,  2.86719322e-01,\n",
      "         1.57071860e-03, -3.81147824e-02, -1.08383097e-01,\n",
      "        -4.79132012e-02],\n",
      "       [ 2.23560438e-01,  2.05505341e-01,  6.98249415e-03,\n",
      "        -2.17069387e-01,  1.40171707e-01, -1.47187516e-01,\n",
      "        -2.87118018e-01, -4.09113407e-01, -2.58152522e-02,\n",
      "        -3.67383778e-01,  2.21600041e-01,  3.66743505e-01,\n",
      "        -2.82944292e-01, -2.10645199e-01,  3.21348220e-01,\n",
      "         1.29398465e-01],\n",
      "       [-5.86696938e-02, -1.07894979e-01, -6.84012026e-02,\n",
      "        -4.77172643e-01,  8.15324634e-02,  4.22172755e-01,\n",
      "        -2.06824660e-01,  4.43090238e-02,  3.57743772e-03,\n",
      "        -2.98865616e-01,  5.60953319e-01, -2.62839496e-01,\n",
      "        -1.40831545e-01, -1.50178730e-01,  2.78904766e-01,\n",
      "         2.22324297e-01],\n",
      "       [ 1.05663635e-01,  5.77412508e-02,  4.30634409e-01,\n",
      "         2.56243706e-01,  2.57564306e-01,  3.95468354e-01,\n",
      "         2.30075464e-01,  3.32919329e-01,  6.36534169e-02,\n",
      "         4.89340603e-01,  2.17457533e-01,  3.09550524e-01,\n",
      "        -4.24798340e-01, -6.28823757e-01, -3.81891206e-02,\n",
      "        -1.98396802e-01],\n",
      "       [-1.32708028e-01,  3.38701040e-01,  2.73342635e-02,\n",
      "         1.94773838e-01,  5.65376952e-02, -2.81762276e-02,\n",
      "         3.96063238e-01, -7.12380335e-02, -1.32422715e-01,\n",
      "        -3.74736369e-01,  1.60455853e-01, -6.70208856e-02,\n",
      "        -1.93379447e-01, -6.84536323e-02, -6.75793961e-02,\n",
      "        -1.61030412e-01],\n",
      "       [-4.73367535e-02, -4.28634673e-01, -1.09608755e-01,\n",
      "         2.79943794e-01, -2.06386253e-01,  3.68057638e-01,\n",
      "         4.79766317e-02, -2.15002090e-01,  2.51972109e-01,\n",
      "         3.20010781e-01, -1.64661452e-01,  4.74401563e-01,\n",
      "         5.94099797e-02, -5.29040158e-01,  9.82673243e-02,\n",
      "         9.46933683e-03],\n",
      "       [-1.73338622e-01,  6.48898661e-01,  3.58323902e-01,\n",
      "        -2.09316432e-01,  2.39073947e-01,  5.17883748e-02,\n",
      "        -3.83969754e-01,  3.75860631e-01, -2.41988882e-01,\n",
      "         2.73527950e-01,  1.55468017e-01,  4.57704306e-01,\n",
      "         2.56813467e-01, -1.02996871e-01,  6.54840246e-02,\n",
      "        -5.09651244e-01],\n",
      "       [ 1.35079339e-01, -7.85455033e-02,  3.42529148e-01,\n",
      "         2.12333441e-01, -2.39866469e-02,  3.20241079e-02,\n",
      "         7.14823604e-03, -3.83344799e-01,  1.23298436e-01,\n",
      "        -4.01637077e-01,  5.15609086e-02, -4.42249166e-06,\n",
      "         1.99287325e-01,  1.05559707e-01, -3.01253540e-03,\n",
      "         1.99146226e-01],\n",
      "       [ 4.50104326e-01,  1.08646855e-01, -1.42407283e-01,\n",
      "         1.40067548e-01, -7.60147497e-02,  3.96352202e-01,\n",
      "        -7.09934309e-02, -1.50069833e-01,  2.72695092e-03,\n",
      "        -1.49464771e-01,  7.28900656e-02, -3.32330346e-01,\n",
      "         2.22732842e-01,  3.30002248e-01,  5.44067860e-01,\n",
      "         2.21403256e-01],\n",
      "       [-3.61328095e-01, -4.31063145e-01, -2.43047163e-01,\n",
      "         4.66781080e-01,  8.78425017e-02, -3.93932313e-01,\n",
      "         3.46480697e-01, -1.40625429e+00, -2.64035076e-01,\n",
      "        -2.94673219e-02,  5.10714114e-01,  1.39834024e-02,\n",
      "        -4.58911583e-02,  7.40978792e-02,  1.72785833e-01,\n",
      "        -7.48629197e-02],\n",
      "       [-5.03202155e-03,  6.40586391e-02, -2.28992298e-01,\n",
      "         1.71863586e-01, -3.87926102e-01,  8.26919615e-01,\n",
      "         3.14316899e-01, -7.17147708e-01, -4.22888510e-02,\n",
      "        -1.75008789e-01,  1.63256690e-01, -4.52154458e-01,\n",
      "         3.28900427e-01,  1.71354905e-01,  6.19560897e-01,\n",
      "        -8.82547274e-02],\n",
      "       [-6.23235226e-01, -1.06774801e-02,  1.70827419e-01,\n",
      "         6.95622340e-02, -2.36890823e-01,  2.03046322e-01,\n",
      "         4.41088915e-01,  2.53811777e-01,  1.95231572e-01,\n",
      "         3.69444340e-01,  1.41164452e-01,  2.59408802e-01,\n",
      "        -1.86116308e-01, -2.11621076e-01, -5.70663810e-01,\n",
      "        -4.94664103e-01],\n",
      "       [-3.53436857e-01,  2.13510878e-02,  1.35281324e-01,\n",
      "         3.63901556e-01,  9.71376523e-02, -1.03261635e-01,\n",
      "         1.59762412e-01,  8.35815258e-03,  2.64435619e-01,\n",
      "         1.32032827e-01, -2.36374922e-02,  5.47289908e-01,\n",
      "        -6.66352868e-01, -4.71636415e-01, -3.16347092e-01,\n",
      "         4.02831405e-01],\n",
      "       [ 2.19575837e-01,  2.77518481e-01, -1.01930529e-01,\n",
      "         2.15288743e-01, -4.26508069e-01,  3.74871492e-01,\n",
      "        -2.50177868e-02, -2.75978208e-01,  6.87220916e-02,\n",
      "        -1.00957195e-03,  7.56247997e-01, -6.82462007e-02,\n",
      "         5.49172580e-01, -3.90507579e-02, -1.53748825e-01,\n",
      "        -3.61416675e-02],\n",
      "       [-2.18674898e-01,  1.58866197e-01,  4.14684862e-02,\n",
      "         2.90789932e-04,  9.48114917e-02,  4.17992473e-01,\n",
      "        -4.30978775e-01,  4.97232616e-01,  7.37035796e-02,\n",
      "         4.67485040e-01, -1.91820472e-01,  1.57890975e-01,\n",
      "        -1.99643269e-01, -4.46947552e-02,  4.35692444e-02,\n",
      "         4.49435055e-01],\n",
      "       [ 2.28865653e-01,  1.58548295e-01, -7.29700997e-02,\n",
      "        -3.58404636e-01, -7.42403790e-02, -4.17483211e-01,\n",
      "        -2.32722029e-01, -9.42604244e-01,  1.53081030e-01,\n",
      "        -3.67339820e-01,  1.94030806e-01,  5.25542021e-01,\n",
      "        -1.75074771e-01, -4.05701026e-02, -6.52145520e-02,\n",
      "         4.65237834e-02]], dtype=float32), array([-0.99192584,  0.3561016 ,  0.4208028 , -0.03900583,  0.5627237 ,\n",
      "        0.08403586, -0.37931615, -0.9305935 ,  0.27698472, -0.02640301,\n",
      "        0.29997757,  0.32109296,  0.77120686,  0.41145054,  0.24295634,\n",
      "        0.46515188], dtype=float32)]\n",
      "set weight for  <keras.src.layers.activation.relu.ReLU object at 0x7f4067131250>\n",
      "[]\n",
      "set weight for  <keras.src.layers.core.dense.Dense object at 0x7f3cdc83fe50>\n",
      "[array([[-0.15956342, -0.29469293, -0.14519864],\n",
      "       [-0.02151131,  0.14028898, -0.40951848],\n",
      "       [ 0.03836306,  0.32632753, -0.04126772],\n",
      "       [-0.322863  ,  0.42257228,  0.35384864],\n",
      "       [ 0.26895982, -0.57215905, -0.49108955],\n",
      "       [-0.28879726, -0.02730809, -0.02767652],\n",
      "       [ 0.07486729, -0.07070249, -0.24961035],\n",
      "       [ 0.02956251, -0.35757294,  0.3698274 ],\n",
      "       [ 0.12045594, -0.16524063, -0.14634122],\n",
      "       [-0.03111534,  0.407232  , -0.29526374],\n",
      "       [ 0.06657935, -0.04434881,  0.35874146],\n",
      "       [ 0.26084682,  0.11606446,  0.34836775],\n",
      "       [-0.17910346, -0.13397716, -0.01654789],\n",
      "       [ 0.06906545,  0.46410114,  0.15372023],\n",
      "       [ 0.02255893, -0.340567  ,  0.14911848],\n",
      "       [ 0.12808374,  0.08985064,  0.06075337]], dtype=float32), array([ 0.41836712,  0.30282003, -0.21760224], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "new_encoder = make_simplified_encoder(57,32,16,3)\n",
    "# Transfer weights from the original encoder\n",
    "for layer in new_encoder.layers:\n",
    "    original_layer = ori_vae_enc.get_layer(layer.name)\n",
    "    if original_layer is not None:\n",
    "        print(\"set weight for \", layer)\n",
    "        print(original_layer.get_weights())\n",
    "        layer.set_weights(original_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b1b1c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: VAE_40MHZ_model_Vsmall_onchip/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: VAE_40MHZ_model_Vsmall_onchip/assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(new_encoder, 'VAE_40MHZ_model_Vsmall_onchip', save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
